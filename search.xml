<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>RESTful思考</title>
    <url>/2020/10/21/RestFul%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<h1 id="Richardson的成熟度模型"><a href="#Richardson的成熟度模型" class="headerlink" title="Richardson的成熟度模型"></a>Richardson的成熟度模型</h1><p><img src="/images/restful-grade.png" alt="RIchardson成熟度模型1"><br><img src="/images/RIchardson-restful.png" alt="RIchardson成熟度模型2"></p>
<h2 id="零级"><a href="#零级" class="headerlink" title="零级"></a>零级</h2><ul>
<li>服务有<strong>单个的URI</strong>，并且使用<strong>单个的HTTP方法</strong>(通常是P0ST)。</li>
<li>该模型的出发点是使用HTTP作为远程交互的传输系统，但是不会使用Web中的任何机制。本质上这里你是为了使用你的远程交互而利用HTTP作为隧道机制(Tunneling Mechanism)，通常是基于远程过程调用(Remote Procedure Invocation)的。</li>
<li>XML-RPC和普通老式XML( Plain Old XML，POX)使用了类似的方法: Http P0ST请求，和传递到单个URI端点的XML载荷，以及作为HTTP响应的一部分以XML格式交付的回复。</li>
</ul>
<h2 id="一级"><a href="#一级" class="headerlink" title="一级"></a>一级</h2><ul>
<li>使用了<strong>很多URI</strong>，但是只使用<strong>单个HTTP动词</strong>。这种基本的服务和零级服务之间的关键区别点在于，这种级别的服务暴露出了很多逻辑上的资源，而零级服务将所有的交互埋入了单个(大型的、复杂的)资源过将操作名称和参数插入到URI中，然后将该URI传递给一个远程服务(通常通过HTTP GET)，操作被埋藏了起来。</li>
<li>在Richardson成熟度模型中，通往真正REST的第一步是引入资源(Resource)这一概念。所以相比将所有的请求发送到单个服务端点(Service Endpoint)，现在我们会和单独的资源进行交互。</li>
<li>注意：<em>Richardson声明，如今大多数描述自己为“ RESTful”的服务实际上常常是一级服务。一级服务可以是很有用的，即使它们并没有严格遵守 RESTfull的束，因此它有可能通过使用一个动词(GET)意外地破坏数据，而这个动词原本不应该有这种副作用</em>。</li>
</ul>
<h2 id="二级"><a href="#二级" class="headerlink" title="二级"></a>二级</h2><ul>
<li>二级服务使用了<strong>大量的可通过URI寻址的资源</strong>。这样的服务支持多个HTTP动词来暴露资源。包含在这个级别的是CRUD( Create Read Update Delete，创建、读、更新和删除)服务，通常表示的是业务实体的资源状态，能够通过网络来操作。</li>
<li>在LEVEL 0和LEVEL 1中一直使用的是HTTP POST来完成所有的交互，但是有些人会使用GET作为替代。在目前的级别上并不会有多大的区别，GET和POST都是作为隧道机制(Tunneling Mechanism)让你能够通过HTTP完成交互。LEVEL 2避免了这一点，它会尽可能根据HTTP协议定义的那样来合理使用HTTP动词。</li>
<li>注意：<em>很重要的是，二级服务使用了HTTP动词和状态代码来协调交互，这意味着它们为实现健壮性而使用了web</em>。</li>
</ul>
<h2 id="三级"><a href="#三级" class="headerlink" title="三级"></a>三级</h2><p>最Web感知(web- aware)的服务级别，支持<strong>超媒体作为应用状态的引擎</strong>的观念，这个概念的缩写是不那么好看的HATEOAS(Hypertext As The Engine Of Application State)。即，表述包含了消费者可能感兴趣的到其他资源的URI链接。这种服务通过追踪资源来引导消费者，结果是引起应用状态的迁移<br>注意：<em>“超媒体作为应用状态的引擎”来自 Fielding关于REST架构风格的工作。我们倾向于使用“超媒体约束”这个术语，因为它更短，而且传递了以下含义:使用超媒体来管理应用的状态，这是大规模计算系统的有利方面</em></p>
<h1 id="Levels的意义-The-Meaning-of-the-Levels"><a href="#Levels的意义-The-Meaning-of-the-Levels" class="headerlink" title="Levels的意义(The Meaning of the Levels)"></a>Levels的意义(The Meaning of the Levels)</h1><p>我应该强调一下，<strong>Richardson成熟度模型(<a href="http://martinfowler.com/articles/richardsonMaturityModel.html">Richardson Maturity Model</a>，简称RMM)虽然是思考REST中有哪些元素的好方法，但是它并不直接定义REST中的级别</strong>。Roy Fielding也阐明了这一点：Level 3 RMM是REST的前置条件。和软件中的众多专有名词一样，REST也有很多的定义，但是由于Roy Fielding创造了这个名词，他的定义会权威很多。</p>
<p><strong>RMM的用处在于它提供了一个层层递进的思考RESTful背后本质思想的方法</strong>。正因为如此，我将它视为一个工具来帮助我们学习概念，而不是作为某种评估机制.</p>
<p>RMM和通用设计方法之间关系:</p>
<ul>
<li>Level 1 解释了如何通过分治法(Divide and Conquer)来处理复杂问题，将一个大型的服务端点(Service Endpoint)分解成多个资源。</li>
<li>Level 2 引入了一套标准的动词，用来以相同的方式应对类似的场景，移除不要的变化。</li>
<li>Level 3 引入了可发现性(Discoverability)，它可以使协议拥有自我描述(Self-documenting)的能力。<br>结果就是，这一模型帮助我们思考我们想要提供的HTTP服务是何种类型的，同时也勾勒出人们和它进行交互时的期望。</li>
</ul>
<h1 id="web-开发中一些注意点"><a href="#web-开发中一些注意点" class="headerlink" title="web 开发中一些注意点"></a>web 开发中一些注意点</h1><ol>
<li><p>善用<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/ETag">ETag</a><br>HTTP响应头是资源的特定版本的标识符。这可以让缓存更高效，并节省带宽，因为如果内容没有改变，Web服务器不需要发送完整的响应。而如果内容发生了变化，使用ETag有助于防止资源的同时更新相互覆盖（“空中碰撞”）。<br>如果给定URL中的资源更改，则一定要生成新的Etag值。 因此Etags类似于指纹，也可能被某些服务器用于跟踪。 比较etags能快速确定此资源是否变化，但也可能被跟踪服务器永久存留。<br>如果我们不希望得到整个资源的表述，只是想要检查HTTP头信息，则可以使用动词HEAD。动词HEAD允许我们基于指定资源的上下文来决定如何做进一步的处理，这样做能够避免因为转移整个资源的表述而付出网络传输方面的额外代价。</p>
</li>
<li><p><a href="https://juejin.im/post/5ca83c6351882544183367e2">put还是patch</a><br>PATCH 请求中的实体保存的是修改资源的指令，该指令指导服务器来对资源做出修改，所以不是幂等的。<br>PUT 用做更新操作的时候是提交一整个更新后的实体，而不是需要修改的实体中的部分属性。当 URI 指向一个存在的资源，服务器要做的事就是查找并替换。</p>
</li>
<li><p>HTTP不是RPC<br>人们常常错误地将HTTP称作一种远程过程调用(RPC)机制，仅仅是因为它也包括了请求和响应。RPC与其他形式的基于网络应用的通信的区别之处在于，从概念上讲它是在调用远程机器上的一个过程( procedure)。在RPC协议中，调用方识别出过程并且传递一组固定的参数，然后等待在使用相同接口返回的一个消息中提供的回答。远程方法调用(RMI)也是类似的，差异仅仅是将过程标识为一个{对象，方法}的组合，而不是一个简单的服务过程( service procedure)。被代理的RMI( Brokered rMi)添加了名称服务的间接层( name service indirection)和少量其他把戏( a few other tricks)，但是接口基本上是相同的。<br>将HTTP与RPC区分开的并不是语法，甚至也不是使用一个流作为参数所获得的不同的特性，尽管它帮助解释了为何现有的RPC机制对于Web而言是不可用的。HTTP与RPC之间的重大区别的是:<strong>请求是被定向到使用一个有标准语义的通用接口的资源，中间组件能够采用与提供服务的机器几乎完全相同的方式来解释这些语义</strong>。其结果是使得一个应用能够支持转换的分层( layers of transformation)和独立于信息来源的间接层( indirection that are independent of the<br>information origin)，这对于一个需要满足互联网规模、多个组织、无法控制的可伸缩性需求的信息系统来说，是非常有用的。与之相比较，RPC的机制是根据语言的API( language API)来定义的，而不是根据基于网络应用的需求来定义的。</p>
</li>
</ol>
<h1 id="url-资源设计"><a href="#url-资源设计" class="headerlink" title="url 资源设计"></a>url 资源设计</h1><p>决定哪些部分应该被分解成独立甚至重叠的资源，这是服务的设计流程的一部分。在进行这些决策时，我们需要考虑以下几个设计因素:</p>
<ul>
<li>表述的大小：载荷会有多大?是否值得分解成多个资源来优化网络访问和缓存?</li>
<li>原子性：由于一种资源与其他资源处于一种组合关系之中，那么应用是否有可能进入不一致的状态?资源的整个表述需要打包在同一个载荷中吗?</li>
<li>信息的重要性： 我们真的需要将所有信息作为一个原子块( atomic block)来发送吗?我们可以允许消费者决定他们需要请求哪些链接资源吗?</li>
<li>性能/可伸缩性： 这个资源会被频繁地访问吗?要生成它的表述是否需要昂贵的计算量或者事务?</li>
<li>可缓存性： 资源表述可以被缓存和复制吗?与该资源相关的不同信息条目的变化频率是否是不同的?哪些信息项依赖于请求的上下文?哪些中立于该上下文?</li>
</ul>
<p>回答这些问题有助于根据新的标准来分割资源，允许它的一些表述被缓存很长一段时间，而其他表述则是针对每一个请求而临时生成。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://blog.csdn.net/dm_vincent/article/details/51341037"> Richardson成熟度模型(Richardson Maturity Model) - 通往真正REST的步骤 </a></li>
<li>《REST实战+中文版-4》</li>
</ul>
]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>RESTful</tag>
        <tag>etag</tag>
        <tag>Richardson成熟度模型</tag>
        <tag>RMM</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo-Next + Github Page制作个人网站使用记录</title>
    <url>/2020/10/20/hexo/</url>
    <content><![CDATA[<h1 id="github-page"><a href="#github-page" class="headerlink" title="github page"></a>github page</h1><ol>
<li>在github上创建仓库</li>
<li>仓库命名为：<code>&#123;github用户名&#125;.github.io</code>, 比如 <code>XiaobinZhao.github.io</code></li>
<li>仓库新建分支gh-page</li>
<li>在仓库的settings –&gt; options –&gt; github pages 设置仓库的gh-page分支为发布分支，并save</li>
<li>打开<code>https://&#123;github用户名&#125;.github.io</code>即可享用， 比如<code>https://xiaobinzhao.github.io/</code></li>
</ol>
<h1 id="hexo-Next-主题使用记录"><a href="#hexo-Next-主题使用记录" class="headerlink" title="hexo-Next 主题使用记录"></a>hexo-Next 主题使用记录</h1><ol>
<li><p>修改内容自动重载并启动server</p>
<p>安装 <code>hexo-browsersync</code>即可：<code>npm install hexo-browsersync</code></p>
<p>安装成功之后，只需要正常执行 <code>hexo server</code> 或 <code>hexo s</code> 就能查看效果了。</p>
<p>经过测试，当保存文章的 Markdown 文件时，网页会自动刷新。另外，修改主题配置文件并保存之后，网页也会自动刷新，非常 nice。唯一一个缺憾是修改站点配置文件没办法触发网页的自动刷新，需要重新执行 <code>hexo g</code>。</p>
</li>
</ol>
<a id="more"></a>

<ol start="2">
<li><p>背景动画</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># JavaScript 3D library.</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/theme-next/theme-next-three</span></span><br><span class="line"><span class="attr">three:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="string">fasle</span></span><br><span class="line">  <span class="attr">three_waves:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">canvas_lines:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">canvas_sphere:</span> <span class="literal">false</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">vendors:</span></span><br><span class="line">  <span class="attr">three:</span> <span class="string">//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js</span></span><br><span class="line">  <span class="attr">three_waves:</span> <span class="string">//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three-waves.min.js</span></span><br><span class="line">  <span class="attr">canvas_lines:</span> <span class="string">//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/canvas_lines.min.js</span></span><br><span class="line">  <span class="attr">canvas_sphere:</span> <span class="string">//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/canvas_sphere.min.js</span>	</span><br></pre></td></tr></table></figure>
</li>
<li><p>其他可以参考</p>
<ul>
<li><a href="https://wylu.me/posts/e0424f3f/"> NexT主题进阶配置 </a></li>
<li><a href="https://hexo.io/zh-cn/docs/front-matterh"> hexo文档 </a></li>
<li><a href="http://theme-next.iissnan.com/"> next  IIssNan文档 </a></li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title>IO模型</title>
    <url>/2020/10/20/io%20%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%98%BB%E5%A1%9E%E3%80%81%E9%9D%9E%E9%98%BB%E5%A1%9E%E3%80%81%E5%90%8C%E6%AD%A5%E3%80%81%E5%BC%82%E6%AD%A5/</url>
    <content><![CDATA[<h1 id="IO模型"><a href="#IO模型" class="headerlink" title="IO模型"></a>IO模型</h1><p>在Linux(UNIX)操作系统中，共有五种IO模型，分别是：阻塞IO模型、非阻塞IO模型、IO复用模型、信号驱动IO模型以及异步IO模型。</p>
<a id="more"></a>

<ul>
<li>参看：<img src="/images/io%E6%A8%A1%E5%9E%8B.png" alt="io模型"></li>
</ul>
<p>在处理 IO 的时候，阻塞和非阻塞都是同步 IO。只有使用了特殊的 API 才是异步 IO。<img src="https://pic3.zhimg.com/50/7d3eb389b7724878bd7e12ebc6dbcdb5_hd.jpg?source=1940ef5c" data-rawwidth="415" data-rawheight="150" class="content_image" width="415"/></p>
<h1 id="同步-异步和阻塞-非阻塞"><a href="#同步-异步和阻塞-非阻塞" class="headerlink" title="同步/异步和阻塞/非阻塞"></a>同步/异步和阻塞/非阻塞</h1><p>阻塞/非阻塞 与 同步/异步不能简单的从字面理解，提供一个从分布式系统角度的回答。</p>
<ol>
<li><p><strong>同步与异步</strong>. 同步和异步关注的是消息通信机制 (synchronous communication/ asynchronous communication).所谓同步，就是在发出一个<em>调用</em>时，在没有得到结果之前，该<em>调用</em>就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由<em>调用者</em>主动等待这个<em>调用</em>的结果。而异步则是相反，<em>调用</em>在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在<em>调用</em>发出后，<em>被调用者</em>通过状态、通知来通知调用者，或通过回调函数处理这个调用。</p>
</li>
<li><p>阻塞与非阻塞<br>阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态: <strong>阻塞调用</strong>是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。<strong>非阻塞调用</strong>指在不能立刻得到结果之前，该调用不会阻塞当前线程。</p>
</li>
<li><p>打一个通俗的比方</p>
</li>
</ol>
<ul>
<li>老张爱喝茶，废话不说，煮开水。</li>
<li>出场人物：老张，水壶两把（普通水壶，简称水壶；会响的水壶，简称响水壶）。<ol>
<li>老张把水壶放到火上，立等水开。（同步阻塞）老张觉得自己有点傻</li>
<li>老张把水壶放到火上，去客厅看电视，时不时去厨房看看水开没有。（同步非阻塞）</li>
<li>老张还是觉得自己有点傻，于是变高端了，买了把会响笛的那种水壶。水开之后，能大声发出嘀<del>~</del>的噪音。老张把响水壶放到火上，立等水开。（异步阻塞）</li>
<li>老张觉得这样傻等意义不大,老张把响水壶放到火上，去客厅看电视，水壶响之前不再去看它了，响了再去拿壶。（异步非阻塞）老张觉得自己聪明了。</li>
</ol>
</li>
</ul>
<blockquote>
<p>所谓同步异步，只是对于水壶而言。普通水壶，同步；响水壶，异步。虽然都能干活，但响水壶可以在自己完工之后，提示老张水开了。这是普通水壶所不能及的。同步只能让调用者去轮询自己（情况2中），造成老张效率的低下。所谓阻塞非阻塞，仅仅对于老张而言。立等的老张，阻塞；看电视的老张，非阻塞。情况1和情况3中老张就是阻塞的，媳妇喊他都不知道。虽然3中响水壶是异步的，可对于立等的老张没有太大的意义。所以一般异步是配合非阻塞使用的，这样才能发挥异步的效用。</p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>阻塞、非阻塞、多路IO复用，都是同步IO，异步必定是非阻塞的，所以不存在异步阻塞和异步非阻塞的说法。真正的异步IO需要CPU的深度参与。换句话说，只有用户线程在操作IO的时候根本不去考虑IO的执行全部都交给CPU去完成，而自己只等待一个完成信号的时候，才是真正的异步IO。所以，拉一个子线程去轮询、去死循环，或者使用select、poll、epool，都不是异步。</p>
<ul>
<li>异步就是异步</li>
</ul>
<p>有许多io模型的相关文章主要涉及四个概念同步( synchronous).异步( asynchronous).阻塞(plocking)和non- blocking).有些文章将这四个作了两两组合,于是有了<strong>异步阳塞和异步非阳塞</strong>,可以很明确地说完全是是羍强之理解。无论是&lt;Uⅸ网络编程&gt;一书中所列的○io模式,还是POSIX标准都没有提这两个概念。异步就是异步!只有同步时才有阻塞和非阻塞之说。</p>
<ul>
<li>阻塞和非阻塞</li>
</ul>
<p>非阻塞时,要区分场合范围.比如linux中说的非阻塞iO和Java的NIO1.0中的非阻塞I/O不是相同的概念。从最根本来说,阻塞就是进程“被”休息,CPU处理其它进程去了,非阻塞可以理解成将大的整片时间的阻塞分成N多的小的阻塞,所以进程不断地有机会 被”CPU光顾,理论上可以做点其它事,看上去 Linux非阻塞I/O 要比阻塞好，但CPU会很大机率因socket没数据而空转 虽然这个进程是爽了，但是从整个机器的效率来说,浪费更大了！Java NIO1.0中的非阻塞I/O中的 Selector select()函数还是阻塞的,所以不会有无谓的CPU浪费Java NIO1.0,与其说是非阻塞I/O, 还不如说是,多路复用I/O,更好让人理解！</p>
<ul>
<li>异步</li>
</ul>
<p>异步可以说是I/O最理想的模型:CPU的原则是,有必要的时候才会参与,既不浪费,也不怠慢。理想中的异步I/O, Application无需等待socket数据(也正是因此进程而被”休息”).也无需 copy socket data,将由其它的同学(理想状态,不是CPU)负责将socket data copy到Appliation事先指定的内存后,通知一声Appliation(一般是回调函数)<br>copy socket data, Application是不用做了，但事情总是需要做，不管是谁做，CPU是否还是要花费精力去参与呢?可以用”内存映射”以及DMA等方式来达到“不用CPU去参与繁重的工作”的目的. “内存映射”是不用copy,而DMA是有其它芯片来代替CPU处理.</p>
<p>同步和异步针对应用程序来，关注的是程序中间的协作关系；阻塞与非阻塞更关注的是单个进程的执行状态。</p>
]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>IO模型</tag>
        <tag>阻塞</tag>
        <tag>非阻塞</tag>
        <tag>同步</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title>yield</title>
    <url>/2020/10/20/yiled/</url>
    <content><![CDATA[<h1 id="yield"><a href="#yield" class="headerlink" title="yield"></a>yield</h1><p>为了解释yiled需要理解几个概念：</p>
<ul>
<li>可迭代对象</li>
<li>迭代器</li>
<li>生成器</li>
</ul>
<h2 id="可迭代对象"><a href="#可迭代对象" class="headerlink" title="可迭代对象"></a>可迭代对象</h2><p>创建一个列表（list）时，你可以逐个地读取里面的每一项元素，这个过程称之为迭代（iteration）。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; for i in mylist:</span><br><span class="line">...    print(i)</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td></tr></table></figure>
<p>mylist是一个可迭代对象。当使用列表推导式（list comprehension）创建了一个列表时，它就是一个可迭代对象：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; mylist &#x3D; [x*x for x in range(3)]</span><br><span class="line">&gt;&gt;&gt; for i in mylist:</span><br><span class="line">...    print(i)</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">4</span><br></pre></td></tr></table></figure>
<p>任何可以使用在<code>for...in...</code>语句中的对象都可以叫做<strong>可迭代对象</strong>，例如：lists，strings，files等等。这些可迭代对象使用非常方便因为它能如你所愿的尽可能读取其中的元素，但是你不得不把所有的值存储在内存中，当它有大量元素的时候这并不一定总是你想要的。</p>
<p><strong>注</strong>：dict对象以及任何<strong>实现了<strong>iter</strong>()或者<strong>getitem</strong>()方法的类都是可迭代对象</strong>，此外，可迭代对象还可以用在zip,map等函数中，当一个可迭代对象作为参数传递给内建函数iter()时，它会返回一个迭代器对象。通常没必要自己来处理迭代器本身或者手动调用iter()，for语句会自动调用iter()，它会创建一个临时的未命名的变量来持有这个迭代器用于循环期间。 </p>
<h2 id="迭代器（ITERATOR）"><a href="#迭代器（ITERATOR）" class="headerlink" title="迭代器（ITERATOR）"></a>迭代器（ITERATOR）</h2><p>迭代器代表一个数据流对象，不断重复调用迭代器的next()方法可以逐次地返回数据流中的每一项，当没有更多数据可用时，next()方法会抛出异常StopIteration。此时迭代器对象已经枯竭了，之后调用next()方法都会抛出异常StopIteration。迭代器需要有一个__iter()__方法用来返回迭代器本身。因此它也是一个可迭代的对象。</p>
<h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><h3 id="1-生成器定义"><a href="#1-生成器定义" class="headerlink" title="1. 生成器定义"></a>1. 生成器定义</h3><p>在Python中，一边循环一边计算的机制，称为生成器：<code>generator</code>。<br>生成器也是一个迭代器，但是你只可以迭代他们一次，不能重复迭代，因为它并没有把所有值存储在内存中，而是实时地生成值</p>
<h3 id="2-为什么要有生成器"><a href="#2-为什么要有生成器" class="headerlink" title="2. 为什么要有生成器"></a>2. 为什么要有生成器</h3><p>列表所有数据都在内存中，如果有海量数据的话将会非常耗内存。</p>
<p>如：仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。</p>
<p>如果列表元素按照某种算法推算出来，那我们就可以在循环的过程中不断推算出后续的元素，这样就不必创建完整的list，从而节省大量的空间。</p>
<p>简单一句话：<strong>我又想要得到庞大的数据，又想让它占用空间少，那就用生成器！</strong></p>
<h3 id="3-如何创建生成器"><a href="#3-如何创建生成器" class="headerlink" title="3. 如何创建生成器"></a>3. 如何创建生成器</h3><ul>
<li><p>通过()生成，</p>
<p>只要把一个列表生成式的<code>[]</code>改成<code>()</code>，就创建了一个generator：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>L = [x * x <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>L</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span>, <span class="number">36</span>, <span class="number">49</span>, <span class="number">64</span>, <span class="number">81</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>g = (x * x <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">10</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>g</span><br><span class="line">&lt;generator object &lt;genexpr&gt; at <span class="number">0x1022ef630</span>&gt;</span><br></pre></td></tr></table></figure>

<p>创建<code>L</code>和<code>g</code>的区别仅在于最外层的<code>[]</code>和<code>()</code>，<code>L</code>是一个list，而<code>g</code>是一个generator。</p>
<ul>
<li>使用<code>yield</code>关键字生成</li>
</ul>
<p>如果一个函数中包含<code>yield</code>关键字，那么这个函数就不再是一个普通函数，而是一个generator。调用函数就是创建了一个生成器（generator）对象。如果我们想定义一个自己的生成器函数怎么办？用return好像不行。没关系，python有yield的关键词。其作用和return的功能差不多，就是返回一个值给调用者，只不过有yield的函数返回值后函数依然保持调用yield时的状态，当下次调用的时候，在原先的基础上继续执行代码，直到遇到下一个yield或者满足结束条件结束函数为止。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> <span class="number">2</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> <span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = test()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t</span><br><span class="line">&lt;generator object test at <span class="number">0x7f3da9d00e08</span>&gt;</span><br></pre></td></tr></table></figure>



<h3 id="4-生成器的调用"><a href="#4-生成器的调用" class="headerlink" title="4. 生成器的调用"></a>4. 生成器的调用</h3><ol>
<li><p>for循环：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> gen:</span><br><span class="line">    print(item)</span><br></pre></td></tr></table></figure>
</li>
<li><p>next：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(next(gen))<span class="comment">#output:0</span></span><br><span class="line">print(next(gen))<span class="comment">#output:1</span></span><br><span class="line">print(next(gen))<span class="comment">#output:2</span></span><br><span class="line">print(next(gen))<span class="comment">#output:3</span></span><br><span class="line">print(next(gen))<span class="comment">#output:4</span></span><br><span class="line">print(next(gen))<span class="comment">#output:Traceback (most recent call last):StopIteration</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>从第一个用for的调用方式我们可以知道生成器是可迭代的。更准确的说法是他就是个迭代器。<br>我们可以验证一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Iterable, Iterator</span><br><span class="line">print(isinstance(gen, Iterable))<span class="comment">#output:True</span></span><br><span class="line">print(isinstance(gen, Iterator))<span class="comment">#output:True</span></span><br></pre></td></tr></table></figure>



<h3 id="4-生成器的工作原理"><a href="#4-生成器的工作原理" class="headerlink" title="4. 生成器的工作原理"></a>4. 生成器的工作原理</h3><p>（1）生成器(generator)能够迭代的关键是它有一个<code>next()</code>方法，</p>
<p>　　工作原理就是通过**重复调用next()**方法，直到捕获一个异常。</p>
<p>（2）带有<code>yield</code>的函数不再是一个普通函数，而是一个生成器<code>generator</code>。</p>
<p>　　可用<code>next()</code>调用生成器对象来取值。next 两种方式 <code>t.__next__()</code> | <code>next(t)</code>。</p>
<p>　　可用<code>for</code>循环获取返回值（每执行一次，取生成器里面一个值）</p>
<p>　　（基本上不会用<code>next()</code>来获取下一个返回值，而是直接使用<code>for</code>循环来迭代）。</p>
<p>（3）<code>yield</code>相当于<code>return</code>返回一个值，并且记住这个返回的位置，下次迭代时，代码从yield的下一条语句开始执行。</p>
<p>（4）<code>.send()</code>和<code>next()</code>一样，都能让生成器继续往下走一步（下次遇到yield停），但<code>send()</code>能传一个值，这个值作为<code>yield</code>表达式整体的结果</p>
<p>　　——换句话说，就是send可以强行修改上一个yield表达式值。比如函数中有一个yield赋值，a = yield 5，第一次迭代到这里会返回5，a还没有赋值。第二次迭代时，使用.send(10)，那么，就是强行修改yield 5表达式的值为10，本来是5的，那么a=10</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line"><span class="meta">... </span>    i = <span class="number">0</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">while</span> i &lt; <span class="number">5</span>:</span><br><span class="line"><span class="meta">... </span>        temp = <span class="keyword">yield</span> i</span><br><span class="line"><span class="meta">... </span>        print(temp)</span><br><span class="line"><span class="meta">... </span>        i += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = test()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.__next__()</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.__next__()</span><br><span class="line"><span class="literal">None</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.__next__()</span><br><span class="line"><span class="literal">None</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.send(<span class="string">&quot;10&quot;</span>)</span><br><span class="line"><span class="number">10</span></span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>关于为何第二次a.<strong>next</strong>()有None输出的问题，可以简单的理解为：a.<strong>next</strong>()和a.send(None)是等价的，或者这么说： <code>return i</code>这个表达式的返回值是None, temp = yiled i可以理解为： temp = return i； 因为程序中遇到return，方法就结束，所以temp = return i = None. 当然这样描述是不准确的，只为理解。</p>
<p>生成器仅仅保存了一套生成数值的算法，并且没有让这个算法现在就开始执行，而是我什么时候调它，它什么时候开始计算一个新的值，并给你返回。</p>
<blockquote>
<p>参考 <a href="https://blog.csdn.net/SL_World/article/details/86507872">https://blog.csdn.net/SL_World/article/details/86507872</a></p>
</blockquote>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>yield</tag>
      </tags>
  </entry>
  <entry>
    <title>协程</title>
    <url>/2020/10/21/%E5%8D%8F%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h1><p>协程，又称微线程，纤程。英文名Coroutine。</p>
<p>那么为什么需要协程？</p>
<h2 id="引出问题"><a href="#引出问题" class="headerlink" title="引出问题"></a>引出问题</h2><ul>
<li>同步编程的并发性不高</li>
<li>多进程编程效率受CPU核数限制，当任务数量远大于CPU核数时，执行效率会降低。</li>
<li>多线程编程需要线程之间的通信，而且需要锁机制来防止共享变量被不同线程乱改，而且由于Python中的GIL(全局解释器锁)，所以实际上也无法做到真正的并行。</li>
</ul>
<a id="more"></a>

<h2 id="产生需求"><a href="#产生需求" class="headerlink" title="产生需求"></a>产生需求</h2><ul>
<li>可不可以采用同步的方式来编写异步功能代码？</li>
<li>能不能只用一个单线程就能做到不同任务间的切换？这样就没有了线程切换的时间消耗，也不用使用锁机制来削弱多任务并发效率！</li>
<li>对于IO密集型任务，可否有更高的处理方式来节省CPU等待时间？</li>
</ul>
<p>所以协程应运而生。此外，多进程和多线程是内核级别的程序，而协程是函数级别的程序，是可以通过程序员进行调用的。</p>
<p>以下是协程特性的总结：<br>协程 | 属性<br>—|—<br>所需线程 | 单线程(因为仅定义一个loop，所有event均在一个loop中)<br>编程方式 |同步<br>实现效果 | 异步<br>是否需要锁机制 | 否<br>程序级别 | 函数级<br>实现机制 | 事件循环＋协程<br>总耗时 | 最耗时事件的时间<br>应用场 | IO密集型任务等</p>
<h1 id="协程与子程序"><a href="#协程与子程序" class="headerlink" title="协程与子程序"></a>协程与子程序</h1><p>协程的概念很早就提出来了，但直到最近几年才在某些语言（如Lua）中得到广泛应用。</p>
<p>子程序，或者称为函数，在所有语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。</p>
<p>所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。</p>
<p>子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。</p>
<p>协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。<br>注意，在一个子程序中中断，去执行其他子程序，不是函数调用，有点类似CPU的中断。比如子程序A、B：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def A():</span><br><span class="line">    print(&#39;1&#39;)</span><br><span class="line">    print(&#39;2&#39;)</span><br><span class="line">    print(&#39;3&#39;)</span><br><span class="line"></span><br><span class="line">def B():</span><br><span class="line">    print(&#39;x&#39;)</span><br><span class="line">    print(&#39;y&#39;)</span><br><span class="line">    print(&#39;z&#39;)</span><br></pre></td></tr></table></figure>
<p>假设由协程执行，在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A，结果可能是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">x</span><br><span class="line">y</span><br><span class="line">3</span><br><span class="line">z</span><br></pre></td></tr></table></figure>

<p>但是在A中是没有调用B的，所以协程的调用比函数调用理解起来要难一些。</p>
<p>看起来A、B的执行有点像多线程，但协程的特点在于是一个线程执行，那和多线程比，协程有何优势？</p>
<h2 id="协程的优势"><a href="#协程的优势" class="headerlink" title="协程的优势"></a>协程的优势</h2><ul>
<li><p>最大的优势就是协程极<strong>高的执行效率</strong>。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。</p>
</li>
<li><p>第二大优势就是<strong>不需要多线程的锁机制</strong>，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。</p>
</li>
</ul>
<p>因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。</p>
<h2 id="协程的劣势"><a href="#协程的劣势" class="headerlink" title="协程的劣势"></a>协程的劣势</h2><ul>
<li>无法利用多核资源：协程的本质是个单线程,它不能同时将 单个CPU 的多个核用上,协程需要和进程配合才能运行在多CPU上.最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。</li>
<li>进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序</li>
</ul>
<h2 id="协程与generator"><a href="#协程与generator" class="headerlink" title="协程与generator"></a>协程与generator</h2><p>Python对协程的支持是通过generator实现的。有关generator请参看yield一节相关记录。</p>
<p>在generator中，我们不但可以通过for循环来迭代，还可以不断调用next()函数获取由yield语句返回的下一个值。</p>
<p>但是Python的yield不但可以返回一个值，它还可以接收调用者发出的参数。</p>
<p>来看例子：</p>
<p>传统的生产者-消费者模型是一个线程写消息，一个线程取消息，通过锁机制控制队列和等待，但一不小心就可能死锁。</p>
<p>如果改用协程，生产者生产消息后，直接通过yield跳转到消费者开始执行，待消费者执行完毕后，切换回生产者继续生产，效率极高：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def consumer():</span><br><span class="line">    r &#x3D; &#39;&#39;</span><br><span class="line">    while True:</span><br><span class="line">        n &#x3D; yield r</span><br><span class="line">        if not n:</span><br><span class="line">            return</span><br><span class="line">        print(&#39;[CONSUMER] Consuming %s...&#39; % n)</span><br><span class="line">        r &#x3D; &#39;200 OK&#39;</span><br><span class="line"></span><br><span class="line">def produce(c):</span><br><span class="line">    c.send(None)</span><br><span class="line">    n &#x3D; 0</span><br><span class="line">    while n &lt; 5:</span><br><span class="line">        n &#x3D; n + 1</span><br><span class="line">        print(&#39;[PRODUCER] Producing %s...&#39; % n)</span><br><span class="line">        r &#x3D; c.send(n)</span><br><span class="line">        print(&#39;[PRODUCER] Consumer return: %s&#39; % r)</span><br><span class="line">    c.close()</span><br><span class="line"></span><br><span class="line">c &#x3D; consumer()</span><br><span class="line">produce(c)</span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[PRODUCER] Producing 1...</span><br><span class="line">[CONSUMER] Consuming 1...</span><br><span class="line">[PRODUCER] Consumer return: 200 OK</span><br><span class="line">[PRODUCER] Producing 2...</span><br><span class="line">[CONSUMER] Consuming 2...</span><br><span class="line">[PRODUCER] Consumer return: 200 OK</span><br><span class="line">[PRODUCER] Producing 3...</span><br><span class="line">[CONSUMER] Consuming 3...</span><br><span class="line">[PRODUCER] Consumer return: 200 OK</span><br><span class="line">[PRODUCER] Producing 4...</span><br><span class="line">[CONSUMER] Consuming 4...</span><br><span class="line">[PRODUCER] Consumer return: 200 OK</span><br><span class="line">[PRODUCER] Producing 5...</span><br><span class="line">[CONSUMER] Consuming 5...</span><br><span class="line">[PRODUCER] Consumer return: 200 OK</span><br></pre></td></tr></table></figure>

<p>注意到consumer函数是一个generator，把一个consumer传入produce后：</p>
<ul>
<li>首先调用c.send(None)启动生成器；</li>
<li>然后，一旦生产了东西，通过c.send(n)切换到consumer执行；</li>
<li>consumer通过yield拿到消息，处理，又通过yield把结果传回；</li>
<li>produce拿到consumer处理的结果，继续生产下一条消息；</li>
<li>produce决定不生产了，通过c.close()关闭consumer，整个过程结束。</li>
</ul>
<p>整个流程无锁，由一个线程执行，produce和consumer协作完成任务，所以称为“协程”，而非线程的抢占式多任务。</p>
<p>最后套用Donald Knuth的一句话总结协程的特点：</p>
<blockquote>
<p>“子程序就是协程的一种特例。”</p>
</blockquote>
<h1 id="发展历程"><a href="#发展历程" class="headerlink" title="发展历程"></a>发展历程</h1><p>Python中的协程经历了很长的一段发展历程。</p>
<ul>
<li>最初的生成器yield和send()语法</li>
<li>然后在Python3.4中加入了asyncio模块，引入@asyncio.coroutine装饰器和yield from语法</li>
<li>在Python3.5上又提供了async/await语法</li>
<li>的Python3.6中asynico也由临时版改为了稳定版</li>
</ul>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>协程</tag>
        <tag>Coroutine</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql大小写敏感问题</title>
    <url>/2020/10/20/%E8%A7%A3%E5%86%B3mysql%E5%A4%A7%E5%B0%8F%E5%86%99%E4%B8%8D%E6%95%8F%E6%84%9F%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Mysql/MariaDB 默认是大小写不敏感的，有时会比较影响业务，我们期望能够大小写敏感。</p>
<a id="more"></a>

<h1 id="问题来源"><a href="#问题来源" class="headerlink" title="问题来源"></a>问题来源</h1><p>python开发过程中会使用sqlalchemy 来做 ORM，但是发现常规做法会出现查询语句对查询条件大小写不敏感问题，比如：</p>
<blockquote>
<p><code>session.query(desktop_pool)filter_by(name=&#39;b3&#39;).one_or_none()</code><br><code>session.query(desktop_pool)filter_by(name=&#39;B3&#39;).one_or_none()</code></p>
</blockquote>
<p>查询的结果是一样的。这样对有些业务就会造成困扰， 那么怎么做到查询时能够 <strong>大小写敏感</strong> 呢</p>
<h1 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h1><ol>
<li>首先想到是不是sqlalchemy本身的问题对大小写不敏感，查询sqlalchemy 中对字段的定义，比如name字段：</li>
</ol>
<blockquote>
<p>name = Column(“name”, String(20), nullable=False,doc=”桌面池的名称”)</p>
</blockquote>
<p>查看sqlalchemy对String()方法定义：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class String(Concatenable, TypeEngine):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;The base for all string and character types.</span><br><span class="line"></span><br><span class="line">    In SQL, corresponds to VARCHAR.  Can also take Python unicode objects</span><br><span class="line">    and encode to the database&#39;s encoding in bind params (and the reverse for</span><br><span class="line">    result sets.)</span><br><span class="line"></span><br><span class="line">    The &#96;length&#96; field is usually required when the &#96;String&#96; type is</span><br><span class="line">    used within a CREATE TABLE statement, as VARCHAR requires a length</span><br><span class="line">    on most databases.</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    __visit_name__ &#x3D; &#39;string&#39;</span><br><span class="line"></span><br><span class="line">    def __init__(self, length&#x3D;None, collation&#x3D;None,</span><br><span class="line">                 convert_unicode&#x3D;False,</span><br><span class="line">                 unicode_error&#x3D;None,</span><br><span class="line">                 _warn_on_bytestring&#x3D;False</span><br><span class="line">                 ):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Create a string-holding type.</span><br><span class="line"></span><br><span class="line">        :param length: optional, a length for the column for use in</span><br><span class="line">          DDL and CAST expressions.  May be safely omitted if no &#96;&#96;CREATE</span><br><span class="line">          TABLE&#96;&#96; will be issued.  Certain databases may require a</span><br><span class="line">          &#96;&#96;length&#96;&#96; for use in DDL, and will raise an exception when</span><br><span class="line">          the &#96;&#96;CREATE TABLE&#96;&#96; DDL is issued if a &#96;&#96;VARCHAR&#96;&#96;</span><br><span class="line">          with no length is included.  Whether the value is</span><br><span class="line">          interpreted as bytes or characters is database specific.</span><br><span class="line"></span><br><span class="line">        :param collation: Optional, a column-level collation for</span><br><span class="line">          use in DDL and CAST expressions.  Renders using the</span><br><span class="line">          COLLATE keyword supported by SQLite, MySQL, and PostgreSQL.</span><br><span class="line">          E.g.::</span><br><span class="line"></span><br><span class="line">            &gt;&gt;&gt; from sqlalchemy import cast, select, String</span><br><span class="line">            &gt;&gt;&gt; print select([cast(&#39;some string&#39;, String(collation&#x3D;&#39;utf8&#39;))])</span><br><span class="line">            SELECT CAST(:param_1 AS VARCHAR COLLATE utf8) AS anon_1</span><br><span class="line"></span><br><span class="line">          .. versionadded:: 0.8 Added support for COLLATE to all</span><br><span class="line">             string types.</span><br><span class="line"></span><br><span class="line">        ...其他代码...</span><br></pre></td></tr></table></figure>
<p>发现有一个collation属性可以设置，并且可以修改字段的DDL定义，也许可以试一下。<br>2. 在搜索引擎搜索<code>sqlalchemy 大小写敏感</code>问题，发现几个关键字：collation、binary<br>3. 查找<a href="https://www.osgeo.cn/sqlalchemy/core/type_basics.html">官方文档</a>，用关键字collation、binary搜索，在最后发现这样一段：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from sqlalchemy.dialects.mysql import VARCHAR, TEXT</span><br><span class="line"></span><br><span class="line">table &#x3D; Table(&#39;foo&#39;, meta,</span><br><span class="line">    Column(&#39;col1&#39;, VARCHAR(200, collation&#x3D;&#39;binary&#39;)),</span><br><span class="line">    Column(&#39;col2&#39;, TEXT(charset&#x3D;&#39;latin1&#39;))</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这样设置本质上是修改mysql属性，可能意味着 大小写敏感的问题不在 sqlalchemy， 而在mysql<br>4. 搜索引擎搜索<code>mysql大小写敏感</code>, 有以下结果：</p>
<ol>
<li>设置mysql大小写敏感参数<br><code>lower_case_table_names=0</code> 表名存储为给定的大小和比较是区分大小写的<br><code>lower_case_table_names = 1</code> 表名存储在磁盘是小写的，但是比较的时候是不区分大小写<br><code>lower_case_table_names=2</code> 表名存储为给定的大小写但是比较的时候是小写的<br><code>unix,linux下lower_case_table_names</code>默认值为 0 .Windows下默认值是 1 .Mac OS X下默认值是<br>查看mysql配置发现<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; show variables like &#39;lower_case%&#39;;</span><br><span class="line">+------------------------+-------+</span><br><span class="line">| Variable_name          | Value |</span><br><span class="line">+------------------------+-------+</span><br><span class="line">| lower_case_file_system | OFF   |</span><br><span class="line">| lower_case_table_names | 0     |</span><br><span class="line">+------------------------+-------+</span><br></pre></td></tr></table></figure>
我们的mysql 配置是对的，无需修改<ol start="2">
<li>设置表或行的collation，使其为binary或case sensitive<br>collate规则：   </li>
</ol>
*_bin: 表示的是binary case sensitive collation，也就是说是区分大小写的<br>*_cs: case sensitive collation，区分大小写<br>*_ci: case insensitive collation，不区分大小写<br>查看mysql的默认collation   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; select * from information_schema.collations where IS_DEFAULT&#x3D;&#39;Yes&#39; and COLLATION_NAME like &#39;utf8%&#39;;</span><br><span class="line">+--------------------+--------------------+----+------------+-------------+---------+</span><br><span class="line">| COLLATION_NAME     | CHARACTER_SET_NAME | ID | IS_DEFAULT | IS_COMPILED | SORTLEN |</span><br><span class="line">+--------------------+--------------------+----+------------+-------------+---------+</span><br><span class="line">| utf8_general_ci    | utf8               | 33 | Yes        | Yes         |       1 |</span><br><span class="line">| utf8mb4_general_ci | utf8mb4            | 45 | Yes        | Yes         |       1 |</span><br><span class="line">+--------------------+--------------------+----+------------+-------------+---------+</span><br></pre></td></tr></table></figure>
我们一般使用utf8编码的数据库，所以只关注utf8、utf8mb4编码的排序规则（collation）<br>按照collate规则分析<code>utf8_general_ci</code>是ci结尾，所以是不区分大小写的。<br>然后查看我们自己的数据库：   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; select * from information_schema.SCHEMATA where SCHEMA_NAME&#x3D;&#39;xview&#39;;</span><br><span class="line">+--------------+-------------+----------------------------+------------------------+----------+</span><br><span class="line">| CATALOG_NAME | SCHEMA_NAME | DEFAULT_CHARACTER_SET_NAME | DEFAULT_COLLATION_NAME | SQL_PATH |</span><br><span class="line">+--------------+-------------+----------------------------+------------------------+----------+</span><br><span class="line">| def          | xview       | utf8                       | utf8_general_ci               | NULL     |</span><br><span class="line">+--------------+-------------+----------------------------+------------------------+----------+</span><br></pre></td></tr></table></figure>
查看表：   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; select TABLE_SCHEMA, TABLE_NAME, TABLE_COLLATION from information_schema.tables where TABLE_NAME&#x3D;&#39;desktop_pool&#39;;</span><br><span class="line">+--------------+--------------+-----------------+</span><br><span class="line">| TABLE_SCHEMA | TABLE_NAME   | TABLE_COLLATION |</span><br><span class="line">+--------------+--------------+-----------------+</span><br><span class="line">| xview        | desktop_pool | utf8_general_ci |</span><br><span class="line">+--------------+--------------+-----------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure>
查看字段： <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; select TABLE_SCHEMA, TABLE_NAME, COLLATION_NAME  from information_schema.columns where TABLE_NAME&#x3D;&#39;desktop_pool&#39; and COLUMN_NAME&#x3D;&#39;name&#39;;</span><br><span class="line">+--------------+--------------+-----------------+</span><br><span class="line">| TABLE_SCHEMA | TABLE_NAME   | COLLATION_NAME  |</span><br><span class="line">+--------------+--------------+-----------------+</span><br><span class="line">| xview        | desktop_pool | utf8_general_ci |</span><br><span class="line">+--------------+--------------+-----------------+</span><br></pre></td></tr></table></figure>
<strong>至此，我们已经找到根本原因是：字段设置的排序规则utf8_general_ci不区分大小写。</strong></li>
</ol>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>查询<a href="https://mariadb.com/kb/zh-cn/setting-character-sets-and-collations/">mariadb文档</a>中有关排序规则设置可以知道:   </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">在MariaDB中，默认的字符集character set为latin1，默认的排序规则为latin1_swedish_ci(但不同的发行版可能会不同，例如Differences in MariaDB in Debian)。</span><br><span class="line">字符集和排序规则都可以**从server端一直指定到字段级别**，client到server连接时也可以指定。**</span><br><span class="line">当修改字符集但却没有指定排序规则时，将总是使用字符集的默认排序规则**。</span><br><span class="line"></span><br><span class="line">**字符集和排序规则总是级联向下的，所以当没有为字段指定排序规则时，将查找表的排序规则，同样对于表来说会上查到数据库，对数据库来说会上查到server级**。</span><br><span class="line">因此，可以使用极细粒度的字符集和排序规则来控制控制你的数据。</span><br></pre></td></tr></table></figure>
<p>所以，为了能够区分大小写，请做以下配置：</p>
<ol>
<li>修改mysql/MariaDB的配置文件：<code>/etc/mysql/mariadb.conf.d/50-server.cnf</code>修改配置项：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">character-set-server  &#x3D; utf8</span><br><span class="line">collation-server      &#x3D; utf8_bin</span><br></pre></td></tr></table></figure></li>
<li>创建数据库的时候最好指定排序规则：<code>create database xview character set utf8 collate utf8_bin;</code></li>
<li>如果数据库已经存在，可以使用<code>alert</code>命令进行修改，参看<a href="https://mariadb.com/kb/zh-cn/setting-character-sets-and-collations/">mariadb文档</a></li>
<li>你可以试试sqlalchemy用法，设置字段：<code>name = Column(&quot;name&quot;, String(20, collation=&#39;binary&#39;), nullable=False, doc=&quot;桌面池的名称&quot;)</code></li>
</ol>
<p><strong>以上</strong><br><strong>至此MySQL大小写问题搞定！</strong></p>
<h1 id="遗留问题"><a href="#遗留问题" class="headerlink" title="遗留问题"></a>遗留问题</h1><p>查看mysql的可用的utf8编码的排序规则，其中区分大小写的只有utf8_bin/utf8mb4_bin/utf8mb4_nopad_bin/utf8_nopad_bin 没有 utf8_xxx_cs 很是神奇！</p>
]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>大小写敏感</tag>
      </tags>
  </entry>
  <entry>
    <title>缓存穿透，缓存击穿，缓存雪崩</title>
    <url>/2020/10/19/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%EF%BC%8C%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%EF%BC%8C%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>设计一个缓存系统，不得不要考虑的问题就是：缓存穿透、缓存击穿与失效时的雪崩效应。</p>
<a id="more"></a>

<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><ul>
<li><p>描述<br>缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。</p>
</li>
<li><p>解决方案<br>有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。</p>
</li>
</ul>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><ul>
<li><p>描述<br>缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。</p>
</li>
<li><p>解决方案<br>缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</p>
</li>
</ul>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><ul>
<li><p>描述<br>对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。<br>缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。</p>
</li>
<li><p>解决方案</p>
</li>
</ul>
<ol>
<li>使用互斥锁(mutex key)<br>业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。<br>SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。在redis2.6.1之前版本未实现setnx的过期时间，所以这里给出两种版本代码参考：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//2.6.1前单机版本锁</span></span><br><span class="line"><span class="function">String <span class="title">get</span><span class="params">(String key)</span> </span>&#123; </span><br><span class="line">   String value = redis.get(key); </span><br><span class="line">   <span class="keyword">if</span> (value  == <span class="keyword">null</span>) &#123;  </span><br><span class="line">    <span class="keyword">if</span> (redis.setnx(key_mutex, <span class="string">&quot;1&quot;</span>)) &#123;  </span><br><span class="line">        <span class="comment">// 3 min timeout to avoid mutex holder crash  </span></span><br><span class="line">        redis.expire(key_mutex, <span class="number">3</span> * <span class="number">60</span>)  </span><br><span class="line">        value = db.get(key);  </span><br><span class="line">        redis.set(key, value);  </span><br><span class="line">        redis.delete(key_mutex);  </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">        <span class="comment">//其他线程休息50毫秒后重试  </span></span><br><span class="line">        Thread.sleep(<span class="number">50</span>);  </span><br><span class="line">        get(key);  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
最新版本代码：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">(key)</span> </span>&#123;</span><br><span class="line">      String value = redis.get(key);</span><br><span class="line">      <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123; <span class="comment">//代表缓存值过期</span></span><br><span class="line">          <span class="comment">//设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db</span></span><br><span class="line">          <span class="keyword">if</span> (redis.setnx(key_mutex, <span class="number">1</span>, <span class="number">3</span> * <span class="number">60</span>) == <span class="number">1</span>) &#123;  <span class="comment">//代表设置成功</span></span><br><span class="line">               value = db.get(key);</span><br><span class="line">                      redis.set(key, value, expire_secs);</span><br><span class="line">                      redis.del(key_mutex);</span><br><span class="line">              &#125; <span class="keyword">else</span> &#123;  <span class="comment">//这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可</span></span><br><span class="line">                      sleep(<span class="number">50</span>);</span><br><span class="line">                      get(key);  <span class="comment">//重试</span></span><br><span class="line">              &#125;</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              <span class="keyword">return</span> value;      </span><br><span class="line">          &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
memcache代码：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (memcache.get(key) == <span class="keyword">null</span>) &#123;  </span><br><span class="line">    <span class="comment">// 3 min timeout to avoid mutex holder crash  </span></span><br><span class="line">    <span class="keyword">if</span> (memcache.add(key_mutex, <span class="number">3</span> * <span class="number">60</span> * <span class="number">1000</span>) == <span class="keyword">true</span>) &#123;  </span><br><span class="line">        value = db.get(key);  </span><br><span class="line">        memcache.set(key, value);  </span><br><span class="line">        memcache.delete(key_mutex);  </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">        sleep(<span class="number">50</span>);  </span><br><span class="line">        retry();  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li>
<li>“提前”使用互斥锁(mutex key)：<br>在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。伪代码如下：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">v = memcache.get(key);  </span><br><span class="line"><span class="keyword">if</span> (v == <span class="keyword">null</span>) &#123;  </span><br><span class="line">    <span class="keyword">if</span> (memcache.add(key_mutex, <span class="number">3</span> * <span class="number">60</span> * <span class="number">1000</span>) == <span class="keyword">true</span>) &#123;  </span><br><span class="line">        value = db.get(key);  </span><br><span class="line">        memcache.set(key, value);  </span><br><span class="line">        memcache.delete(key_mutex);  </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">        sleep(<span class="number">50</span>);  </span><br><span class="line">        retry();  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">    <span class="keyword">if</span> (v.timeout &lt;= now()) &#123;  </span><br><span class="line">        <span class="keyword">if</span> (memcache.add(key_mutex, <span class="number">3</span> * <span class="number">60</span> * <span class="number">1000</span>) == <span class="keyword">true</span>) &#123;  </span><br><span class="line">            <span class="comment">// extend the timeout for other threads  </span></span><br><span class="line">            v.timeout += <span class="number">3</span> * <span class="number">60</span> * <span class="number">1000</span>;  </span><br><span class="line">            memcache.set(key, v, KEY_TIMEOUT * <span class="number">2</span>);  </span><br><span class="line">  </span><br><span class="line">            <span class="comment">// load the latest value from db  </span></span><br><span class="line">            v = db.get(key);  </span><br><span class="line">            v.timeout = KEY_TIMEOUT;  </span><br><span class="line">            memcache.set(key, value, KEY_TIMEOUT * <span class="number">2</span>);  </span><br><span class="line">            memcache.delete(key_mutex);  </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">            sleep(<span class="number">50</span>);  </span><br><span class="line">            retry();  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li>
<li>“永远不过期”  </li>
<li>这里的“永远不过期”包含两层意思：</li>
</ol>
<ul>
<li>(1) 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。</li>
<li>(2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期<br>从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">String <span class="title">get</span><span class="params">(<span class="keyword">final</span> String key)</span> </span>&#123;  </span><br><span class="line">        V v = redis.get(key);  </span><br><span class="line">        String value = v.getValue();  </span><br><span class="line">        <span class="keyword">long</span> timeout = v.getTimeout();  </span><br><span class="line">        <span class="keyword">if</span> (v.timeout &lt;= System.currentTimeMillis()) &#123;  </span><br><span class="line">            <span class="comment">// 异步更新后台异常执行  </span></span><br><span class="line">            threadPool.execute(<span class="keyword">new</span> Runnable() &#123;  </span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">                    String keyMutex = <span class="string">&quot;mutex:&quot;</span> + key;  </span><br><span class="line">                    <span class="keyword">if</span> (redis.setnx(keyMutex, <span class="string">&quot;1&quot;</span>)) &#123;  </span><br><span class="line">                        <span class="comment">// 3 min timeout to avoid mutex holder crash  </span></span><br><span class="line">                        redis.expire(keyMutex, <span class="number">3</span> * <span class="number">60</span>);  </span><br><span class="line">                        String dbValue = db.get(key);  </span><br><span class="line">                        redis.set(key, dbValue);  </span><br><span class="line">                        redis.delete(keyMutex);  </span><br><span class="line">                    &#125;  </span><br><span class="line">                &#125;  </span><br><span class="line">            &#125;);  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="keyword">return</span> value;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<ol start="4">
<li>资源保护<br>采用netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。<br>四种解决方案：没有最佳只有最合适<table>
<thead>
<tr>
<th>解决方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>简单分布式互斥锁（mutex key）</td>
<td>1. 思路简单  2. 保证一致性</td>
<td>1. 代码复杂度增大  2. 存在死锁的风险  3. 存在线程池阻塞的风险</td>
</tr>
<tr>
<td>“提前”使用互斥锁</td>
<td>1. 保证一致性</td>
<td>同上</td>
</tr>
<tr>
<td>不过期(本文)</td>
<td>1. 异步构建缓存，不会阻塞线程池</td>
<td>1. 不保证一致性。  2. 代码复杂度增大(每个value都要维护一个timekey)。  3. 占用一定的内存空间(每个value都要维护一个timekey)。</td>
</tr>
<tr>
<td>资源隔离组件hystrix(本文)</td>
<td>1. hystrix技术成熟，有效保证后端。  2. hystrix监控强大。</td>
<td>1. 部分访问存在降级策略。</td>
</tr>
</tbody></table>
</li>
</ol>
<blockquote>
<p>四种方案来源网络，详文请链接：<a href="http://carlosfu.iteye.com/blog/2269687?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io">http://carlosfu.iteye.com/blog/2269687?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io</a></p>
</blockquote>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>针对业务系统，永远都是具体情况具体分析，没有最好，只有最合适。<br>最后，对于缓存系统常见的缓存满了和数据丢失问题，需要根据具体业务分析，通常我们采用LRU策略处理溢出，Redis的RDB和AOF持久化策略来保证一定情况下的数据安全。</p>
]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>缓存穿透</tag>
        <tag>缓存击穿</tag>
        <tag>缓存雪崩</tag>
      </tags>
  </entry>
  <entry>
    <title>遗留系统改造思路和方法论</title>
    <url>/2020/10/22/%E9%81%97%E7%95%99%E7%B3%BB%E7%BB%9F%E6%94%B9%E9%80%A0%E6%80%9D%E8%B7%AF%E5%92%8C%E6%96%B9%E6%B3%95%E8%AE%BA/</url>
    <content><![CDATA[<h1 id="遗留系统的定义"><a href="#遗留系统的定义" class="headerlink" title="遗留系统的定义"></a>遗留系统的定义</h1><ul>
<li>维基百科定义：遗留系统是一种旧的方法，旧的技术，旧的计算机系统或者应用。（没有反应出遗留系统的本质）</li>
<li>重新定义：是一个还在运行和使用，但已步入软件生命周期的衰老期的软件系统。它符合所谓的奶牛规则：奶牛逐渐衰老，最终无奶可挤，然而与此同时，饲养成本却在上升。</li>
</ul>
<h1 id="遗留系统产生的原因"><a href="#遗留系统产生的原因" class="headerlink" title="遗留系统产生的原因"></a>遗留系统产生的原因</h1><ol>
<li>开发人员的工作目的是为了积累经验而非构建软件</li>
<li>学习新事物很有趣</li>
<li>时尚</li>
<li>今日时尚，明日老套</li>
<li>喜新厌旧</li>
<li>不必要的依赖和过于紧密的耦合</li>
<li>不必要的复杂架构</li>
<li>编程语言中的不必要的部分</li>
<li>不限制开发人员</li>
<li>没有模块化的软件以及没有范围限制的模块<blockquote>
<p>软件应该拥有一位架构师和技术主管，长期负责保护该软件。这位架构师应该在选择技术与处理技术变更时，做出谨慎而明智的决策。这位架构师应该确保软件的模块化，还要确保每个模块只包含结构和编程语言必要的依赖性和复杂程度。从事这些模块开发的工作人员应该了解模块的范围并遵循范围要求。而这位技术主管可以主要通过代码审查以及静态分析来强制执行这些要求。</p>
</blockquote>
</li>
</ol>
<h1 id="遗留系统的特点"><a href="#遗留系统的特点" class="headerlink" title="遗留系统的特点"></a>遗留系统的特点</h1><ol>
<li>耦合严重</li>
<li>升级或者新增困难</li>
<li>代码不规范，难于阅读，复杂度高</li>
</ol>
<h1 id="改造原则"><a href="#改造原则" class="headerlink" title="改造原则"></a>改造原则</h1><ol>
<li>少修改代码</li>
<li>尽可能的不影响业务</li>
</ol>
<h1 id="实施误区"><a href="#实施误区" class="headerlink" title="实施误区"></a>实施误区</h1><p><strong>重写遗留系统</strong></p>
<p>直接重写遗留系统可行么？遇到遗留系统的改造问题时，不少人可能会首先想到一个直截了当的方案：推翻重写，用全新的系统一次性替换掉遗留系统。采用这种方式，在落地过程中总会发现种种问题，导致新修缮者模式系统无法顺利切换，旧系又无法完全替代。常见的问题有以下几种：</p>
<ol>
<li>上线困难，业务阻塞风险高：在遗留系统重写的过程中，往往会有新增需求对遗留系统的功能进行修改。在新系统未上线前，这些需求要么被阻塞，要么需要付出双倍的工作量在遗留系统和新系统上同时实现，无论哪种选择对团队都是很难接受的。</li>
<li>影响面不可控，系统改造周期长：遗留系统往往运行着关键业务或者持有核心数据，会被多个上层服务所调用。一旦决定开始重写，其影响面无法评估，需要极为小心，考虑周全，客观上会造成系统改造周期被无限期拉长。</li>
<li>学习成本高，知识传递周期长：遗留系统的改造周期越长，对系统的学习成本就会随之升高。在这个过程中随着人员的正常流失，团队对业务和技术的熟恐程度会逐渐降低，而新人需要花费更多的时间才能熟恶遗留系统改造过程中必要的知识和技术。</li>
</ol>
<blockquote>
<p>寄希望于直接重写遗留系统，进行一次性替换而解决服务改造问题是不现实的，必须探素一条能够持续可演进的道路，实现快速、低成本、影响面可控的改造效果。</p>
</blockquote>
<h1 id="遗留系统改造策略"><a href="#遗留系统改造策略" class="headerlink" title="遗留系统改造策略"></a>遗留系统改造策略</h1><h2 id="稳健策略-量力而行"><a href="#稳健策略-量力而行" class="headerlink" title="稳健策略-量力而行"></a>稳健策略-量力而行</h2><ol>
<li>项目时间有限，跨度中等，以月计</li>
<li>投入有限，预算有限</li>
<li>技术风险中等，采用成熟技术加少许新技术，难度中等</li>
<li>团队技术水平要求略高</li>
</ol>
<h2 id="激进策略"><a href="#激进策略" class="headerlink" title="激进策略"></a>激进策略</h2><ol>
<li>时间充裕跨度长，以年计</li>
<li>投入大，需要耗费高预算</li>
<li>技术风险高，采用新技术，试错成本高，难度大</li>
<li>团队技术水平要求高</li>
</ol>
<h2 id="保守策略"><a href="#保守策略" class="headerlink" title="保守策略"></a>保守策略</h2><ol>
<li>项目紧张跨度短，以周计算</li>
<li>投入少</li>
<li>局部优化，技术风险小</li>
<li>团队技术水平要求略低</li>
</ol>
<h1 id="实施方法论"><a href="#实施方法论" class="headerlink" title="实施方法论"></a>实施方法论</h1><ol>
<li><p>绞杀者模式（抽象层）：通过逐步替换而非一次性替换的方式，来保证新旧系统的平滑过渡。逐渐用新的应用程序和服务来替代特定功能。创建一个门面，拦截后端遗留系统的请求。门面将这些请求路由到旧应用程序或新服务。现有功能可以逐渐迁移到新系统，消费者可以继续使用相同的接口，不会感知到迁移的发生。</p>
<ol>
<li>考虑新系统和遗留系统之间的数据共享或者同步方式。</li>
<li>在微服务中，要确保绞杀者门面服务（即抽象层）不会出现单点故障或成为性能“瓶颈”。</li>
</ol>
<p>这种模式有助于最大限度地减少迁移的风险，并随着时间推移扩大开发工作。通过门面安全地将用户路由到正确的应用程序，可以以任何喜欢的速度向新系统添加功能，同时确保旧应用程序继续运行。随着时间的推移，功能迁移到新系统，遗留系统最终被“绞杀”，不再需要。 一旦这个过程完成，遗留系统就可以安全地退休。</p>
</li>
<li><p>修缮者模式： 就如修房或修路一样，将老旧待修缮的部分进行隔离，用新的方式对其进行单独修复。修复的同时，需保证与其他部分仍能协同功能。</p>
<p>通过识别内部的被拆模块，对其增加接口层，将旧的引用改为新接口调用；随后将接口封装为API，并将对接口的引用改为本地API调用；最后将新服务部署为新进程，调用改为真正的服务API调用。</p>
</li>
<li><p>抽象分支，同于绞杀者</p>
</li>
<li><p>防腐层：在新的应用程序和依赖于其的遗留系统之间实现装饰层或适配器层。该层转换新的应用程序和遗留系统之间的请求。 使用此模式可确保应用程序的设计不受依赖的旧系统的限制。通过在遗留系统和现代系统之间使用防腐层来隔离它们。该层转换两个系统之间的通信，允许遗留系统保持不变，同时可以避免损害现代应用程序的设计和技术方法。现代应用与防腐层之间的通信始终使用应用程序的数据模型和架构。从防腐层到遗留系统的调用都符合该系统的数据模型或方法。 防腐层包含两个系统之间转换所需的所有逻辑。该层可以作为应用程序中的组件或作为独立服务来实现。</p>
<ol>
<li>防腐层可能会增加在两个系统之间进行调用的延迟。</li>
<li>防腐层添加了必须进行管理和维护的附加服务。</li>
<li>考虑防腐层如何伸缩。</li>
<li>考虑是否需要多个防腐层。你可能希望使用不同的技术或语言将功能分解成多个服务，或者因为其它原因来分割防腐层。</li>
<li>考虑如何根据其它应用程序或服务来管理防腐层。如何将其集成到监控，发布和配置过程中？</li>
<li>确保事务和数据的一致性得到维护并可以监控。</li>
<li>考虑防腐层是否需要处理遗留和现代系统之间的所有通信，或只是功能的一个子集。</li>
<li>考虑防腐层是否是为永久性的，或者是在所有旧功能都迁移后最终退休。</li>
</ol>
</li>
<li><p>网关隔离：使用一个端点将请求按照路由分发到多个服务上去。该模式用于希望将多个服务通过一个单独的端点暴露出去，并将请求按路由分发给适当的服务时。</p>
<ol>
<li>网关服务可能会引入单点故障。确保在设计时就考虑到可用性需求。在实现时考虑可恢复性与故障容错能力。</li>
<li>网关服务可能会成为瓶颈。确保网关具有足够的性能以处理负载，并能够容易随着预期增长一致扩展。</li>
<li>对网关进行负载测试，以确保你不会为服务引入级联性故障。</li>
<li>网关路由位于第7层。可以基于IP、端口、header或URL来实现。</li>
</ol>
</li>
</ol>
<h1 id="遗留系统进行微服务拆分"><a href="#遗留系统进行微服务拆分" class="headerlink" title="遗留系统进行微服务拆分"></a>遗留系统进行微服务拆分</h1><p>48字箴言的微服务拆分核心价值观</p>
<blockquote>
<p>功能剥离，数据解耦<br>自然演进，逐步拆分<br>小步快跑，快速送代<br>灰度发布，谨慎试错<br>提质量线，还技术债<br>各方一致，过程透明</p>
</blockquote>
<h2 id="拆分方法"><a href="#拆分方法" class="headerlink" title="拆分方法"></a>拆分方法</h2><h3 id="服务拆分"><a href="#服务拆分" class="headerlink" title="服务拆分"></a>服务拆分</h3><ol>
<li>水平拆分（功能维度）</li>
<li>垂直拆分（业务维度）</li>
</ol>
<h3 id="数据库拆分"><a href="#数据库拆分" class="headerlink" title="数据库拆分"></a>数据库拆分</h3><ol>
<li>水平分表</li>
<li>垂直分库</li>
</ol>
<h2 id="拆分带来的技术挑战"><a href="#拆分带来的技术挑战" class="headerlink" title="拆分带来的技术挑战"></a>拆分带来的技术挑战</h2><ol>
<li>分布式事务数据一致性的问题</li>
<li>微服务基础设施</li>
<li>自动化运维</li>
<li>DevOps文化</li>
<li>分布式系统带来的复杂性</li>
</ol>
<h1 id="遗留系统改造技术方案"><a href="#遗留系统改造技术方案" class="headerlink" title="遗留系统改造技术方案"></a>遗留系统改造技术方案</h1><ol>
<li>基于zuul网关动态路由方案实现老系统和新系统的动态切换平滑升级，逐步改造推进。</li>
<li>前后端分离</li>
<li>跨域处理</li>
<li>统一认证授权</li>
</ol>
<h1 id="相关设计模式"><a href="#相关设计模式" class="headerlink" title="相关设计模式"></a>相关设计模式</h1><ol>
<li>模板方法模式:抽象公共业务逻辑</li>
<li>策略模式解决 if else 问题</li>
<li>观察者模式解耦</li>
</ol>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li>本文参考自网络知名开发者：二康</li>
<li><a href="https://www.progsbase.com/blog/top-10-reasons-your-software-became-legacy/">Top 10 Reasons Your Software Became Legacy</a></li>
<li><a href="https://mp.weixin.qq.com/s/Z6Tk7FMLX9PIdbcL3iyIHA">从300万行到50万行代码，遗留系统的微服务改造</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&mid=2247489784&amp;idx=1&amp;sn=632a1d86e5710a59071d22bcaeea68d0&source=41#wechat_redirect">最头疼的遗留系统该如何改造</a></li>
<li>《遗留系统重建实战》</li>
<li>《重构》</li>
<li>《代码修改的艺术》</li>
<li><a href="https://iambowen.gitbooks.io/cloud-design-pattern/content/">云设计模式</a></li>
</ul>
]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>遗留系统改造</tag>
      </tags>
  </entry>
  <entry>
    <title>FastAPI</title>
    <url>/2020/10/20/FastAPI/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>学习了一下FastAPI，感觉其实现了目前python-web需要的大部分功能，可以说是这些python web框架的集大成者。我所关注的特性如下：</p>
<ol>
<li>自动化文档。文档标准是OpenAPI，也就是swagger。目前xView项目实现了与FastAPI类似的自动化文档，但是欠缺了一点是：没有使用Pydantic这样的声明类型。request参数的构造也咩有FastAPI灵活便捷。</li>
</ol>
<a id="more"></a>

<ol start="2">
<li><p>支持websock。目前xView项目需要单独开启socket服务</p>
</li>
<li><p>支持ORM。支持集成sqlAlchemy+alembic</p>
</li>
<li><p>支持plugin方式拦截请求。在FastAPI叫MiddleWare</p>
</li>
<li><p>异步io</p>
</li>
</ol>
<p>让我惊喜的是：</p>
<ol>
<li>可以同时支持FastAPI+Django[Flask/bottle等]并存</li>
<li>可以支持root-url设置代理，这样文档生成就不会需要特别修改</li>
<li>可以设置API CallBack 文档，这样我们的API文档就会非常友好</li>
<li>集成很多MiddleWare，比如<ul>
<li>SentryMiddleware，做日志重定向并管理</li>
<li>TimingMiddleware，统计每一个API请求耗时</li>
</ul>
</li>
</ol>
<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="type-hints-类型提示"><a href="#type-hints-类型提示" class="headerlink" title="type hints(类型提示)"></a>type hints(类型提示)</h2><ul>
<li>python3.0 引入 <strong>函数注释</strong> <a href="http://www.python.org/dev/peps/pep-3107">PEP 3107</a>.这提供了注释函数参数和返回值的标准化方法。除了可以在运行时使用 <code>__annotations__</code>属性对它们进行自省外，这些注释没有附加任何语义。目的是鼓励通过元类，装饰器或框架进行实验。</li>
<li>Python3.5.0 开始支持 <strong>类型提示</strong>，见<a href="https://docs.python.org/3.5/whatsnew/3.5.html#whatsnew-pep-484">PEP 484</a>。<br>python3.0支持函数注释，但是对注释的语义没有做定义。经验表明，大多数函数注释用法都是为函数参数和返回值提供<strong>类型提示</strong>。显而易见的是，如果标准库包含基本定义和用于类型注释的工具，则对Python用户将是有益的。它的主要作用<strong>是方便开发，供IDE和各种开发工具使用</strong>，对代码运行不产生影响，运行时会过滤类型信息。<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">x: int, y:int</span>) -&gt; int:</span></span><br><span class="line">    <span class="keyword">return</span> x+y</span><br></pre></td></tr></table></figure>
运行如下命令：<br><code>print(add(1,2))</code> 和 <code>print(add(1,2))</code> 结果分别是：<code>3</code> 和 <code>helloworld</code>。<br>也就是说，python3.5版本的type hint就是一个文档标识作用，便于IDE编辑和代码维护，不能进行代码层面的自动校验。</li>
<li>python3.6 开始支持<strong>变量注释</strong>语法，见 <a href="https://www.python.org/dev/peps/pep-0484">PEP 484</a>.与3.0/3.5不同之处是：添加了变量注释，之前版本是方法返回值注释和方法参数注释。<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">primes: List[int] = []</span><br><span class="line"></span><br><span class="line">captain: str  <span class="comment"># Note: no initial value!</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Starship</span>:</span></span><br><span class="line">    stats: Dict[str, int] = &#123;&#125;</span><br></pre></td></tr></table></figure>
就像函数注释一样，Python解释器不会在变量注释中附加任何特殊含义，而仅将它们存储在__annotations__类或模块的属性中。</li>
<li>3.7 支持优化类型提示。因为引入类型提示带来了一些问题：<ul>
<li>批注只能使用当前范围内已经可用的名称，换句话说，它们不支持任何形式的正向引用；和</li>
<li>注释源代码会对Python程序的启动时间产生不利影响。<br>所以，3.7版本进行优化，使用方式是：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> annotations  <span class="comment"># 在模块中导入，Python 4.0中的默认设置</span></span><br></pre></td></tr></table></figure>
所以想要实现fastAPI的功能，需要支持python3.6+，如果需要优化类型提示需要python3.7+<br>想了解有关类型的更多信息，来自 <a href="https://mypy.readthedocs.io/en/latest/cheat_sheet_py3.html">mypy 的”速查表”</a>是不错的资源。</li>
</ul>
</li>
</ul>
<h1 id="OpenAPI与FastAPI"><a href="#OpenAPI与FastAPI" class="headerlink" title="OpenAPI与FastAPI"></a>OpenAPI与FastAPI</h1><h2 id="Request"><a href="#Request" class="headerlink" title="Request"></a>Request</h2><p>Request参数校验主要包含三种情况：</p>
<ol>
<li>请求url中的path包含的参数，比如： <code>/users/&#123;user_id&#125;</code>这样的url,user_id就是path param; </li>
<li>而形如：<code>/users?name=aaa</code>这样的url, name是query param;</li>
<li>以上2中情况多出现于GET请求，而PUT/PATCH/POST这样的请求会包含request body,body内的参数为就是第三种情况<h3 id="path-param"><a href="#path-param" class="headerlink" title="path param"></a>path param</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">read_item</span>(<span class="params">item_id: int</span>):</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;item_id&quot;</span>: item_id&#125;</span><br></pre></td></tr></table></figure>
代码如上。</li>
<li>使用pydantic声明式命名</li>
<li>数据转换，fastAPI 通过上面的类型声明,自动转换item_id为int型</li>
<li>数据校验，如果item_id不是整形数字，比如字符串或者浮点型，都将报错</li>
<li>API 标注和自动生成的文档<h3 id="query-param"><a href="#query-param" class="headerlink" title="query param"></a>query param</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line">fake_items_db = [&#123;<span class="string">&quot;item_name&quot;</span>: <span class="string">&quot;Foo&quot;</span>&#125;, &#123;<span class="string">&quot;item_name&quot;</span>: <span class="string">&quot;Bar&quot;</span>&#125;, &#123;<span class="string">&quot;item_name&quot;</span>: <span class="string">&quot;Baz&quot;</span>&#125;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(&quot;/items/&quot;)</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">read_item</span>(<span class="params">skip: int = <span class="number">0</span>, limit: int = <span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> fake_items_db[skip : skip + limit]</span><br></pre></td></tr></table></figure>
代码如上，如果请求的url如：<code>http://127.0.0.1:8000/items/?skip=0&amp;limit=10</code>,那么skip：对应的值为 0，limit：对应的值为 10。<br>和path param 一样，你可以得到：</li>
</ol>
<ul>
<li>数据”解析”</li>
<li>数据校验</li>
<li>自动生成文档</li>
</ul>
<h3 id="path-param-query-param"><a href="#path-param-query-param" class="headerlink" title="path param + query param"></a>path param + query param</h3><p>你可以同时声明多个路径参数和查询参数，FastAPI 能够识别它们。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from typing import Optional</span><br><span class="line"></span><br><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;&#x2F;users&#x2F;&#123;user_id&#125;&#x2F;items&#x2F;&#123;item_id&#125;&quot;)</span><br><span class="line">async def read_user_item(</span><br><span class="line">    user_id: int, item_id: str, q: Optional[str] &#x3D; None, short: bool &#x3D; False</span><br><span class="line">):</span><br><span class="line">    item &#x3D; &#123;&quot;item_id&quot;: item_id, &quot;owner_id&quot;: user_id&#125;</span><br><span class="line">    if q:</span><br><span class="line">        item.update(&#123;&quot;q&quot;: q&#125;)</span><br><span class="line">    if not short:</span><br><span class="line">        item.update(</span><br><span class="line">            &#123;&quot;description&quot;: &quot;This is an amazing item that has a long description&quot;&#125;</span><br><span class="line">        )</span><br><span class="line">    return item</span><br></pre></td></tr></table></figure>
<p>以上无论是 path param， 还是query param，还是2者并存，都可以设置参数为：</p>
<ul>
<li>可选/必填</li>
<li>默认值</li>
<li>参数的一些额外校验<ul>
<li>字符串参数长度(最长/最短)，比如  <code>q: Optional[str] = Query(None, max_length=50)</code></li>
<li>字符串参数正则<code>q: Optional[str] = Query(None, regex=&quot;^fixedquery$&quot;)</code> </li>
<li>数字参数范围控制，比如：大于，小于，大于等于等</li>
<li>查询参数是一个列表， 比如：<code>http://localhost:8000/items/?q=foo&amp;q=bar</code></li>
</ul>
</li>
<li>设置更多参数，可以用为OpenAPI文档，比如：<ul>
<li>title</li>
<li>description</li>
</ul>
</li>
<li>别名参数</li>
<li>弃用设置</li>
</ul>
<h3 id="Request-body"><a href="#Request-body" class="headerlink" title="Request body"></a>Request body</h3><p>需要先创建数据模型，这里的数据模型就是request的body的数据声明，</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from typing import Optional</span><br><span class="line"></span><br><span class="line">from fastapi import FastAPI</span><br><span class="line">from pydantic import BaseModel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Item(BaseModel):</span><br><span class="line">    name: str</span><br><span class="line">    description: Optional[str] &#x3D; None</span><br><span class="line">    price: float</span><br><span class="line">    tax: Optional[float] &#x3D; None</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line">@app.post(&quot;&#x2F;items&#x2F;&quot;)</span><br><span class="line">async def create_item(item: Item):</span><br><span class="line">    return item</span><br></pre></td></tr></table></figure>
<p>按照以上方式，你将得到：</p>
<ul>
<li>将请求体作为 JSON 读取。</li>
<li>转换为相应的类型（在需要时）。</li>
<li>校验数据。<br>如果数据无效，将返回一条清晰易读的错误信息，指出不正确数据的确切位置和内容。</li>
<li>将接收的数据赋值到参数 item 中。<br>由于你已经在函数中将它声明为 Item 类型，你还将获得对于所有属性及其类型的一切编辑器支持（代码补全等）。</li>
<li>为你的模型生成 JSON 模式 定义，你还可以在其他任何对你的项目有意义的地方使用它们。</li>
<li>这些模式将成为生成的 OpenAPI 模式的一部分，并且被自动化文档 UI 所使用。</li>
</ul>
<p>当然你可以随意组合query parm、path param、request body.FastAPI能够正确的识别他们。</p>
<p>如果request body是一个复杂类型，比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;item&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;Foo&quot;,</span><br><span class="line">        &quot;description&quot;: &quot;The pretender&quot;,</span><br><span class="line">        &quot;price&quot;: 42.0,</span><br><span class="line">        &quot;tax&quot;: 3.2</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;user&quot;: &#123;</span><br><span class="line">        &quot;username&quot;: &quot;dave&quot;,</span><br><span class="line">        &quot;full_name&quot;: &quot;Dave Grohl&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>你可以这么写：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from typing import Optional</span><br><span class="line"></span><br><span class="line">from fastapi import FastAPI</span><br><span class="line">from pydantic import BaseModel</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Item(BaseModel):</span><br><span class="line">    name: str</span><br><span class="line">    description: Optional[str] &#x3D; None</span><br><span class="line">    price: float</span><br><span class="line">    tax: Optional[float] &#x3D; None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class User(BaseModel):</span><br><span class="line">    username: str</span><br><span class="line">    full_name: Optional[str] &#x3D; None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.put(&quot;&#x2F;items&#x2F;&#123;item_id&#125;&quot;)</span><br><span class="line">async def update_item(item_id: int, item: Item, user: User):</span><br><span class="line">    results &#x3D; &#123;&quot;item_id&quot;: item_id, &quot;item&quot;: item, &quot;user&quot;: user&#125;</span><br><span class="line">    return results</span><br></pre></td></tr></table></figure>
<p>在以上示例中，所有的属性或者变量的声明类型都是简单类型：int/str/bool/float, 还可以有复杂类型比如：List/Set/嵌套类型，或者直接使用Optional。pydantic还提供了一些特殊领域的声明，比如：HttpUrl。</p>
<h2 id="Request-Filed"><a href="#Request-Filed" class="headerlink" title="Request Filed"></a>Request Filed</h2><p>以上request path param/query param/requet  body其实都是Pydantic 的 Field的字段的实例。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from typing import Optional</span><br><span class="line"></span><br><span class="line">from fastapi import Body, FastAPI</span><br><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Item(BaseModel):</span><br><span class="line">    name: str</span><br><span class="line">    description: Optional[str] &#x3D; Field(</span><br><span class="line">        None, title&#x3D;&quot;The description of the item&quot;, max_length&#x3D;300</span><br><span class="line">    )</span><br><span class="line">    price: float &#x3D; Field(..., gt&#x3D;0, description&#x3D;&quot;The price must be greater than zero&quot;)</span><br><span class="line">    tax: Optional[float] &#x3D; None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.put(&quot;&#x2F;items&#x2F;&#123;item_id&#125;&quot;)</span><br><span class="line">async def update_item(item_id: int, item: Item &#x3D; Body(..., embed&#x3D;True)):</span><br><span class="line">    results &#x3D; &#123;&quot;item_id&quot;: item_id, &quot;item&quot;: item&#125;</span><br><span class="line">    return results</span><br></pre></td></tr></table></figure>
<p>实际上，Query、Path 和其他你将在之后看到的类，创建的是由一个共同的 Params 类派生的子类的对象，该共同类本身又是 Pydantic 的 FieldInfo 类的子类。<br>Pydantic 的 Field 也会返回一个 FieldInfo 的实例。<br>Body 也直接返回 FieldInfo 的一个子类的对象。还有其他一些你之后会看到的类是 Body 类的子类。<br>请记住当你从 fastapi 导入 Query、Path 等对象时，他们实际上是返回特殊类的函数。</p>
<p>除了通过字段声明来控制一个属性的校验规则之外，还可以显式的指定。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Item(BaseModel):</span><br><span class="line">    name: str</span><br><span class="line">    description: Optional[str] &#x3D; None</span><br><span class="line">    price: float</span><br><span class="line">    tax: Optional[float] &#x3D; None</span><br><span class="line"></span><br><span class="line">    class Config:</span><br><span class="line">        schema_extra &#x3D; &#123;</span><br><span class="line">            &quot;example&quot;: &#123;</span><br><span class="line">                &quot;name&quot;: &quot;Foo&quot;,</span><br><span class="line">                &quot;description&quot;: &quot;A very nice Item&quot;,</span><br><span class="line">                &quot;price&quot;: 35.4,</span><br><span class="line">                &quot;tax&quot;: 3.2,</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>这里是增加了example属性，可以在openAPI 文档中看到。</p>
<h2 id="Response"><a href="#Response" class="headerlink" title="Response"></a>Response</h2><p>与request不同的是，response的参数声明式在路径装饰器.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from typing import List, Optional</span><br><span class="line"></span><br><span class="line">from fastapi import FastAPI</span><br><span class="line">from pydantic import BaseModel</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Item(BaseModel):</span><br><span class="line">    name: str</span><br><span class="line">    description: Optional[str] &#x3D; None</span><br><span class="line">    price: float</span><br><span class="line">    tax: Optional[float] &#x3D; None</span><br><span class="line">    tags: List[str] &#x3D; []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.post(&quot;&#x2F;items&#x2F;&quot;, response_model&#x3D;Item)</span><br><span class="line">async def create_item(item: Item):</span><br><span class="line">    return item</span><br></pre></td></tr></table></figure>
<p>你将得到：</p>
<ul>
<li>转换输出数据为声明类型。这里之所以把<code>response_model</code>声明放在路径装饰器上，是因为路径方法(比如上边示例的<code>create_item</code>)的返回值可能是字典/对象甚至没有返回值。使用装饰器来控制和序列化路径方法的返回值。</li>
<li>验证数据</li>
<li>响应api路径</li>
<li>自动文档</li>
</ul>
<p>fastAPI可以自动转换SqlAlchemy ORM Model 到Schema Model。这样API就可以直接返回SqlAlchemy对象，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_db():</span><br><span class="line">    db &#x3D; SessionLocal()</span><br><span class="line">    try:</span><br><span class="line">        yield db</span><br><span class="line">    finally:</span><br><span class="line">        db.close()</span><br><span class="line"></span><br><span class="line">class Item(ItemBase):</span><br><span class="line">    id: int</span><br><span class="line">    owner_id: int</span><br><span class="line"></span><br><span class="line">    class Config:</span><br><span class="line">        orm_mode &#x3D; True</span><br><span class="line"></span><br><span class="line">@app.post(&quot;&#x2F;users&#x2F;&#123;user_id&#125;&#x2F;items&#x2F;&quot;, response_model&#x3D;Item)</span><br><span class="line">def create_item_for_user(</span><br><span class="line">    user_id: int, item: Item, db: Session &#x3D; Depends(get_db)</span><br><span class="line">):</span><br><span class="line">    db_item &#x3D; models.Item(**item.dict(), owner_id&#x3D;user_id)</span><br><span class="line">    db.add(db_item)</span><br><span class="line">    db.commit()</span><br><span class="line">    db.refresh(db_item)</span><br><span class="line">    return db_item</span><br></pre></td></tr></table></figure>
<p>上例子中， <code>db_item</code>是SqlAlchemy ORM对象，response_model是schema对象。这里会自动进行转化，前提是需要schema class 定义<code>orm_mode</code>为true</p>
<h2 id="Header"><a href="#Header" class="headerlink" title="Header"></a>Header</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from typing import Optional</span><br><span class="line"></span><br><span class="line">from fastapi import FastAPI, Header</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;&#x2F;items&#x2F;&quot;)</span><br><span class="line">async def read_items(user_agent: Optional[str] &#x3D; Header(None)):</span><br><span class="line">    return &#123;&quot;User-Agent&quot;: user_agent&#125;</span><br></pre></td></tr></table></figure>
<p>需要注意的是：</p>
<ul>
<li>不区分大小写</li>
<li>header中的连字符<code>-</code>会自动换成下划线<code>_</code><h2 id="Cookie等"><a href="#Cookie等" class="headerlink" title="Cookie等"></a>Cookie等</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from typing import Optional</span><br><span class="line"></span><br><span class="line">from fastapi import Cookie, FastAPI</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;&#x2F;items&#x2F;&quot;)</span><br><span class="line">async def read_items(ads_id: Optional[str] &#x3D; Cookie(None)):</span><br><span class="line">    return &#123;&quot;ads_id&quot;: ads_id&#125;</span><br></pre></td></tr></table></figure>
<h1 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h1>FastAPi的Dependency类似于提取公共方法，然后被多处调用，原理跟装饰器差不多。比如你有如下需求：</li>
</ul>
<ol>
<li>具有共享逻辑（一次又一次地使用相同的代码逻辑）。</li>
<li>共享数据库连接。</li>
<li>强制执行安全性，身份验证，角色要求等。<br>所有这些，同时最大程度地减少了代码重复。</li>
</ol>
<p>依赖可以互相嵌套，即：子依赖</p>
<h1 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h1><p>中间件（MiddleWare）可以拦截每一个request，处理请求前和response前的一些行为。</p>
<ul>
<li>它接受应用程序中的每个请求。</li>
<li>然后，它可以对该请求执行某些操作或运行任何需要的代码。</li>
<li>然后，它传递要由应用程序其余部分（通过某些路径操作）处理的请求。</li>
<li>然后，它将获取应用程序生成的响应（通过某些路径操作）。</li>
<li>它可以对响应做出响应或运行任何需要的代码。</li>
<li>然后返回响应。<br>类似于xView bottle中的plugin。</li>
</ul>
<h1 id="ORM"><a href="#ORM" class="headerlink" title="ORM"></a>ORM</h1><p>可以使用SqlAlchemy或者peewee(peewee是一个微型的ORM框架)。并且FastAPi支持自动转化SqlAlchemy对象和schema对象。</p>
<h1 id="后台任务和Celery"><a href="#后台任务和Celery" class="headerlink" title="后台任务和Celery"></a>后台任务和Celery</h1><p>如果返回response之后要运行一些操作，可以使用后台任务。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from fastapi import BackgroundTasks, FastAPI</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def write_notification(email: str, message&#x3D;&quot;&quot;):</span><br><span class="line">    with open(&quot;log.txt&quot;, mode&#x3D;&quot;w&quot;) as email_file:</span><br><span class="line">        content &#x3D; f&quot;notification for &#123;email&#125;: &#123;message&#125;&quot;</span><br><span class="line">        email_file.write(content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.post(&quot;&#x2F;send-notification&#x2F;&#123;email&#125;&quot;)</span><br><span class="line">async def send_notification(email: str, background_tasks: BackgroundTasks):</span><br><span class="line">    background_tasks.add_task(write_notification, email, message&#x3D;&quot;some notification&quot;)</span><br><span class="line">    return &#123;&quot;message&quot;: &quot;Notification sent in the background&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>response也可以返回202，然后任务继续在后台执行。<br>与之类似的是Celery:一个分布式多任务处理队列。</p>
<h1 id="静态资源"><a href="#静态资源" class="headerlink" title="静态资源"></a>静态资源</h1><p>FastAPi也可以返回静态资源，比如：图片/文件。需要 单独安装<code>aiofiles</code>.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line">from fastapi.staticfiles import StaticFiles</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line">app.mount(&quot;&#x2F;static&quot;, StaticFiles(directory&#x3D;&quot;static&quot;), name&#x3D;&quot;static&quot;)</span><br></pre></td></tr></table></figure>
<p>mount 是指在特定路径中添加完整的“独立”应用程序，然后负责处理所有子路径。<br>这与使用APIRouter完全独立的已安装应用程序不同。主应用程序中的OpenAPI和文档不会包含mount应用程序等中的任何内容。</p>
<h1 id="子应用"><a href="#子应用" class="headerlink" title="子应用"></a>子应用</h1><p>如果需要两个独立的FastAPI应用程序，以及它们各自的独立OpenAPI和文档ui，则可以拥有一个主应用程序并“装载”一个（或多个）子应用程序。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;&#x2F;app&quot;)</span><br><span class="line">def read_main():</span><br><span class="line">    return &#123;&quot;message&quot;: &quot;Hello World from main app&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">subapi &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@subapi.get(&quot;&#x2F;sub&quot;)</span><br><span class="line">def read_sub():</span><br><span class="line">    return &#123;&quot;message&quot;: &quot;Hello World from sub API&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app.mount(&quot;&#x2F;subapi&quot;, subapi)</span><br></pre></td></tr></table></figure>
<p>子应用是以mount方式挂载到主应用中的。子应用与主应用区别之处就是文档是分开的，其他都一样。文档访问的时候，主应用默认地址： <code>http://127.0.0.1:8000/docs</code>, 子应用默认地址: <code>http://127.0.0.1:8000/subapi/docs</code></p>
<h1 id="websocket"><a href="#websocket" class="headerlink" title="websocket"></a>websocket</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from fastapi import FastAPI, WebSocket</span><br><span class="line">from fastapi.responses import HTMLResponse</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line">html &#x3D; &quot;&quot;&quot;</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;head&gt;</span><br><span class="line">        &lt;title&gt;Chat&lt;&#x2F;title&gt;</span><br><span class="line">    &lt;&#x2F;head&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">        &lt;h1&gt;WebSocket Chat&lt;&#x2F;h1&gt;</span><br><span class="line">        &lt;form action&#x3D;&quot;&quot; onsubmit&#x3D;&quot;sendMessage(event)&quot;&gt;</span><br><span class="line">            &lt;input type&#x3D;&quot;text&quot; id&#x3D;&quot;messageText&quot; autocomplete&#x3D;&quot;off&quot;&#x2F;&gt;</span><br><span class="line">            &lt;button&gt;Send&lt;&#x2F;button&gt;</span><br><span class="line">        &lt;&#x2F;form&gt;</span><br><span class="line">        &lt;ul id&#x3D;&#39;messages&#39;&gt;</span><br><span class="line">        &lt;&#x2F;ul&gt;</span><br><span class="line">        &lt;script&gt;</span><br><span class="line">            var ws &#x3D; new WebSocket(&quot;ws:&#x2F;&#x2F;localhost:8000&#x2F;ws&quot;);</span><br><span class="line">            ws.onmessage &#x3D; function(event) &#123;</span><br><span class="line">                var messages &#x3D; document.getElementById(&#39;messages&#39;)</span><br><span class="line">                var message &#x3D; document.createElement(&#39;li&#39;)</span><br><span class="line">                var content &#x3D; document.createTextNode(event.data)</span><br><span class="line">                message.appendChild(content)</span><br><span class="line">                messages.appendChild(message)</span><br><span class="line">            &#125;;</span><br><span class="line">            function sendMessage(event) &#123;</span><br><span class="line">                var input &#x3D; document.getElementById(&quot;messageText&quot;)</span><br><span class="line">                ws.send(input.value)</span><br><span class="line">                input.value &#x3D; &#39;&#39;</span><br><span class="line">                event.preventDefault()</span><br><span class="line">            &#125;</span><br><span class="line">        &lt;&#x2F;script&gt;</span><br><span class="line">    &lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;&#x2F;&quot;)</span><br><span class="line">async def get():</span><br><span class="line">    return HTMLResponse(html)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.websocket(&quot;&#x2F;ws&quot;)</span><br><span class="line">async def websocket_endpoint(websocket: WebSocket):</span><br><span class="line">    await websocket.accept()</span><br><span class="line">    while True:</span><br><span class="line">        data &#x3D; await websocket.receive_text()</span><br><span class="line">        await websocket.send_text(f&quot;Message text was: &#123;data&#125;&quot;)</span><br></pre></td></tr></table></figure>

<h1 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h1><p>您可以定义在应用程序启动之前或关闭应用程序时需要执行的事件处理程序（函数）。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line">items &#x3D; &#123;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.on_event(&quot;startup&quot;)</span><br><span class="line">async def startup_event():</span><br><span class="line">    items[&quot;foo&quot;] &#x3D; &#123;&quot;name&quot;: &quot;Fighters&quot;&#125;</span><br><span class="line">    items[&quot;bar&quot;] &#x3D; &#123;&quot;name&quot;: &quot;Tenders&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.on_event(&quot;shutdown&quot;)</span><br><span class="line">def shutdown_event():</span><br><span class="line">    with open(&quot;log.txt&quot;, mode&#x3D;&quot;a&quot;) as log:</span><br><span class="line">        log.write(&quot;Application shutdown&quot;)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">@app.get(&quot;&#x2F;items&#x2F;&#123;item_id&#125;&quot;)</span><br><span class="line">async def read_items(item_id: str):</span><br><span class="line">    return items[item_id]</span><br></pre></td></tr></table></figure>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>fastAPI测试基于pytest. fastAPi继承了starlette的testClient, testClient又包装了requests.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line">from fastapi.testclient import TestClient</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;&#x2F;&quot;)</span><br><span class="line">async def read_main():</span><br><span class="line">    return &#123;&quot;msg&quot;: &quot;Hello World&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">client &#x3D; TestClient(app)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def test_read_main():</span><br><span class="line">    response &#x3D; client.get(&quot;&#x2F;&quot;)</span><br><span class="line">    assert response.status_code &#x3D;&#x3D; 200</span><br><span class="line">    assert response.json() &#x3D;&#x3D; &#123;&quot;msg&quot;: &quot;Hello World&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>另外，testClient还可以用于：</p>
<ul>
<li>测试websocket。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def test_websocket():</span><br><span class="line">    client &#x3D; TestClient(app)</span><br><span class="line">    with client.websocket_connect(&quot;&#x2F;ws&quot;) as websocket:</span><br><span class="line">        data &#x3D; websocket.receive_json()</span><br><span class="line">        assert data &#x3D;&#x3D; &#123;&quot;msg&quot;: &quot;Hello WebSocket&quot;&#125;</span><br></pre></td></tr></table></figure></li>
<li>测试事件：启动和关闭</li>
<li>override 依赖</li>
<li>单独出测试数据库</li>
</ul>
<h1 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h1><p>fastAPI没有提供template，如果要用需要可以使用：jinja2。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from fastapi import FastAPI, Request</span><br><span class="line">from fastapi.responses import HTMLResponse</span><br><span class="line">from fastapi.staticfiles import StaticFiles</span><br><span class="line">from fastapi.templating import Jinja2Templates</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line">app.mount(&quot;&#x2F;static&quot;, StaticFiles(directory&#x3D;&quot;static&quot;), name&#x3D;&quot;static&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">templates &#x3D; Jinja2Templates(directory&#x3D;&quot;templates&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;&#x2F;items&#x2F;&#123;id&#125;&quot;, response_class&#x3D;HTMLResponse)</span><br><span class="line">async def read_item(request: Request, id: str):</span><br><span class="line">    return templates.TemplateResponse(&quot;item.html&quot;, &#123;&quot;request&quot;: request, &quot;id&quot;: id&#125;)</span><br></pre></td></tr></table></figure>
<h1 id="部署-Server"><a href="#部署-Server" class="headerlink" title="部署/Server"></a>部署/Server</h1><p>一般情况下，fastAPi只作为应用的载体，需要一个server容器来部署应用，这个server我们建议使用uvicorn, 比如：<br><code>uvicorn main:app --reload</code><br>这样的命令行方式适合部署时使用，如果要进行debug,可以使用以下方式部署：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import uvicorn</span><br><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app &#x3D; FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;&#x2F;&quot;)</span><br><span class="line">def root():</span><br><span class="line">    a &#x3D; &quot;a&quot;</span><br><span class="line">    b &#x3D; &quot;b&quot; + a</span><br><span class="line">    return &#123;&quot;hello world&quot;: b&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    uvicorn.run(app, host&#x3D;&quot;0.0.0.0&quot;, port&#x3D;8000)</span><br></pre></td></tr></table></figure>
<h1 id="项目生成器"><a href="#项目生成器" class="headerlink" title="项目生成器"></a>项目生成器</h1><p>可以使用项目生成器来进行一键初始化：<br>GitHub：https : //github.com/tiangolo/full-stack-fastapi-postgresql</p>
<p>全栈FastAPI PostgreSQL-功能</p>
<ol>
<li>完全Docker集成（基于Docker）。</li>
<li>Docker Swarm模式部署。</li>
<li>Docker用于本地开发的集成和优化。</li>
<li>使用Uvicorn和Gunicorn的可投入生产的 Python Web服务器。</li>
<li>Python FastAPI后端：<ul>
<li>快速：非常高的性能，看齐的NodeJS和围棋（感谢Starlette和Pydantic）。</li>
<li>直观：强大的编辑器支持。完成无处不在。调试时间更少。</li>
<li>简易：旨在易于使用和学习。减少阅读文档的时间。</li>
<li>短：最小化代码重复。每个参数声明中的多个功能。</li>
<li>健壮：获取可用于生产的代码。具有自动交互式文档。</li>
<li>基于标准：基于（并完全兼容）API的开放标准：OpenAPI和JSON Schema。</li>
<li>许多其他功能包括自动验证，序列化，交互式文档，使用OAuth2 JWT令牌进行身份验证等。</li>
<li>默认情况下，安全密码哈希。</li>
</ul>
</li>
<li>JWT令牌认证。</li>
<li>SQLAlchemy模型（独立于Flask扩展，因此可以直接与Celery工作者一起使用）。</li>
<li>用户的基本启动模型（根据需要修改和删除）。</li>
<li>alembic迁移。</li>
<li>CORS（跨源资源共享）。</li>
<li>可以选择性地从后端的其余部分导入和使用模型和代码的celery。</li>
<li>基于Pytest的 REST后端测试，与Docker集成在一起，因此您可以独立于数据库测试完整的API交互。由于它在Docker中运行，因此每次都可以从头开始构建新的数据存储（因此您可以使用ElasticSearch，MongoDB，CouchDB或任何您想要的东西，只需测试API是否有效）。</li>
<li>与Jupyter Kernels轻松实现Python集成，可通过 Atom Hydrogen或Visual Studio Code Jupyter之类的扩展来进行远程或Docker内部开发。</li>
<li>Vue前端：<ul>
<li>用Vue CLI生成。</li>
<li>JWT认证处理。</li>
<li>登录视图。</li>
<li>登录后，进入主仪表板视图。</li>
<li>具有用户创建和版本的主仪表板。</li>
<li>自我用户版。</li>
<li>Vuex。</li>
<li>Vue路由器。</li>
<li>Vuetify提供精美的材料设计组件。</li>
<li>TypeScript。</li>
<li>基于Nginx的 Docker服务器（配置为与Vue-router完美配合）。</li>
<li>Docker多阶段构建，因此您无需保存或提交已编译的代码。</li>
<li>前端测试在构建时运行（也可以禁用）。</li>
<li>尽可能采用模块化设计，因此可以立即使用，但是您可以使用Vue - CLI重新生成或根据需要创建它，然后重新使用所需的内容。</li>
</ul>
</li>
<li>PGAdmin for PostgreSQL数据库，您可以对其进行修改以轻松使用PHPMyAdmin和MySQL。</li>
<li>Flower为celery工作监视。</li>
<li>使用Traefik可以在前端和后端之间实现负载平衡，因此您可以将两者都放在同一个域中，以路径分隔，但可以通过不同的容器进行服务。</li>
<li>Traefik集成，包括让我们加密HTTPS证书自动生成。</li>
<li>GitLab CI（连续集成），包括前端和后端测试。</li>
</ol>
<h2 id="项目生成器使用"><a href="#项目生成器使用" class="headerlink" title="项目生成器使用"></a>项目生成器使用</h2><p>按照生成器的说明步骤，输入适当参数即可得到一个 full-stack的项目，包含后端api、前端vue、docker 部署。</p>
<h3 id="backend-fastAPI"><a href="#backend-fastAPI" class="headerlink" title="backend: fastAPI"></a>backend: fastAPI</h3><p>backend 服务启动2个容器：python FastAPI应用和celery应用。</p>
<h4 id="python-FastAPI应用"><a href="#python-FastAPI应用" class="headerlink" title="python FastAPI应用"></a>python FastAPI应用</h4><ol>
<li><p>使用python3.7</p>
</li>
<li><p>泛型和类型提示（type hints）</p>
</li>
<li><p>fastAPI官方出品docker容器：tiangolo/uvicorn-gunicorn-fastapi:python3.7</p>
</li>
<li><p>使用Poetry来做包管理工具，代替Pipenv。</p>
<ol>
<li>python 与java/JavaScript等语言的project隔离是不一样的。python的项目依赖包都是统一安装到site-packages目录下，如果不同project依赖了不同版本的同一模块，那么后安装的会卸载掉先安装的。所以python需要为每一个项目进行单独隔离，所以virtualenv应运而生。</li>
<li>那么讨论python的依赖管理一般就指 依赖管理+虚拟环境。最初的工具就是pip+virtualenv，pip用来做包管理，virtualenv用来做虚拟环境。那么就带来问题：<ol>
<li>需要同时使用2个工具</li>
<li>不能动态更新requirements.txt，这点尤其突出。这种文本格式的文件只能记录依赖包的名称，不能像yaml/json/xml一样记录更多的环境信息和参数。每次更新都是需要手动执行<code>pip freeze &gt; requirements.txt</code>，如果那次遗漏，那么后患无穷。</li>
</ol>
</li>
<li>因此，pipenv诞生了。</li>
<li>pipenv可以看成是pip+virtualenv两款工具的合体，它集合了pip的依赖包管理和virtualenv虚拟环境 管理于一身。另外，在依赖包记录方面使用Pipfile替代原来的requirements.txt。而且，它能够自动记录并更新记录文件，这样就不在需要手动执行命令来更新requirements.txt。但是他依然有很多缺陷：<ol>
<li>Lock速度缓慢</li>
<li>强行更新不相干依赖</li>
<li>依赖处理效果较差。</li>
</ol>
</li>
<li><code>当当~当~当~~~</code>！Poetry出现了</li>
<li>poetry是一款可以管理Python依赖、环境，同時可以用于Python工程打包和发布的一款第三方工具包。poetry通过配置文件pyproject.toml来完成依赖管理、环境配置、基本信息配置等功能。相当于把Python項目中的Pipfile、setup.py、setup.cfg、requirements.txt、MANIFEST.in融合到一起。通过pyproject.toml文件，不仅可以配置依赖包，还可以用于区分开发、测试、生产环境、配置源路径。</li>
</ol>
</li>
<li><p>使用Tenacity做重试，判断DB是否就绪。<a href="https://tenacity.readthedocs.io/">Tenacity</a>不兼容<a href="https://github.com/invl/retry">retry</a>的api并且做了一些重要的功能和bug 修复。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> tenacity <span class="keyword">import</span> after_log, before_log, retry, stop_after_attempt, wait_fixed</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.INFO)</span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line">max_tries = <span class="number">60</span> * <span class="number">5</span>  <span class="comment"># 5 minutes</span></span><br><span class="line">wait_seconds = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@retry(</span></span><br><span class="line">    stop=stop_after_attempt(max_tries),</span><br><span class="line">    wait=wait_fixed(wait_seconds),</span><br><span class="line">    before=before_log(logger, logging.INFO),</span><br><span class="line">    after=after_log(logger, logging.WARN),</span><br><span class="line">)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init</span>() -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># Try to create session to check if DB is awake</span></span><br><span class="line">        db = SessionLocal()</span><br><span class="line">        db.execute(<span class="string">&quot;SELECT 1&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        logger.error(e)</span><br><span class="line">        <span class="keyword">raise</span> e</span><br></pre></td></tr></table></figure>
<h4 id="celery应用"><a href="#celery应用" class="headerlink" title="celery应用"></a>celery应用</h4></li>
<li><p>使用”uvicorn.workers.UvicornWorker” </p>
</li>
<li><p>容器启动之前使用Tenacity重试DB是否就绪</p>
</li>
</ol>
<h3 id="frontend-vue"><a href="#frontend-vue" class="headerlink" title="frontend: vue"></a>frontend: vue</h3><ol>
<li>typescript</li>
<li>tslint</li>
<li>测试使用vue-test-utils单元测试</li>
<li>Vue.js 的验证库VeeValidate</li>
<li>vuetify，是一个基于vue2.0，为移动而生的组件框架，一个渐进式的UI框架</li>
</ol>
]]></content>
      <categories>
        <category>FastAPI</category>
      </categories>
      <tags>
        <tag>FastAPI</tag>
      </tags>
  </entry>
  <entry>
    <title>VDI 远程协议的一些解释</title>
    <url>/2020/12/24/VDI%20%E8%BF%9C%E7%A8%8B%E5%8D%8F%E8%AE%AE%E7%9A%84%E4%B8%80%E4%BA%9B%E8%A7%A3%E9%87%8A/</url>
    <content><![CDATA[<h1 id="桌面协议"><a href="#桌面协议" class="headerlink" title="桌面协议"></a>桌面协议</h1><p>虚拟桌面架构（VDI）中，协议是非常关键的一环，其定义了将服务器虚拟出的客户机系统从服务器传输到各类终端的规则，涉及到安全，图像处理，数据压缩，网络传输协议等多个方面，直接决定着虚拟桌面的终端体验。</p>
<a id="more"></a>
<p>常用的虚拟桌面协议有：</p>
<ol>
<li><p>RDP(remote desktop protocol)协议：远程桌面协议，大部分 Windows 系统都默认支持此协议。Windows系统中的远程桌面管理就是基于该协议的。据说也是由思杰开发，支持的功能较少，且主要应用在windows环境中，现在也有<a href="http://www.microsoft.com/mac/remote-desktop-client">Mac下的RDP客户端</a>和linux下的RDP客户端<a href="http://www.rdesktop.org/">rdesktop</a>. 历经多个版本的开发，RDP最新版也支持了打印机重定向，音频重定向，剪贴板共享等功能。</p>
<p>RemoteFX是RDP的增强版，提供了vGPU,视频支持，多点触摸，USB重定向等功能。 </p>
</li>
<li><p>RFB(Remote FrameBuffer)协议：图形远程管理协议，<strong>VNC</strong>远程管理工具就是基于此协议。</p>
</li>
<li><p>SPICE，Simple Protocol for Independent Computing Environment（独立计算环境简单协议）是红帽企业虚拟化桌面版的主要技术组件之一，具有自适应能力的远程提交协议，能够提供与物理桌面完全相同的最终用户体验。借助支持SPICE协议的客户端（如remote-viewer）或者通过浏览器，用户可以访问自己的虚拟云桌面。</p>
</li>
<li><p>ICA/HDX：Citrix Independent Computing Architecture （ ICA ）应该是目前最成熟的虚拟桌面协议, 思杰十几年的耕耘使其难以在短时间内被完全超越。ICA除了功能齐全（支持windows areo）之外，还有广泛的移动端支持。ICA的网络协议无关性，使其可以支持TCP/IP 、 NetBIOS 和 IPX/SPX 。ICA不仅支持自家的虚拟化平台XenServer，还支持vSphere和Hyper-V。性能上比较突出的特点是较低的带宽占用，在网络环境差（延迟高）的情况下也能正常使用</p>
<p>HDX（High Definition Experience）作为ICA的增强版，着力于改善用户体验，包括音视频，多媒体和3D，HDX支持H.264.</p>
</li>
<li><p>PCoIP最初由加拿大公司Teradici开发，早期定位于高端图形设计，2008年VMware宣布与Teradici共同开发PCoIP，以改进自己的VDI解决方案VMware View。</p>
</li>
<li><p>其他协议</p>
<ol>
<li><p><a href="http://systems.cs.columbia.edu/projects/thinc/">THINC</a>（Thin-Client Internet Computing）是哥伦比亚大学的一个研究项目，不太成熟，只找到一篇论文，可以拿来做学习研究用。</p>
</li>
<li><p>X11 <a href="http://en.wikipedia.org/wiki/X_Window_System">X windows system</a> 最初设计的时候就是client server的架构方式，因此也能远程访问主机的桌面。</p>
</li>
<li><p>ALP：Sun公司在1999年就推出了一款瘦终端产品Sun Ray，其采用的协议为Sun公司开发的ALP（Appliance Link Protocol），VMware view也支持该协议，不过最近Oracle宣布终止Sun Ray的开发。</p>
</li>
<li><p>EOP(Experience Optimization Protocol)协议是Quest Software的VDI协议，用在其自家的VDI产品vWorkspace（<a href="http://www.brianmadden.com/blogs/brianmadden/archive/2007/11/12/quest-software-buys-provision-networks-finally-a-real-challenger-to-citrix-in-the-app-delivery-space.aspx">收购了Provision-Networks</a>）中，Quest没有自己的hypervisor，所以vWorkspace支持Citrix VMware 微软等的hypervisor。Quest Software已经被DELL收购。</p>
</li>
<li><p>CHP，号称宇宙无敌最强协议，直接把ICA RDP PCoIP虐出xiang的国产CHP，不说了 上图。</p>
<p><img src="https://songtianyi.info/images/004-vdi-03.png" alt="虚拟桌面协议 - songtianyi - songtianyi"></p>
</li>
</ol>
</li>
</ol>
<p>以上参考 <a href="https://songtianyi.info/pages/vdi/004-vdi.html">https://songtianyi.info/pages/vdi/004-vdi.html</a></p>
<p>spice/vnc/rdp, 三者的对比如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>SPICE</th>
<th>VNC</th>
<th>RDP</th>
</tr>
</thead>
<tbody><tr>
<td>BIOS屏幕显示</td>
<td>能</td>
<td>能</td>
<td>不能</td>
</tr>
<tr>
<td>全彩支持</td>
<td>能</td>
<td>能</td>
<td>能</td>
</tr>
<tr>
<td>更改分辨率</td>
<td>能</td>
<td>能</td>
<td>能</td>
</tr>
<tr>
<td>多显示器</td>
<td>多显示器支持（高达4画面）</td>
<td>只有一个屏幕</td>
<td>多显示器支持</td>
</tr>
<tr>
<td>图像传输</td>
<td>图像和图形传输</td>
<td>图像传输</td>
<td>图像和图形传输</td>
</tr>
<tr>
<td>视频播放支持</td>
<td>GPU加速支持</td>
<td>不能</td>
<td>GPU加速支持</td>
</tr>
<tr>
<td>音频传输</td>
<td>双向语音可以控制</td>
<td>不能</td>
<td>双向语音可以控制</td>
</tr>
<tr>
<td>鼠标控制</td>
<td>客户端服务器都可以控制</td>
<td>服务器端控制</td>
<td>服务器端控制</td>
</tr>
<tr>
<td>USB传输</td>
<td>USB可以通过网络传输</td>
<td>不能</td>
<td>USB可以通过网络传输</td>
</tr>
</tbody></table>
<h2 id="spice"><a href="#spice" class="headerlink" title="spice"></a>spice</h2><p>SPICE架构包括客户端、SPICE服务端和相应的QXL设备、QXL驱动等，如下图所示。客户端运行在用户终端设备上，为用户提供桌面环境。SPICE服务端以动态连接库的形式与KVM虚拟机整合，通过SPICE协议与客户端进行通信。</p>
<p><img src="/images/spice-arc.png" alt="spice架构"></p>
<p>Spice agent运行在客户机（虚拟机）操作系统中。Spice server和Spice client利用spice agent来执行一些需要在虚拟机里执行的任务，如配置分辨率，另外还有通过剪贴板来拷贝文件等。从上图可以看出，Spice client与server与Spice Agent的通信需要借助一些其他的软件模块，如在客户机里面，Spice Agent需要通过VDIPort Driver与主机上 QEMU的VDIPort Device进行交互，他们的交互通过一种叫做输入/输出的环进行。Spice Client和Server产生的消息被写入到设备的输出环中，由VDI Port Driver读取；而Spice Agent发出的消息则通过VDI Port Driver先写入到VDI Port Device输入环中,被QEMU读入到Spice server的缓冲区中，然后再根据消息决定由Spice Server直接处理，还是被发往Spice Client中。</p>
<p><img src="/images/spice-agent.png" alt="spice agent通信"></p>
<p>SPICE协议最大的特点是其架构中增加的位于Hypervisor中的QXL设备，本质上是KVM虚拟化平台中通过软件实现的PCI显示设备，利用循环队列等数据结构供虚拟化平台上的多个虚拟机共享实现了设备的虚拟化。但是，这种架构使得SPICE协议紧密地依赖于服务器虚拟化软／硬件基础设施，SPICE必须与KVM虚拟化环境绑定。传统的远程桌面传输协议工作在虚拟机Guest OS中，而SPICE协议本身运行在虚拟机服务器中，可以直接使用服务器的硬件资源。</p>
<p>其实KVM虚拟化桌面进行云端访问时也是可以使用VNC通道进行数据传输的，然而VNC虽然通用但是效率比起SPICE还是差的远，资源消耗也是非常大，如果你是用KVM-QEMU虚拟机的话，进行云端桌面访问建议使用SPICE协议。</p>
<p><strong>SPICE协议特点</strong></p>
<ul>
<li><p>和低端(low end)的虚拟桌面协议（如RFB）不同，SPICE协议虚拟出一个图形处理设备QXL，专门用于处理客户机的图形命令（graphic commands）。</p>
</li>
<li><p>SPICE用不同的信道来传输键盘，鼠标，视频图像和音频等，便于针对性地优化。</p>
</li>
<li><p>SPICE首先尝试将渲染的工作交给客户端（瘦终端），利用客户端硬件资源来加速，之后会将渲染工作交给主机来处理，这时可以用软件或者GPU来处理。</p>
</li>
<li><p>SPICE客户端支持linux，windows和<a href="http://spice-space.org/page/OSX_Client">Mac</a></p>
<p><strong>SPICE协议目前已有的功能</strong></p>
</li>
<li><p>视频/图像压缩，基于MPEG的视频压缩和基于SFALIC，Lempel–Ziv的图像压缩</p>
</li>
<li><p>客户端缓存，对图像 调色板 光标进行缓存处理</p>
</li>
<li><p>热迁移，虚拟机从当前主机（Host）迁移到另外一个主机时spice的连接不会中断</p>
</li>
<li><p>多屏显示，最多支持四个屏幕</p>
</li>
<li><p>音频的播放和录制，音频也可以压缩传输</p>
</li>
<li><p>加密传输，支持openssl</p>
</li>
<li><p>剪贴板共享，瘦终端系统（client OS）和客户机系统（guest OS）可以相互拷贝粘贴</p>
</li>
<li><p>USB重定向，将瘦终端的USB设备重定向到客户机</p>
</li>
<li><p>smartcard，支持智能卡登录</p>
</li>
</ul>
<h2 id="vnc"><a href="#vnc" class="headerlink" title="vnc"></a>vnc</h2><p> VNC (Virtual Network Console)，虚拟网络控制台。VNC系统由客户端，服务端和一个协议组成。VNC的服务端目的是分享其所运行机器的屏幕， 服务端被动的允许客户端控制它。 </p>
<p>VNC客户端（或Viewer） 观察控制服务端，与服务端交互。 VNC 协议 Protocol (RFB)是一个简单的协议，传送服务端的原始图像到客户端（一个X,Y 位置上的正方形的点阵数据）， 客户端传送事件消息到服务端。服务器发送小方块的帧缓存给客户端，在最简单的情况，VNC协议使用大量的带宽，因此各种各样的方法被发明出来减少通讯的开支，举例来说，有各种各样的编码方法来决定最有效率的方法来传送这些点阵方块。协议允许客户端和服务端去协议哪种编码会被使用，最简单的编码，被大多数客户端和服务端所支持的是， 从左到右的像素扫描数据的原始编码， 当原始的满屏被发送后，只发送变化的方块区域。这种编码在帧间只有小部分屏幕变化的情况下工作的非常好（像是鼠标键在桌面移动的情况，或在光标处敲击文字），不过如果大量的像素同时变化带宽将会增加的非常高，像是拖动一个窗口或观看全屏录像。</p>
<p><a href="https://novnc.com/info.html">noVNC</a> 是一个 HTML5 的 VNC 客户端，采用 JavaScript 编程实现。其主要功能是和远端的 VNC Server 互通，通过对 <a href="https://en.wikipedia.org/wiki/RFB_protocol">RFB（Remote Frame Buffer）协议</a> 数据的编解码，一方面接收远端 VNC Server 发送的数据，解码后通过 <a href="https://en.wikipedia.org/wiki/Canvas_element">Canvas</a> 技术绘制在客户端侧，另一方面将客户端侧的终端输入编码成 RFB 数据发送给远端的 VNC Server。也就是说有了 noVNC，我们可以直接使用支持 HTML5 的 Web 浏览器，譬如 Chrome，就可以访问远端的安装了 VNC Server 的机器的桌面，而不用另外安装原生的 VNC 客户端（譬如我们经常在 Windows 上安装的 <a href="https://www.realvnc.com/download/viewer/">RealVNC Viewer</a>）。</p>
<p>但需要注意的是，具体传输时，和原生的 VNC 客户端不同，原生的客户端的 RFB 数据是直接承载在 TCP （Raw TCP）上，而 noVNC 处理的 RFB 数据是承载在 Websocket 之上。由于目前大多数 VNC 服务器都不支持 WebSockets，所以 noVNC 是不能直接连接 VNC 服务器的，怎么办呢？这就需要一个代理来实现 Websockets 和 Raw TCP 之间的转换，这个代理就是 Websockify。</p>
<p>一个典型的从客户端浏览器到 VNC 服务器，中间经过 Websockify 转换的网络如下，注意其中 noVNC 作为一个 HTML5 的客户端，虽然一开始是存放在 websockify 所在的代理服务器上，但其主体 js 代码会在客户端浏览器访问 websockify 服务时被下载到客户端的浏览器中执行。</p>
<p>   <img src="/images/vnc-network.png" alt="vnc-network"></p>
<p>参考<a href="http://tinylab.org/guide-to-novnc/">http://tinylab.org/guide-to-novnc/</a></p>
<h1 id="spice图像处理"><a href="#spice图像处理" class="headerlink" title="spice图像处理"></a>spice图像处理</h1><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ul>
<li><p>JPEG/MJPEG(MotionJPEG)</p>
<ul>
<li>JPEG是一种静止图像的压缩标准，它是一种标准的帧内压缩编码方式。当硬件处理速度足够快时，JPEG能用于实时动图像的视频压缩。在画面变动较小的情况下能提供相当不错的图像质量，传输速度快，使用相当安全，缺点是数据量较大。</li>
<li>M-JPEG源于JPEG压缩技术，是一种简单的帧内JPEG压缩，压缩图像质量较好，在画面变动情况下无马赛克，但是由于这种压缩本身技术限制，无法做到大比例压缩，录像时每小时约1-2GB空间，网络传输时需要2M带宽，所以无论录像或网络发送传输，都将耗费大量的硬盘容量和带宽，不适合长时间连续录像的需求，不大实用于视频图像的网络传输。</li>
</ul>
<p>MJPEG是spice默认算法，它只单独的对某一帧进行压缩（帧内压缩），而基本不考虑视频流中不同帧之间的变化。通过此压缩技术可获取清晰度很高的视频图像，而且可灵活设置每路的视频清晰度和压缩帧数，并且压缩后的画面还可任意剪接。但它的缺陷也非常明显：</p>
<ul>
<li>丢帧现象严重、实时性差，在保证多台瘦客户机都必须是高清晰的前提下，很难完成实时压缩，通常用做单台虚拟机测试播放1080P 高清视频；</li>
<li>压缩效率低，传输带宽和存储空间占用大</li>
</ul>
</li>
<li><p>H.264是 ITU-T和ISO共同成立的JVT联合视频工作组制定的新一代视频编码标准，用来实现视频的高压缩比、高图像质量、良好的网络适应性等目标。H.264 不仅比MJPEG节约了80%以上的码率，而且对网络传输具有更好的支持功能。H.264引入了面向IP包的编码机制，有利于网络中的分组传输，支持网络中视频的流媒体传输，支持不同网络资源下的分级编码传输，从而获得平稳的图像质量。H.264可以在更低的带宽下实现720p、 1080i/p的广播级高清视频分辨率。</p>
<p>尽管MJPEG能够获得比较好的单幅图像质量，但由于它在运动性、带宽占用方面均有致命缺陷，所以更需要H.264视频编码方式来满足低带宽，实时多并发连接的桌面虚拟化使用场境.</p>
</li>
<li><p>h.265是H.264的升级版,H.265标准保留H.264原来的某些技术，同时对一些相关的技术加以改进。新技术使用先进的技术用以改善码流、编码质量、延时和算法复杂度之间的关系，达到最优化设置；</p>
<p>具体的研究内容包括：提高压缩效率、提高鲁棒性和错误恢复能力、减少实时的时延、减少信道获取时间和随机接入时延、降低复杂度等。H264由于算法优化，可以低于1Mbps的速度实现标清数字图像传送；H265则可以实现利用1~2Mbps的传输速度传送720P（分辨率1280*720）普通高清音视频传送。H.265旨在在有限带宽下传输更高质量的网络视频，仅需原先的一半带宽即可播放相同质量的视频。这也意味着，我们的智能手机、平板机等移动设备将能够直接在线播放1080p的全高清视频。H.265标准也同时支持4K(4096×2160)和8K(8192×4320)超高清视频。可以说，H.265标准让网络视频跟上了显示屏“高分辨率化”的脚步。</p>
</li>
<li><p>MPEG是ISO与IEC于1988年成立的专门针对运动图像和语音压缩制定国际标准的组织。MPEG标准主要有以下五个，<a href="https://baike.baidu.com/item/MPEG-1">MPEG-1</a>、MPEG-2、<a href="https://baike.baidu.com/item/MPEG-4">MPEG-4</a>、MPEG-7及<a href="https://baike.baidu.com/item/MPEG-21">MPEG-21</a>等。当年的dvd碟片就是用的mpeg-2视频编码，广电mpeg-2用的比较普遍。</p>
</li>
<li><p>YUV420和YUV444. RGB是构成多种颜色的三基色（红绿蓝），也称为加成色。主要是图像的采集和显示。YUV是优化彩色视频信号的编码和传输，和rgb相比，YUV占用的带宽少。YUV中Y表示的是亮度，UV表示的是色度，定义了颜色的两个方面的色度和饱和度。YUV分为YUV444，YUV422，YUV420等，含有不同色度分量的编码方式。每个部分用8位或者1个字节来标识。由于YUV444没有色彩二次采样的问题，也就是说我们不会从原图像中去除任何色彩信息，这样YUV444就会有完整的24bits。但是对于YUV420来说，由于我们移除了一半的水平和垂直色彩信息，以便降低带宽的使用，这最终导致了我们只用了12bits来代表YUV420，仍然是8bits的亮度，但是只有4bits而不是16bits的色彩度。你可以查看此网站(<a href="https://en.wikipedia.org/wiki/Chroma_subsampling#4:4:4">https://en.wikipedia.org/wiki/Chroma_subsampling#4:4:4</a>) 了解更多的采样系统.人类肉眼通常对于光线或者亮度比较敏感，所以无论YUV420还是YUV444都保证了亮度，但是色彩因人而异，不同的人对于不同的色彩的理解有一定的差异，同时在高帧率（high frame per second）的场景下，您往往无法很快察觉到颜色的差异，但是亮度差异会更加明显。所以，YUV420是采用了一种折中的方式来平衡显示效果和资源占用。</p>
<ul>
<li>对于色彩准确度上，YUV444相比YUV420 有很大的改善</li>
<li>UV444每像素24比特，YUV420每像素仅12比特，所以YUV444的带宽消耗比YUV420高出两倍左右</li>
<li>YUV444比YUV420使用硬件编码（NVENC）情况下略有延迟（编码量更多）</li>
<li>基于Linux的瘦客户机可能不支持YUV444</li>
</ul>
<p><strong>没有最好，只有最合适，我们需要在不同场景中进行平衡的选择。建议在用户对颜色准确性敏感的3D VDI使用场景中使用YUV444。</strong></p>
</li>
</ul>
<h2 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h2><p>VDI传输的图像画面有2种处理方式：图片和视频。</p>
<ul>
<li><p>图片场景</p>
<p>如果桌面的屏幕大多数没有变化，那么传输的图像完全可以是一帧帧的图片，比如用户使用office和erp应用等。此时可以使用例如Citrix Bitmap remoting（位图远程控制），基于JPG 压缩和RLE（Rung Length Encoding）技术。位图远程（Bitmap Remoting），也叫做“Thinwire”是一种针对静态内容“Static Content”可以高效利用带宽的远程控制协议。当然，在spice协议中我们可以使用无损压缩来得到同样的体验（无损压缩是在不丢失任何信息的情况下将数据压缩更小，算法有lz4/glz）。</p>
<ul>
<li>对资源消耗非常低，不需要特别的终端硬件配置</li>
<li>使用cpu进行位图压缩编码</li>
<li>不能使用GPU编码</li>
</ul>
</li>
<li><p>视频场景</p>
<p>位图（Bitmap Remoting）对于静态图像支持的非常好，但是当涉及到移动图像和视频播放时，情况则有所不同了。当帧率越高（30fps，60fps），就有越多的图像需要被位图远程控制(Bitmap Remoting)所传输，这将严重影响带宽需求和总体的使用体验。所以，这种情况下视频编解码正好有所作用。视频编解码的技术有JPEG/M-JPE、H.264/H265和MPEG等，结合YUV方案分别有如下的视频场景下的技术方案：</p>
<table>
<thead>
<tr>
<th>技术方案</th>
<th>带宽</th>
<th>延时</th>
<th>GPU加速</th>
<th>硬件要求</th>
<th>图像质量（SSIM）</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>H.264 YUV420</td>
<td>中</td>
<td>低</td>
<td>支持</td>
<td></td>
<td>0.8310</td>
<td>一般场景</td>
</tr>
<tr>
<td>H.264 YUV444</td>
<td>高</td>
<td>中</td>
<td>支持</td>
<td>Citrix linux终端不支持</td>
<td>0.9836</td>
<td>对颜色敏感，带宽会增加</td>
</tr>
<tr>
<td>H.265 YUV420</td>
<td>低</td>
<td>低</td>
<td>支持</td>
<td>需要指定的CPU/GPU以及终端</td>
<td>0.8311</td>
<td>节约带宽</td>
</tr>
<tr>
<td>H.265 YUV444</td>
<td>/</td>
<td>/</td>
<td>少部分专业GPU卡支持</td>
<td>/</td>
<td>/</td>
<td>/</td>
</tr>
<tr>
<td>Citrix 无损构建（H.264/H.265）</td>
<td>极低</td>
<td>低</td>
<td>支持</td>
<td></td>
<td>0.9999</td>
<td>一般办公（office 等）,不适合2D/3D设计等(过程画面有损，最终清晰，锐化现象)</td>
</tr>
<tr>
<td>Citrix 混合编码</td>
<td>极低</td>
<td>高</td>
<td>视频编码时支持</td>
<td></td>
<td>0.9999</td>
<td>结合了位图编解码和视频编解码优点。热点区域使用视频编码，非热点使用位图。无法将硬件编码用于位图编解码所以延迟大。</td>
</tr>
</tbody></table>
</li>
</ul>
]]></content>
      <categories>
        <category>VDI</category>
      </categories>
      <tags>
        <tag>VDI</tag>
        <tag>spice</tag>
        <tag>vnc</tag>
      </tags>
  </entry>
  <entry>
    <title>cloudbase-init 源码研究</title>
    <url>/2020/12/04/cloudbase-init%20%E6%BA%90%E7%A0%81%E7%A0%94%E7%A9%B6/</url>
    <content><![CDATA[<h1 id="cloudbase-init-源码研究"><a href="#cloudbase-init-源码研究" class="headerlink" title="cloudbase-init 源码研究"></a>cloudbase-init 源码研究</h1><p>cloudbase-init是cloud-init的windows版本实现，与cloudinit有一些区别，官方文档请参看<a href="https://cloudbase-init.readthedocs.io/">https://cloudbase-init.readthedocs.io/</a></p>
<a id="more"></a>

<p>以下以window10 64位+cloudbase-init 1.1.2为例。</p>
<h2 id="cloudbase-init的安装文件结构"><a href="#cloudbase-init的安装文件结构" class="headerlink" title="cloudbase-init的安装文件结构"></a>cloudbase-init的安装文件结构</h2><ul>
<li>源代码参见<a href="https://github.com/openstack/cloudbase-init">github</a></li>
<li>在windows系统安装之后为：<ul>
<li>bin 二进制一些工具和服务启动入口</li>
<li>conf 配置文件</li>
<li>LocalScripts 本地脚本文件夹</li>
<li>log 日志目录</li>
<li>Python python环境（1.1.2版本使用的python是3.6）<ul>
<li>Scripts目录下一些工具</li>
<li>Lib/site-packages 目录下安装了cloudbase-init的源码和其依赖包</li>
<li>其他目录没有特别之处</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h2><p>cloudbase-init使用pbr打包。pbr是setuptools的加强版，是openstack社区出品。使用pbr可以方便的使用git管理版本。</p>
<p>pbr会把setuptools的配置项转移到setup.cfg中，setup.cfg文件我们重点关注 entry_points这个设置项。entry_points可以方便为我们打包的python应用提供一个可执行的二进制文件，类似于<code>pip install</code> 和 <code>python -m pip intstall</code>的关系。在cloudbase-init中，通过pbr打包，会生成cloudbase-init.exe，位于：Cloudbase-Init\Python\Scripts目录下，cloudbase-init运行的时候，可以直接调用该二进制文件。</p>
<h2 id="入口"><a href="#入口" class="headerlink" title="入口"></a>入口</h2><p>通过打包章节可以知道cloudbase-init的执行文件为Cloudbase-Init\Python\Scripts\cloudbase-init.exe，这个文件是pbr的entry_points控制生成的。entry_points的设置为：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[entry_points]</span></span><br><span class="line">console_scripts =</span><br><span class="line">  <span class="attr">cloudbase-init</span> = cloudbaseinit.shell:main</span><br></pre></td></tr></table></figure>

<p>所以，可以知道cloudbase-init项目的入口是cloudbase-init下的<strong>shell.py</strong>.</p>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p>从git clone下代码之后，主要源码位于/cloudbase-init目录下：</p>
<ul>
<li>cloudbase-init<ul>
<li>conf</li>
<li>metadata</li>
<li>models</li>
<li>osutils</li>
<li>plugins</li>
<li>tests</li>
<li>utils</li>
<li><code>__init__.py</code></li>
<li>constant.py</li>
<li>exception.py</li>
<li>init.py</li>
<li>shell.py</li>
<li>version.py</li>
</ul>
</li>
</ul>
<h3 id="osutils"><a href="#osutils" class="headerlink" title="osutils"></a>osutils</h3><pre class="mermaid">classDiagram
    BaseOSUtils <|-- PosixUtils
    BaseOSUtils <|-- WindowsUtils
    BaseOSUtils : +string PROTOCOL_TCP
    BaseOSUtils : +string PROTOCOL_UDP
    BaseOSUtils : +execute_process()
    BaseOSUtils : +generate_random_password()
    BaseOSUtils : +create_user()
    BaseOSUtils : +reboot()
    BaseOSUtils : +set_timezone()
    BaseOSUtils : +other_method(...)
    class WindowsUtils{
        -class _network_team_manager
        -_get_system_dir()
        -other_method()
    }</pre>

<p>osutils 使用了<strong>简单工厂</strong>设计模式，根据当前操作系统的类型来加载相应的类，并创建对应的对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_os_utils</span>():</span></span><br><span class="line">    osutils_class_paths = &#123;</span><br><span class="line">        <span class="string">&#x27;nt&#x27;</span>: <span class="string">&#x27;cloudbaseinit.osutils.windows.WindowsUtils&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;posix&#x27;</span>: <span class="string">&#x27;cloudbaseinit.osutils.posix.PosixUtils&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cl = classloader.ClassLoader()</span><br><span class="line">    <span class="keyword">return</span> cl.load_class(osutils_class_paths[os.name])()</span><br></pre></td></tr></table></figure>

<p><code>os.name</code>的返回值是posix，nt，java之一，分别代表linux/windows/java虚拟机。</p>
<p>cloudbase-init主要针对windows环境，所以WindowsUtils实现的比较健全，PosixUtils只实现了reboot方法。</p>
<h3 id="shell-py"><a href="#shell-py" class="headerlink" title="shell.py"></a>shell.py</h3><p>shell.py是cloudbase-init的入口文件，提供3个功能：</p>
<ol>
<li>读取配置文件。通过command line参数读取配置文件位置，使用oslo.config加载配置文件。配置文件一般位于：Cloudbase-Init/conf目录下</li>
<li>初始化log</li>
<li>进入cloudbase-init的主程序：init.py，执行<code>init.InitManager().configure_host()</code></li>
</ol>
<h3 id="init-py"><a href="#init-py" class="headerlink" title="init.py"></a>init.py</h3><p>init.py只有一个public方法，<code>configure_host</code>。该方法的逻辑如下：</p>
<ol>
<li>查看配置项<code>reset_service_password</code>是否为true， 为true则需要先修改cloudbase-init服务用户的密码。如果cloudbase-init使用的是系统内置用户（比如Administrator）或者是域用户则跳过修改，密码为长度20的随机字符串。设置自动修改密码，可以避免克隆虚机时，密码泄露。</li>
<li>等待修改密码并重启完成</li>
<li>开始执行PRE_NETWORKING阶段plugin，PRE_NETWORKING阶段的plugin只有<code>cloudbaseinit.plugins.windows.ntpclient.NTPClientPlugin</code>，如果NTPClientPlugin不在cloudbase-init.conf的plugins配置项内出现，则跳过。NTPClientPlugin具体逻辑请参看plugins章节。</li>
<li>如果需要检查版本，需要到官网地址<code>https://www.cloudbase.it/checkupdates.php</code>获取最新版本并输出日志</li>
<li>开始执行PRE_METADATA_DISCOVERY阶段plugin，PRE_METADATA_DISCOVERY阶段的plugin只有<code>cloudbaseinit.plugins.common.mtu.MTUPlugin</code>，如果MTUPlugin不在cloudbase-init.conf的plugins配置项内出现，则跳过。MTUPlugin具体逻辑请参看plugins章节。</li>
<li>判断PRE_NETWORKING和PRE_METADATA_DISCOVERY阶段是否有立刻重启的返回值（比如如果设置了RTC，就需要重启），如果有就执行重启</li>
<li>如果不需要重启，那么开始执行metadata service。</li>
<li><strong>简单工厂</strong>方式加载配置文件<code>metadata_services</code>选项指定的services，循环执行service的load方法，只要有任何一个load方法正确执行，则返回当前service，停止循环；如果所有的load方法都执行失败，则抛出异常：No available service found，此后MAIN阶段的plugin不会执行。</li>
<li>如果开启<code>metadata_report_provisioning_started</code>，则需要进行服务状态汇报，目前只有AzureService需要。</li>
<li>获取instance__uuid，用来保存每个plugin执行的结果。</li>
<li>执行MAIN阶段的plugins。<strong>简单工厂</strong>方式加载配置文件<code>plugins</code>选项指定的plugins，并且循环执行所有plugin的excute方法。根据excute的返回值来记录plugin的状态和是否需要重启，有任何一个plugin需要重启，则break循环。</li>
<li>如果开启<code>metadata_report_provisioning_completed</code>并且执行失败，则需要进行服务状态汇报，目前只有AzureService需要。</li>
<li>根据plugins的返回结果，判断是否需要重启</li>
<li>如果开启<code>metadata_report_provisioning_completed</code>并且执行成功，则需要进行服务状态汇报，目前只有AzureService需要。</li>
<li>程序结束</li>
</ol>
<h3 id="conf"><a href="#conf" class="headerlink" title="conf"></a>conf</h3><p>包含了cloudbase-init的配置文件提供的配置项。使用了oslo.config第三方包，并且使用oslo.log作为日志工具，oslo.log会自动引入以下配置项，具体每一项的含义参看cloudbase-init的<a href="https://cloudbase-init.readthedocs.io/en/latest/config.html">文档</a>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">debug</span><br><span class="line">log-config-append</span><br><span class="line">log-date-format</span><br><span class="line">log-file</span><br><span class="line">log-dir</span><br><span class="line">watch-log-file</span><br><span class="line">use-syslog</span><br><span class="line">use-journal</span><br><span class="line">syslog_log_facility</span><br><span class="line">use_json</span><br><span class="line">use_stderr</span><br><span class="line">use_eventlog</span><br><span class="line">log_rotate_interval</span><br><span class="line">log_rotate_interval_type</span><br><span class="line">max_logfile_count</span><br><span class="line">max_logfile_size_mb</span><br><span class="line">log_rotation_type</span><br><span class="line">logging_context_format_string</span><br><span class="line">logging_default_format_string</span><br><span class="line">logging_debug_format_suffix</span><br><span class="line">logging_exception_prefix</span><br><span class="line">logging_user_identity_format</span><br><span class="line">default_log_levels</span><br><span class="line">publish_errors</span><br></pre></td></tr></table></figure>

<p>除了log相关的配置项之外，还有一些其他配置，如azure/openstack等平台的特殊参数，我们主要关注的参数位于<code>conf/default.py</code>内，以下几个参数比较重要，其他的请参看<a href="https://cloudbase-init.readthedocs.io/en/latest/config.html">官方文档</a>：</p>
<p>local_scripts_path：本地脚本目录。我们可以在这个目录下放置一些脚本（powershell/python/cmd shell），cloudbase-init会执行该目录下的脚本。比如小酷云版本实现的自动格式化数据盘功能就是一个python的脚本。</p>
<p>metadata_services：已启用的元数据服务类的列表，将按列表的顺序测试其可用性。第一个可用的服务将用于检索元数据，并缓存元数据；之后的service可以从缓存获取数据。</p>
<p>plugins：启用的插件来列表，将按照列表顺序依次执行。插件根据加载的metadata service获取的元数据执行操作。</p>
<h3 id="metadata-service"><a href="#metadata-service" class="headerlink" title="metadata service"></a>metadata service</h3><pre class="mermaid">classDiagram
    BaseMetadataService <|-- BaseHTTPMetadataService
    BaseMetadataService <|-- BaseOpenStackService
    BaseHTTPMetadataService <|-- HttpService
    BaseOpenStackService <|-- HttpService
    BaseMetadataService: -Dict _cache
    BaseMetadataService: -Boolean _enable_retry
    BaseMetadataService: +get_name()
    BaseMetadataService: +load()
    BaseMetadataService: +other_func()
    BaseHTTPMetadataService: -String _base_url
    BaseHTTPMetadataService: -_get_data()
    BaseHTTPMetadataService: -_http_request()
    BaseOpenStackService: +get_user_data()
    BaseOpenStackService: +get_instance_id()
    BaseOpenStackService: +get_host_name()
    BaseOpenStackService: +other_func()
    class HttpService {
        +load()
        +other_func()
    }</pre>

<p>metadata （元数据）服务有：</p>
<ol>
<li>cloudbaseinit.metadata.services.httpservice</li>
<li>cloudbaseinit.metadata.services.configdrive.ConfigDriveService</li>
<li>cloudbaseinit.metadata.services.nocloudservice.NoCloudConfigDriveService</li>
<li>cloudbaseinit.metadata.services.ec2service.EC2Service</li>
<li>cloudbaseinit.metadata.services.cloudstack.CloudStack</li>
<li>cloudbaseinit.metadata.services.opennebulaservice.OpenNebulaService</li>
<li>cloudbaseinit.metadata.services.maasservice.MaaSHttpService</li>
<li>cloudbaseinit.metadata.services.ovfservice.OvfService</li>
<li>cloudbaseinit.metadata.services.packet.PacketService</li>
<li>cloudbaseinit.metadata.services.azureservice.AzureService</li>
<li>cloudbaseinit.metadata.services.base.EmptyMetadataService</li>
<li>cloudbaseinit.metadata.services.vmwareguestinfoservice.VMwareGuestInfoService</li>
<li>cloudbaseinit.metadata.services.gceservice.GCEService</li>
</ol>
<h4 id="httpservice-openstack"><a href="#httpservice-openstack" class="headerlink" title="httpservice[openstack]"></a>httpservice[openstack]</h4><p>HttpService和EC2Service、MaaSHttpService以及CloudStack使用了相同的基类BaseHTTPMetadataService，这4个服务都是基于http服务获取metadata数据的。</p>
<ul>
<li><p>httpService一般用来做Openstack metadata 获取，一般metadata数据所在的http地址是：<code>http://169.254.169.254:80</code>，这个地址可以通过配置文件的<code>metadata_base_url</code>来设置。这个特殊的地址最初是由亚马逊的虚拟计算服务提出的，后由各大厂商继承发展，逐渐成为一个业内通用的做法。这个服务可以提供以下数据：</p>
<ul>
<li>instance id： 虚机的uuid</li>
<li>hostname： 虚机的计算机名字</li>
<li>public keys： ca证书</li>
<li><a href="https://docs.microsoft.com/en-us/windows/win32/winrm/authentication-for-remote-connections#client-certificate-based-authentication">WinRM</a> authentication certificates</li>
<li>static network configuration： 静态网络地址配置</li>
<li>admin user password： admin用户的密码</li>
<li>post admin user password (only once)</li>
<li>user data：user data数据</li>
</ul>
</li>
<li><p>与这个服务相关的配置项有：</p>
<ul>
<li>metadata_base_url (string: “<a href="http://169.254.169.254/%E2%80%9D">http://169.254.169.254/”</a>)</li>
<li>add_metadata_private_ip_route (bool: True)</li>
<li>https_allow_insecure (bool: False)</li>
<li>https_ca_bundle (string: None)</li>
<li>retry_count (integer: 5)</li>
<li>retry_count_interval (integer: 4)</li>
</ul>
</li>
<li><p>代码逻辑</p>
<ul>
<li>由init.py的代码逻辑可以看出，service加载的时候，首先执行service的<code>__init__</code>，其次执行其<code>load()</code>方法。</li>
<li>httpService的<code>__init__</code>方法主要完成了<code>base_url</code>设置，<code>base_url</code>一般是<code>http://169.254.169.254/</code>，可以通过配置文件<code>metadata_base_url</code>修改</li>
<li>load方法主要逻辑为<ul>
<li>设置静态路由，比如<code>169.254.169.254  255.255.255.255   10.221.120.206(网关)   10.221.120.131(本机网卡)      6(跃点数) </code></li>
<li>获取metadata数据，metadata数据路径为：<code>http://169.254.169.254/openstack/latest/meta_data.json</code>。<ul>
<li>zstack平台使用lighttpd作为http server服务，每创建一个虚机，就会在lighttpd的web root目录下添加一个以该虚机IP为名字的目录，目录内放置user_data和meta_data数据。但是如果没有设置虚机的userdata参数，那么zstack不会在lighttpd下创建meta_data数据。所以，在zstack平台，如果需要cloudbase-init成功执行，userdata必须设置，哪怕是一个空字符串。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="ConfigDriveService-openstack"><a href="#ConfigDriveService-openstack" class="headerlink" title="ConfigDriveService[openstack]"></a>ConfigDriveService[openstack]</h4><p>ConfigDriveService可以支持cloudbase-init从一个挂载在虚机的磁盘获取metadata数据而不需要网络连接，通常这种获取metadata数据的方式会比http更快。 ConfigDriveService一般用来支持openstack虚拟化平台。支持ConfigDrive的hypervisors包括 libvirt, XenServer, Hyper-V和VMware。这个磁盘可以是以下类型：</p>
<ul>
<li><p>cdrom_iso</p>
</li>
<li><p>hdd_iso</p>
</li>
<li><p>hdd_vfat</p>
</li>
<li><p>partition_iso</p>
</li>
<li><p>partition_vfat</p>
<p>这里的5种磁盘格式是由cloudbase-init配置文件的<code>types</code>和<code>locations</code>字段控制的。</p>
<ul>
<li><code>types</code>：提供metadata数据的磁盘格式。可选值是vfat和iso。<ul>
<li>vfat，文件分配表（File Allocation Table，FAT），是一种由微软发明并拥有部分专利的文件系统，FAT已被大多数的操作系统支持（包括linux/freeBSD/BeOS）。FAT16性能有限，现在，一般所讲的FAT专指FAT32。VFAT是对基本FAT文件系统的改进，允许为每个文件存储更多信息。vfat格式一般用来做兼容性的设置，默认建议使用iso。另外，在openstack中，vfat格式会限制磁盘大小为64M，详见<a href="https://docs.openstack.org/nova/queens/user/config-drive.html">openstack config drive user guide</a>。</li>
<li>iso，ISO-9660，简称ISO，是通用的光盘文件系统。需要用光驱的方式加载，以kvm方式来说，就是给虚机添加一个cdrom的设备。文件是只读的。</li>
</ul>
</li>
<li><code>locations</code>: 提供metadata数据的磁盘的位置。可选值是cdrom/hdd/partition。<ul>
<li>cdrom: 光驱。光驱设备只能加载iso文件，所以当<code>locations</code>是cdrom时，<code>types</code>只能是iso。</li>
<li>hdd: hard disk drive，硬盘驱动。</li>
<li>partition: 分区或者卷（volume）</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>这个服务可以提供以下数据：</p>
<ul>
<li>instance id： 虚机的uuid</li>
<li>hostname： 虚机的计算机名字</li>
<li>public keys： ca证书</li>
<li>authentication certificates</li>
<li>static network configuration： 静态网络地址配置</li>
<li>admin user password： admin用户的密码</li>
<li>user data：user data数据</li>
</ul>
<p>与这个服务相关的配置项有：</p>
<ul>
<li><del>raw_hdd (bool: True) 将要被弃用</del></li>
<li><del>cdrom (bool: True)将要被弃用</del></li>
<li><del>vfat (bool: True)将要被弃用</del></li>
<li>types (list: [“vfat”, “iso”])</li>
<li>locations (list: [“cdrom”, “hdd”, “partition”])</li>
</ul>
<h3 id="plugins"><a href="#plugins" class="headerlink" title="plugins"></a>plugins</h3><pre class="mermaid">classDiagram
    BasePlugin <|-- NTPClientPlugin
    BasePlugin <|-- AzureGuestAgentPlugin
    BasePlugin <|-- BootStatusPolicyPlugin
    BasePlugin <|-- OtherPlugin
    BasePlugin: +execution_stage
    BasePlugin: +get_name()
    BasePlugin: +get_os_requirements()
    BasePlugin: +execute()
    class NTPClientPlugin{
        +execution_stage
        +execute()
    }</pre>



<p>plugins根据加载的metadata service获取的元数据执行操作。plugins执行的时候分成三个阶段：</p>
<ol>
<li>PRE_NETWORKING：在任何基于网络请求的操作之前执行，用来设置网络。</li>
<li>PRE_METADATA_DISCOVERY：在metadata service执行前执行的一些操作。</li>
<li>MAIN：MAIN阶段执行前，需要metadata service先要获取到当前虚机的instance uuid，instance uuid用来保存每次plugin执行之后的状态（1:执行完成，下次开机跳过。2：下次开机执行）。如果metadata service获取instance uuid过程正常，但是没有得到正确的uuid，比如instance uuid是<code>None</code>，那么每次开机plugins都会执行。但是如果metadata service获取instance uuid过程都出错，比如<code>169.254.169.254</code>地址不通，那么<strong>所有的plugin都不会执行</strong>。</li>
</ol>
<p>每一个阶段内的每个子元素（metada/plugin）都可以设置执行结果的code。</p>
<ul>
<li>1001 - 立刻重启，并且下次重启不再执行</li>
<li>1002 - 现在不重启，下次重启再次执行该plugin</li>
<li>1003 - 重启并且下次开机再次执行</li>
</ul>
<h5 id="PRE-NETWORKING"><a href="#PRE-NETWORKING" class="headerlink" title="PRE_NETWORKING"></a>PRE_NETWORKING</h5><p> PRE_NETWORKING阶段执行的plugin只有一个：时钟同步</p>
<ol>
<li>cloudbaseinit.plugins.windows.ntpclient.NTPClientPlugin<ul>
<li>支持的配置项有：<ul>
<li>ntp_use_dhcp_config (bool: False)是否使用dhcp server提供的NTP来同步时钟，默认是false。</li>
<li>real_time_clock_utc (bool: False)是否修改RTC时间。</li>
<li>ntp_enable_service (bool: True)是否启用ntp自动同步，默认开启</li>
</ul>
</li>
<li>注意：<ul>
<li>可能需要重启（比如修改RTC时间）.</li>
<li>可能每次开机都运行（比如启用dhcp方式，但是本次获取dhcp数据失败，下次开机继续尝试）。</li>
</ul>
</li>
<li>NTPClientPlugin代码逻辑<ul>
<li>检查NTPClientPlugin的系统要求：<code>sys.platform</code>和<code>min_os_version</code>;windows平台下<code>sys.platform</code>返回值为win32/linux/cygwin/darwin分别对应windows/linux/“Windows/Cygwin”/Mac OS X。 NTPClientPlugin对这2这者都不做要求。</li>
<li>执行NTPClientPlugin。判断注册表HKEY_LOCAL_MACHINE目录下路径为<code>SOFTWARE/Cloudbase Solutions/Cloudbase-Init/[instance_uuid]/Plugins/NTPClientPlugin</code>的value，如果value是1（PLUGIN_EXECUTION_DONE）则代表该plugin已经执行成功，不再执行。否则执行NTPClientPlugin的execute方法。</li>
<li>执行NTPClientPlugin的execute方法。判断是否使用dhcp来同步时间、是否启用NTP、是否修改当前RTC时间格式为UTC(需要重启)。</li>
<li>Plugin返回本次执行结果[PLUGIN_EXECUTION_DONE(1)|PLUGIN_EXECUTE_ON_NEXT_BOOT(2)]和是否需要重启</li>
</ul>
</li>
</ul>
</li>
</ol>
<h5 id="PRE-METADATA-DISCOVERY"><a href="#PRE-METADATA-DISCOVERY" class="headerlink" title="PRE_METADATA_DISCOVERY"></a>PRE_METADATA_DISCOVERY</h5><p>PRE_METADATA_DISCOVERY阶段执行的plugin只有一个：设置MTU</p>
<ol>
<li>cloudbaseinit.plugins.common.mtu.MTUPlugin<ul>
<li>支持的配置项有：<ul>
<li>mtu_use_dhcp_config (bool: True)使用dhcp server提供的MTU参数设置网络。OpenStack GRE Neutron Open vSwitch可能会需要设置这个参数。</li>
</ul>
</li>
<li>注意：<ul>
<li>每次开机都运行</li>
</ul>
</li>
<li>MTUPlugin代码逻辑<ul>
<li>mtu参数需要获取当前虚机网卡属性中的<code>dhcp_server</code>，通过dhcp server的ip，发送socket数据包，从回执消息中得到MTU的value.</li>
<li>设置mtu值。windows XP和Windows Server 2003不支持设置MTU。使用python的<code>subprocess.Popen</code>执行<code>netsh.exe</code>命令来设置MTU。</li>
<li>plugin返回 PLUGIN_EXECUTE_ON_NEXT_BOOT（2），无需立刻重启。所以每次虚机开机都会去尝试执行设置MTU。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h5 id="MAIN"><a href="#MAIN" class="headerlink" title="MAIN"></a>MAIN</h5><p>MAIN阶段官方提供的plugin如下，分别是：</p>
<ol>
<li><p>cloudbaseinit.plugins.common.ephemeraldisk.EphemeralDiskPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.common.localscripts.LocalScriptsPlugin</p>
<p>执行本地目录下（配置项local_scripts_path）的脚本，脚本支持 powershell, batch, python等。脚本的返回值可以设置相应的code(1001/1002/1003)来控制是否重启继续执行。</p>
<ul>
<li>重启策略：根据脚本返回值决定</li>
</ul>
</li>
<li><p>cloudbaseinit.plugins.common.networkconfig.NetworkConfigPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.common.sethostname.SetHostNamePlugin</p>
</li>
<li><p>cloudbaseinit.plugins.common.setuserpassword.SetUserPasswordPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.common.sshpublickeys.SetUserSSHPublicKeysPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.common.trim.TrimConfigPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.common.userdata.UserDataPlugin</p>
<p>userdata可以由虚机的创建者或者虚拟化平台自定义，目的是能够把虚机外部的一些参数传进虚机内部，做一些定制化修改。</p>
<p>userdata的文件内容一般会在第一行指定以哪种方式执行：Batch、PowerShell、bash、Python、EC2 format、Cloud config。具体参看<a href="https://cloudbase-init.readthedocs.io/en/latest/userdata.html#">官方文档</a></p>
<ul>
<li>重启策略：根据脚本返回值决定</li>
<li>代码逻辑<ul>
<li>UserDataPlugin核心代码是excute方法。首先通过成功加载的第一个service获取userdata数据，路径是：：<code>http://169.254.169.254/openstack/latest/user_data</code></li>
<li>如果设置了<code>userdata_save_path</code>保存user_data到本地</li>
<li>读取user_data header，识别user data的格式，以及确定使用哪种方式执行。支持的方式有：<ul>
<li>MIME multi-part类型，可以使用jinja2模板渲染内容</li>
<li><code>-----BEGIN CERTIFICATE-----</code>开头的PEM certificate类型</li>
<li><code>#cloud-config</code>开头的类型</li>
<li>其他类型<ul>
<li>先另存user_data数据到临时目录（临时目录根据环境变量’TMPDIR’, ‘TEMP’, ‘TMP’依次获取），并使用一个uuid作为名字，文件名的后缀根据user_data获取，user_data临时文件绝对路径为：<code>$TEMP/$uuid.&lt;后缀&gt;</code>：<ul>
<li><code>rem cmd</code>使用<code>.cmd</code>后缀</li>
<li><code>python</code>使用<code>.py</code>后缀</li>
<li><code>PowerShell</code>使用<code>.ps1</code>后缀</li>
<li>其他的以<code>#!</code>开头的使用<code>.sh</code>后缀</li>
<li>EC2 format无后缀</li>
</ul>
</li>
<li>使用<code>subprocess.Popen</code>来执行具体的命令</li>
<li><strong>策略模式</strong>获取当前类型以及对应的执行该类型脚本的命令。按照以下顺序依次匹配：<ul>
<li>开头有<code>rem cmd</code>执行<code>subprocess.Popen($TEMP/$uuid.cmd, shell=True)</code></li>
<li>开头有<code>#!/usr/bin/env python</code>执行<code>subprocess.Popen(python $TEMP/$uuid.py, shell=False)</code></li>
<li>开头有<code>#!</code>使用<code>subprocess.Popen</code>执行<code>subprocess.Popen(bash $TEMP/$uuid.sh, shell=False)</code></li>
<li>开头有<code>#ps1</code>或者<code>#ps1_sysnative</code>使用<code>subprocess.Popen</code>执行<code>subprocess.Popen(&#39;powershell.exe路径&#39; $TEMP/$uuid.ps1, shell=False)</code></li>
<li>开头有<code>#ps1_x86</code>(Windows On Windows 32bit)使用<code>subprocess.Popen</code>执行<code>subprocess.Popen(&#39;powershell.exe路径&#39; $TEMP/$uuid.ps1, shell=False)</code></li>
<li>user_data内容有<code>&lt;script&gt;一些内容&lt;/script&gt;</code>和<code>&lt;powershell&gt;一些内容&lt;/powershell&gt;</code>这样的标记，使用EC2 format处理。EC2 format其实还是解析内容，再分成bash 和powershell_sysnative方式处理。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>cloudbaseinit.plugins.windows.azureguestagent.AzureGuestAgentPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.bootconfig.BCDConfigPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.bootconfig.BootStatusPolicyPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.certificates.ServerCertificatesPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.createuser.CreateUserPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.displayidletimeout.DisplayIdleTimeoutConfigPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.extendvolumes.ExtendVolumesPlugin</p>
<p>自动扩容磁盘。当磁盘的容量有变更时，虚机开机会自动扩容。比如虚机创建时设置的磁盘为40G, 在虚拟化平台扩容为100G，那么虚机开机之后，会自动扩容磁盘为100G。否则的话，磁盘设备会有一个60G的数据空间为未分配。</p>
<ul>
<li>重启策略：每次开机执行</li>
</ul>
</li>
<li><p>cloudbaseinit.plugins.windows.licensing.WindowsLicensingPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.pagefiles.PageFilesPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.rdp.RDPPostCertificateThumbprintPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.rdp.RDPSettingsPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.sanpolicy.SANPolicyPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.updates.WindowsAutoUpdatesPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.winrmcertificateauth.ConfigWinRMCertificateAuthPlugin</p>
</li>
<li><p>cloudbaseinit.plugins.windows.winrmlistener.ConfigWinRMListenerPlugin</p>
</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>cloudbase-init 善于使用抽象/继承、策略模式、简单工厂模式来组织项目代码。代码看起来井井有条，值得借鉴。</li>
<li>封装了很多windows系统上使用python实现的一些方法，比如获取网络信息/设置MTU/设置计算机名等。与windows的交互使用的是ctypes这个第三方库，它提供了与 C 兼容的数据类型，并允许调用 DLL 或共享库中的函数。可使用该模块以纯 Python 形式对这些库进行封装。</li>
<li>pbr/setuptools等打包方式也可以借鉴。</li>
</ul>
]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>cloudbase-init</tag>
      </tags>
  </entry>
  <entry>
    <title>并发和锁</title>
    <url>/2020/10/20/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/</url>
    <content><![CDATA[<p>在web开过程中，经常会遇到高并发和资源共享的问题，这些问题的本质是：并行的请求转成串行。我们应该考虑的是怎么在尽可能提高吞吐量的情况下，保证资源的合理生产和消耗。</p>
<a id="more"></a>

<h1 id="前置知识点"><a href="#前置知识点" class="headerlink" title="前置知识点"></a>前置知识点</h1><h2 id="锁的实现的非权威解读"><a href="#锁的实现的非权威解读" class="headerlink" title="锁的实现的非权威解读"></a>锁的实现的非权威解读</h2><p>生活当中的锁原理其实很简单，传统的机械锁可以当作是一种机关，通过匹配形状齿轮触发机关某个部位而解锁。而现代的锁原理更简单，加锁其实就是设置一种状态，而要解除该状态只需要比对信息，比如数字密码、指纹等。</p>
<p>计算机中的锁，根据运行环境可以大体分为以下三类：</p>
<ul>
<li><p>同一个进程。此时主要管理该进程的多个线程间同步以及控制并发访问共享资源。由于进程是<strong>共享内存空间</strong>的，一个最简单的实现方式就是使用一个整型变量作为flag，这个flag被所有线程所共享，其值为1表示已上锁，为0表示空闲。使用该方法的前提是设置(set)和获取(get)这个flag变量的值都必须是原子操作，即要么成功，要么失败，并且中间不允许有中断，也不允许出现中间状态。可幸的是，目前几乎所有的操作系统都提供了此类原子操作，并已经引入了锁机制，所以以上前提是可以满足的。</p>
</li>
<li><p>同一个主机。此时需要控制在同一个操作系统下运行的多个进程间如何协调访问共享资源。不同的进程由于不共享内存空间，因此不能通过设置变量来实现。既然内存不能共享，那磁盘是共享的，因此我们自然想到可以通过创建一个文件作为锁标记。进程只需要检查文件是否存在来判断是否有锁。</p>
</li>
<li><p>不同主机。此时通常跑的都是分布式应用，如何保证不同主机的进程同步和避免资源访问冲突。有了前面的例子，相信很多人都想到了，使用共享存储不就可以了，这样不同主机的进程也可以通过检测文件是否存在来判断是否有锁了。[机智表情]</p>
</li>
</ul>
<p>以上介绍了锁的非权威实现，为了解释得更简单通俗，其实隐瞒了很多真正实现上的细节，甚至可能和实际的实现方式并不一致。要想真正深入理解操作系统的锁机制以及单主机的锁机制实现原理，请查阅更多的文献。</p>
<h1 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h1><p>我们经常遇到多进程/多线程的服务，以此来提高吞吐量，但是也会带来一些问题。</p>
<p>测试代码如下：<br><code>main.py</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from json import dumps as json_dumps</span><br><span class="line">from bottle import put, get, run, request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@put(&#39;&#x2F;todos&#39;)</span><br><span class="line">def modify():</span><br><span class="line"># w:可读写，打开时清空文件</span><br><span class="line">with open(&quot;file_db.txt&quot;, &#39;w&#39;, encoding&#x3D;&#39;utf8&#39;) as f:</span><br><span class="line">query &#x3D; request.query[&quot;index&quot;]</span><br><span class="line">f.write(query)</span><br><span class="line">with open(&quot;file_db.txt&quot;, &#39;r&#39;, encoding&#x3D;&#39;utf8&#39;) as f:</span><br><span class="line">read_content &#x3D; f.read()</span><br><span class="line">print(&quot;read_content&quot;, read_content)</span><br><span class="line">return json_dumps(read_content)</span><br><span class="line"></span><br><span class="line">@get(&#39;&#x2F;todos&#39;)</span><br><span class="line">def lists():</span><br><span class="line">with open(&quot;file_db.txt&quot;, &#39;r&#39;, encoding&#x3D;&#39;utf8&#39;) as f:</span><br><span class="line">read_content &#x3D; f.read()</span><br><span class="line">print(&quot;read_content&quot;, read_content)</span><br><span class="line">return json_dumps(read_content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">run(host&#x3D;&#39;0.0.0.0&#39;, port&#x3D;7000)</span><br></pre></td></tr></table></figure>
<p>使用bottle默认wsgiref(单进程单线程)做基础代码，之后在此之上进行修改测试验证。<br>验证内容为： 往文件写内容，写的方式为：覆盖写。</p>
<p>使用就jmeter做并发测试<br>jmeter配置如下：<br>线程组：</p>
<ul>
<li>线程数： 10</li>
<li>ramp-up: 0</li>
<li>循环次数： 1<br>http请求：</li>
<li>协议： http</li>
<li>ip: 10.221.103.233</li>
<li>port: 7000</li>
<li>method: PUT</li>
<li>url: /todos?index=${__Random(1,100,)}</li>
</ul>
<h2 id="1-service-1-Process-1-Thread"><a href="#1-service-1-Process-1-Thread" class="headerlink" title="1 service + 1 Process + 1 Thread"></a>1 service + 1 Process + 1 Thread</h2><p>基础代码即为单服务单进程单线程.并发测试结果为：request返回值和写入的值相等。<br>结论：单服务单进程单线程天然串行，不存在并发问题，不需要锁控制。</p>
<h2 id="1-service-1-Process-n-Thread"><a href="#1-service-1-Process-n-Thread" class="headerlink" title="1 service + 1 Process + n Thread"></a>1 service + 1 Process + n Thread</h2><p>修改服务启动命令为：<code>run(host=&#39;0.0.0.0&#39;, port=7000, server=&#39;paste&#39;, threadpool_workers=10)</code><br>使用paste作为server.paste使用线程池来实现。<br>并发测试结果为：request返回值和写入的值不一定相等。</p>
<h2 id="1-service-n-Process-1-Thread"><a href="#1-service-n-Process-1-Thread" class="headerlink" title="1 service + n Process + 1 Thread"></a>1 service + n Process + 1 Thread</h2><p>修改服务启动命令为：<code>run(host=&#39;0.0.0.0&#39;, port=7000, server=&#39;gunicorn&#39;, workers=2)</code><br>使用gunicorn作为server.gunicorn使用pre-fork来实现, 实现类默认为sync。<br>并发测试结果为：request返回值和写入的值不一定相等。</p>
<h2 id="1-service-n-Process-n-Thread"><a href="#1-service-n-Process-n-Thread" class="headerlink" title="1 service + n Process + n Thread"></a>1 service + n Process + n Thread</h2><p>修改服务启动命令为：<code>run(host=&#39;0.0.0.0&#39;, port=7000, server=&#39;gunicorn&#39;, workers=2, threads=2)</code><br>使用gunicorn作为server.gunicorn使用pre-fork来实现, 实现类默认为threads。<br>并发测试结果为：request返回值和写入的值不一定相等。</p>
<h2 id="n-service"><a href="#n-service" class="headerlink" title="n service"></a>n service</h2><ul>
<li>n service 部署在一个机器上, 每个service port 不同：可以通过nginx进行分发</li>
<li>n service 部署在n机器上, 共享资源需要放到DB或者多个service访问某个指定位置的文件： 可以通过nginx进行分发</li>
</ul>
<p>并发测试结果为：request返回值和写入的值不一定相等。<br><strong>以上情况，只要存在并发就需要考虑资源抢占问题，就需要引入锁。</strong></p>
<h1 id="python内置线程锁"><a href="#python内置线程锁" class="headerlink" title="python内置线程锁"></a>python内置线程锁</h1><p>python线程锁： threading.Lock<br>装饰器实现线程锁</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> json <span class="keyword">import</span> dumps <span class="keyword">as</span> json_dumps</span><br><span class="line"><span class="keyword">from</span> bottle <span class="keyword">import</span> put, get, run, request</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"></span><br><span class="line">LOCK = threading.Lock()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">thread_lock</span>(<span class="params">f</span>):</span></span><br><span class="line"><span class="meta">@wraps(f)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inner</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">LOCK.acquire()</span><br><span class="line">ret = f(*args, **kwargs)</span><br><span class="line"><span class="keyword">return</span> ret</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line"><span class="keyword">if</span> LOCK.locked():</span><br><span class="line">LOCK.release()</span><br><span class="line"><span class="keyword">return</span> inner</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@put(&#x27;/todos&#x27;)</span></span><br><span class="line"><span class="meta">@thread_lock</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">modify</span>():</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">&quot;/root/workspace/concurrence/1service1process1thread/file_db.txt&quot;</span>, <span class="string">&#x27;w+&#x27;</span>, encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">query = request.query[<span class="string">&quot;index&quot;</span>]</span><br><span class="line">f.write(query)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">&quot;/root/workspace/concurrence/1service1process1thread/file_db.txt&quot;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">read_content = f.read()</span><br><span class="line">print(<span class="string">&quot;read_content&quot;</span>, read_content)</span><br><span class="line"><span class="keyword">return</span> json_dumps(read_content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">run(host=<span class="string">&#x27;0.0.0.0&#x27;</span>, port=<span class="number">7000</span>, server=<span class="string">&#x27;paste&#x27;</span>, threadpool_workers=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>使用线程锁可以控制单进程多线程的并发。在jmeter测试之下，参数、返回结果、文件内容一致。</p>
<h1 id="文件锁"><a href="#文件锁" class="headerlink" title="文件锁"></a>文件锁</h1><p>使用fcntl模块实现文件锁，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file_lock</span>(<span class="params">f, lock_type=fcntl.LOCK_EX</span>):</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">fcntl模块：</span></span><br><span class="line"><span class="string">flock() : flock(f, operation)</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">operation : 包括：</span></span><br><span class="line"><span class="string">     fcntl.LOCK_UN 解锁</span></span><br><span class="line"><span class="string">     fcntl.LOCK_EX  排他锁, 除加锁进程外其他进程没有对已加锁文件读写访问权限。</span></span><br><span class="line"><span class="string">fcntl.LOCK_SH  共享锁, 所有进程没有写访问权限，即使是加锁进程也没有。所有进程有读访问权限。</span></span><br><span class="line"><span class="string">fcntl.LOCK_NB  非阻塞锁, 如果指定此参数，函数不能获得文件锁就立即返回，否则，函数会等待获得文件锁。</span></span><br><span class="line"><span class="string">LOCK_NB可以同LOCK_SH或LOCK_EX进行按位或（|）运算操作，fcnt.flock(f, fcntl.LOCK_EX|fcntl.LOCK_NB)</span></span><br><span class="line"><span class="string">这个意思是：无论是否请求到锁，函数立即返回</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">POSIX locks:</span></span><br><span class="line"><span class="string">lockf() most of the time implemented as just an interface of fcntl()</span></span><br><span class="line"><span class="string">fcntl() locks are bound to processes, not file descriptors.</span></span><br><span class="line"><span class="string">If a process has multiple open file descriptors for a particular file,</span></span><br><span class="line"><span class="string">any one of these file descriptors used for acquiring locking will RESET the lock.</span></span><br><span class="line"><span class="string">BSD lock:</span></span><br><span class="line"><span class="string">flock() locks are bound to file descriptors, not processes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">:param f: 执行的函数体</span></span><br><span class="line"><span class="string">:param lock_type:默认排他锁</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="meta">@wraps(f)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inner</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">lock_f = open(<span class="string">&#x27;/var/lock/my_lock&#x27;</span>, <span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">print(<span class="string">&quot;lock wait&quot;</span>)</span><br><span class="line">fcntl.lockf(lock_f, fcntl.LOCK_EX | fcntl.LOCK_NB) <span class="comment"># 由于lockf 绑定的是进程，所以只能用在多进程的时候进行加锁。</span></span><br><span class="line">print(<span class="string">&quot;lock file: [%s]&quot;</span> % lock_f.read())</span><br><span class="line">print(<span class="string">&quot;lock acquire&quot;</span>)</span><br><span class="line"><span class="keyword">return</span> f(*args, **kwargs)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">print(<span class="string">&quot;lock release&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> lock_f:</span><br><span class="line">fcntl.lockf(lock_f, fcntl.LOCK_UN)</span><br><span class="line">lock_f.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> inner</span><br></pre></td></tr></table></figure>

<p>由于lockf 绑定的是进程，所以只能用在多进程的时候进行加锁，在多线程中是不起作用的。</p>
<p>在Linux中有三个文件锁接口函数flock(…)、fcntl(…)、lockf(…)，这三个接口可以创建Linux中不同类型的锁。下面简单介绍一下Linux中不同类型的锁<br>Linux中支持四种功能的文件锁：劝告锁、强制锁、租赁锁、共享模式锁，其中后两种锁都是强制锁的变种。</p>
<table>
<thead>
<tr>
<th>锁的类型</th>
<th>实现接口</th>
<th>锁的功能</th>
</tr>
</thead>
<tbody><tr>
<td>劝告锁</td>
<td>flock(…) fcntl(…) lockf(…)</td>
<td>劝告锁是一种协同工作的锁。对于这一种锁来说，内核只提供加锁以及检测文件是否已经加锁的手段，但是内核并不参与锁的控制和协调。</td>
</tr>
<tr>
<td>强制锁</td>
<td>fcntl(…) lockf(…)</td>
<td>强制锁是一种内核强制采用的文件锁。每当有系统调用 open()、read() 以及write()发生的时候，内核都要检查并确保这些系统调用不会违反在所访问文件上加的强制锁约束。</td>
</tr>
<tr>
<td>租赁锁</td>
<td>fcntl(…)</td>
<td>租赁锁实际上是强制锁的变种，当进程尝试打开一个被租借锁保护的文件时，该进程会被阻塞，同时，在一定时间内拥有该文件租借锁的进程会收到一个信号。收到信号之后，拥有该文件租借锁的进程会首先更新文件，从而保证了文件内容的一致性，接着，该进程释放这个租借锁。如果拥有租借锁的进程在一定的时间间隔内没有完成工作，内核就会自动删除这个租借锁或者将该锁进行降级，从而允许被阻塞的进程继续工作。</td>
</tr>
<tr>
<td>共享模式锁</td>
<td>flock(…)</td>
<td>共享模式强制锁可以用于某些私有网络文件系统，如果某个文件被加上了共享模式强制锁，那么其他进程打开该文件的时候不能与该文件的共享模式强制锁所设置的访问模式相冲突。但是由于可移植性不好，因此并不建议使用这种锁。</td>
</tr>
</tbody></table>
<p>关于flock(…)、lockf（…）、fcntl(…)的说明：</p>
<ul>
<li>flock(…)：适用于劝告锁，只能实现对整个文件进行加锁，而不能实现记录级的加锁。但是flock实现了共享强制锁；</li>
<li>fcntl(…)：适用于劝告锁和强制锁，不仅能够对整个文件进行加锁，而且能够对文件中的记录(若干字节)加锁，实际上属于posix系列的锁。</li>
<li>lockf(…)：由于fcntl(…)函数功能非常多，文件锁只是其中一个。lockf(…)是fcntl(…)锁功能的包装。</li>
</ul>
<h1 id="数据库锁"><a href="#数据库锁" class="headerlink" title="数据库锁"></a>数据库锁</h1><h2 id="数据库-乐观锁"><a href="#数据库-乐观锁" class="headerlink" title="数据库-乐观锁"></a>数据库-乐观锁</h2><p>乐观锁（Optimistic Lock），顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。乐观锁适用于读多写少的应用场景，这样可以提高吞吐量。</p>
<p>乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。</p>
<p>乐观锁一般来说有以下2种方式：</p>
<ul>
<li>使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。</li>
<li>使用时间戳（timestamp）。乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。<br>Java JUC中的atomic包就是乐观锁的一种实现，AtomicInteger 通过CAS（Compare And Set，是一种自旋锁）操作实现线程安全的自增。</li>
</ul>
<h2 id="数据库-悲观锁"><a href="#数据库-悲观锁" class="headerlink" title="数据库-悲观锁"></a>数据库-悲观锁</h2><p>悲观锁（Pessimistic Lock），顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。</p>
<p>悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。</p>
<p>Java synchronized 就属于悲观锁的一种实现，每次线程要修改数据时都先获得锁，保证同一时刻只有一个线程能操作数据，其他线程则会被block。</p>
<h2 id="举例如下"><a href="#举例如下" class="headerlink" title="举例如下"></a>举例如下</h2><p>假设，MySQL数据库中商品库存表tb_product_stock 结构定义如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`product`</span> (</span><br><span class="line"><span class="string">`id`</span> <span class="built_in">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT <span class="keyword">COMMENT</span> <span class="string">&#x27;自增ID&#x27;</span>,</span><br><span class="line"><span class="string">`product_id`</span> <span class="built_in">bigint</span>(<span class="number">32</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">&#x27;商品ID&#x27;</span>,</span><br><span class="line"><span class="string">`number`</span> <span class="built_in">INT</span>(<span class="number">8</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="number">0</span> <span class="keyword">COMMENT</span> <span class="string">&#x27;库存数量&#x27;</span>,</span><br><span class="line"><span class="string">`create_time`</span> DATETIME <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line"><span class="string">`modify_time`</span> DATETIME <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">&#x27;更新时间&#x27;</span>,</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>),</span><br><span class="line"><span class="keyword">UNIQUE</span> <span class="keyword">KEY</span> <span class="string">`index_pid`</span> (<span class="string">`product_id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8 <span class="keyword">COMMENT</span>=<span class="string">&#x27;商品库存表&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>悲观锁. <em><code>SELECT ... FOR UPDATE</code></em></p>
<ul>
<li>sql语句写法<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">updateStock</span><span class="params">(Long productId)</span></span>&#123;</span><br><span class="line">    <span class="comment">//先锁定商品库存记录</span></span><br><span class="line">    ProductStock product = query(<span class="string">&quot;SELECT * FROM tb_product_stock WHERE product_id=#&#123;productId&#125; FOR UPDATE&quot;</span>, productId);</span><br><span class="line">    <span class="keyword">if</span> (product.getNumber() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> updateCnt = update(<span class="string">&quot;UPDATE tb_product_stock SET number=number-1 WHERE product_id=#&#123;productId&#125;&quot;</span>, productId);</span><br><span class="line">        <span class="keyword">if</span>(updateCnt &gt; <span class="number">0</span>)&#123; <span class="comment">//更新库存成功</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>python sqlalchemy写法</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sqlalchemy.engine <span class="keyword">import</span> create_engine</span><br><span class="line"><span class="keyword">from</span> sqlalchemy.orm <span class="keyword">import</span> sessionmaker</span><br><span class="line">engine = create_engine(db.url)</span><br><span class="line">session = sessionmaker(autocommit=<span class="literal">True</span>)(bind=engine)</span><br><span class="line"><span class="keyword">with</span> session.begin(subtransactions=<span class="literal">True</span>):</span><br><span class="line">session.Query(Product).with_for_update().filter_by(id=product_id).first()</span><br><span class="line">session.Query(Product).filter_by(id=product_id).update(&#123;<span class="string">&quot;number&quot;</span>: number<span class="number">-1</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>乐观锁.</p>
<ul>
<li>sql写法</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">updateStock</span><span class="params">(Long productId)</span></span>&#123;</span><br><span class="line"><span class="keyword">int</span> updateCnt = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (updateCnt == <span class="number">0</span>) &#123;</span><br><span class="line">    ProductStock product = query(<span class="string">&quot;SELECT * FROM tb_product_stock WHERE product_id=#&#123;productId&#125;&quot;</span>, productId);</span><br><span class="line">    <span class="keyword">if</span> (product.getNumber() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        updateCnt = update(<span class="string">&quot;UPDATE tb_product_stock SET number=number-1 WHERE product_id=#&#123;productId&#125; AND number=#&#123;number&#125;&quot;</span>, productId, product.getNumber());</span><br><span class="line">        <span class="keyword">if</span>(updateCnt &gt; <span class="number">0</span>)&#123; <span class="comment">//更新库存成功</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">//卖完啦</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>python sqlalchemy写法</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sqlalchemy.engine <span class="keyword">import</span> create_engine</span><br><span class="line"><span class="keyword">from</span> sqlalchemy.orm <span class="keyword">import</span> sessionmaker</span><br><span class="line">engine = create_engine(db.url)</span><br><span class="line">session = sessionmaker(autocommit=<span class="literal">True</span>)(bind=engine)</span><br><span class="line"><span class="keyword">with</span> session.begin(subtransactions=<span class="literal">True</span>):</span><br><span class="line">product = session.Query(Product).filter_by(id=product_id).first()</span><br><span class="line">session.Query(Product).filter_by(id=product_id, number=product.number).update(&#123;<span class="string">&quot;number&quot;</span>: number<span class="number">-1</span>&#125;)</span><br></pre></td></tr></table></figure>

<p><strong>乐观锁与悲观锁的区别</strong>:<br>乐观锁的思路一般是表中增加版本字段，更新时where语句中增加版本的判断，算是一种CAS（Compare And Swep）操作，商品库存场景中number起到了版本控制（相当于version）的作用（ AND number=#{number}）。</p>
<p>悲观锁之所以是悲观，在于他认为本次操作会发生并发冲突，所以一开始就对商品加上锁（SELECT … FOR UPDATE），然后就可以安心的做判断和更新，因为这时候不会有别人更新这条商品库存。</p>
<h2 id="sqlalchemy实现探究"><a href="#sqlalchemy实现探究" class="headerlink" title="sqlalchemy实现探究"></a>sqlalchemy实现探究</h2><h3 id="with-for-update详解"><a href="#with-for-update详解" class="headerlink" title="with_for_update详解"></a>with_for_update详解</h3><p>SQLAlchemy 提供 with_for_update 函数 进行 锁的操作 .</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">session.Query(User).with_for_update().first()</span><br><span class="line">session.Query(User).with_for_update(read&#x3D;True).first()</span><br></pre></td></tr></table></figure>
<p>完整形式为：<br><code>with_for_update(read=False, nowait=False, of=None)</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- read</span><br><span class="line">是标识加互斥锁还是共享锁. 当为 True 时, 即 for share 的语句, 是共享锁. 多个事务可以获取共享锁, 互斥锁只能一个事务获取. 有&quot;多个地方&quot;都希望是&quot;这段时间我获取的数据不能被修改, 我也不会改&quot;, 那么只能使用共享锁.</span><br><span class="line">- nowait</span><br><span class="line">其它事务碰到锁, 是否不等待直接&quot;报错&quot;.</span><br><span class="line">- of</span><br><span class="line">指明上锁的表, 如果不指明, 则查询中涉及的所有表(行)都会加锁.</span><br></pre></td></tr></table></figure>
<p>在用SQLAlchemy对数据库操作的过程中出现这样一个现象，当在session.query()时，如果之前有session.add()操作，即使尚未进行commit操作，在query时也会查询到这个尚未真正插入数据库的对象</p>
<h3 id="关于行锁和表锁"><a href="#关于行锁和表锁" class="headerlink" title="关于行锁和表锁"></a>关于行锁和表锁</h3><ul>
<li>由于InnoDB 预设是Row-Level Lock，所以只有「明确」的指定主键或者其他索引的键，MySQL 才会执行Row lock (只锁住被选取的数据) ，否则mysql 将会执行Table Lock (将整个数据表单给锁住)。</li>
<li>只锁住被选取的数据的好处是：多线程时，如果其他线程使用的是非锁住的数据，则不会受影响，无需等待解锁，更好的实现了并发。</li>
<li>select for update获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。</li>
<li>在数据库内部update同一行的时候是不允许并发的，即数据库每次执行一条update语句时会获取被update行的写锁，直到这一行被成功更新后才释放。</li>
<li>另外：mysql的MyAsim引擎只支持表级锁，InnerDB支持行级锁</li>
<li>MySQL InnoDB采用的是两阶段锁定协议（two-phase locking protocol）。在事务执行过程中，随时都可以执行锁定，锁只有在执行 COMMIT或者ROLLBACK的时候才会释放，并且所有的锁是在同一时刻被释放。</li>
<li>MySQL隐式和显示锁定</li>
<li>隐式加锁</li>
</ul>
<ul>
<li>InnoDB自动加意向锁。</li>
<li>对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁</li>
<li>对于普通SELECT语句，InnoDB不会加任何锁；</li>
</ul>
<ul>
<li>显示加锁：</li>
</ul>
<ul>
<li>共享锁（S）：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE</li>
<li>排他锁（X) ：SELECT * FROM table_name WHERE … FOR UPDATE</li>
</ul>
<ul>
<li>锁参考： <a href="https://blog.csdn.net/zcl_love_wx/article/details/81983267">https://blog.csdn.net/zcl_love_wx/article/details/81983267</a></li>
<li>mysql索引参看 <a href="https://www.cnblogs.com/cq-home/p/3482101.html">https://www.cnblogs.com/cq-home/p/3482101.html</a></li>
</ul>
<p>openstack的多个组件，比如nova/cinder等都用到了锁来实现并发的控制。openstack 的oslo.* 模块是一个公用模块，一些常用的如下：</p>
<table>
<thead>
<tr>
<th>库名</th>
<th>作用</th>
<th>背景知识</th>
</tr>
</thead>
<tbody><tr>
<td>oslo.config</td>
<td>配置文件</td>
<td>无</td>
</tr>
<tr>
<td>oslo.utils</td>
<td>工具库</td>
<td>无</td>
</tr>
<tr>
<td>oslo.log + oslo.context</td>
<td>带调用链的日志系统</td>
<td>无</td>
</tr>
<tr>
<td>oslo.messaging</td>
<td>RPC调用</td>
<td>amqp</td>
</tr>
<tr>
<td>oslo.service</td>
<td>带ssl的REST服务器</td>
<td>wsgi</td>
</tr>
<tr>
<td>oslo.db</td>
<td>数据库</td>
<td>sqlalchemy</td>
</tr>
<tr>
<td>oslo.rootwrap</td>
<td>Linux的sudo</td>
<td>无</td>
</tr>
<tr>
<td>oslo.serialization</td>
<td>序列化</td>
<td>无</td>
</tr>
<tr>
<td>oslo.i18n</td>
<td>国际化</td>
<td>无</td>
</tr>
<tr>
<td>oslo.policy</td>
<td>权限系统</td>
<td>deploy paste</td>
</tr>
<tr>
<td>oslo.middleware</td>
<td>pipeline</td>
<td>deploy paste</td>
</tr>
<tr>
<td>keystonemiddleware</td>
<td>用户系统</td>
<td>deploy paste + keystone</td>
</tr>
<tr>
<td>oslo_test</td>
<td>测试</td>
<td>unittest</td>
</tr>
<tr>
<td>oslo.concurrency</td>
<td>多进程/线程管理</td>
<td>threading/fcntl</td>
</tr>
</tbody></table>
<p>本文重点使用oslo.concurrency.</p>
<h1 id="oslo-concurrency-lockutils"><a href="#oslo-concurrency-lockutils" class="headerlink" title="oslo.concurrency.lockutils"></a><code>oslo.concurrency.lockutils</code></h1><ul>
<li>InterProcessLock：进程锁。基于fasteners实现，fasteners根据操作系统具体实现有所区分，其中linux系统的实现是<code>fcntl.lockf</code></li>
<li>ReaderWriterLock：读写锁。读写锁实际是一种特殊的<strong>自旋锁（CAS:Compare and Set）</strong>，它把对共享资源的访问者划分成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源进行写操作。fasteners通过ReadWriterLock类实现了读锁和写锁，其在该类中定义了READER和WRITER标识分别表示申请的锁是读锁还是写锁。使用该类可以获得多个读锁，但只能存在一个写锁。在目前的版本中，该类不能实现从读写升级到写锁，且写锁在加锁时不能获取读锁；而以后可能会对这些问题进行优化。该类的主要方法如下：<ul>
<li><code>read_lock()</code>：为当前线程申请一个读锁，其只有在没有为其他线程分配写锁时才能获取成功；如果另一个线程以及获取了写锁，调用该方法会返回RuntimeError异常。</li>
<li><code>write_lock()</code>：为当前线程申请一个写锁，其只有在没有为其他线程分配读锁或写锁时才能获取成功；一旦申请写锁成功，将会阻塞申请读锁的线程。</li>
<li><code>is_reader()</code>：判断当前线程是否申请了读锁。</li>
<li><code>is_writer()</code>：判断当前线程是否申请了写锁，或已申请但尚未获得写锁。</li>
<li><code>owner()</code>：判断当前线程是否申请了锁；如果获得了锁是读锁还是写锁。<br>ReaderWriterLock类中包含<code>_writer</code>属性表示占有写锁的线程，<code>_readers</code>属性表示占有读锁的线程集合，<code>_pending_writers</code>属性表示正在等待分配写锁的线程的队列，<code>_current_thread</code>属性表示当前线程，<code>_cond</code>属性表示threading.Condition对象。上述的这些方法就是通过操作这几个属性实现读写锁的。</li>
</ul>
</li>
<li>FairLocks: 读写锁。实现原理是基于python的<code>弱引用对象</code>–<code>weakref.WeakValueDictionary()</code>实现的一个字典，字典的key是lock name，value是<code>ReaderWriterLock</code>对象。<strong>弱引用对象可以解决循环引用内存泄漏问题。</strong></li>
<li>Semaphores：线程锁。也利用了弱引用对象。只不过<code>WeakValueDictionary</code>字典的value是<code>threading.Semaphore()</code>.</li>
<li>external_lock: 进程锁。核心还是<code>InterProcessLock</code>,与<code>InterProcessLock</code>区别是可以自定义设置lock 文件的位置。</li>
<li>remove_external_lock_file： 删除lock文件方法</li>
<li>internal_lock: 线程锁。可以指定<code>Semaphore</code>的具体实现方法，比如：<code>eventlet.semaphore.Semaphore</code>,如果没有指定，默认使用<code>threading.Semaphore()</code></li>
<li>lock: 这个是一个综合方法，参数比较多，根据参数可以实现FairLocks、internal_lock、external_lock的其中一种。</li>
<li>lock_with_prefix： 可以指定带有统一前缀的lock。目的是可以统一clean lock文件。调用lock来实现。</li>
<li>synchronized： 是一个装饰器方法。封装lock方法。<br>其他方法不再一一列举，功能就是以上方法的再次封装运用。</li>
</ul>
<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><p>分布式锁主要解决的是分布式资源访问冲突的问题，保证数据的一致性。使用共享存储文件作为锁标记，这种方案只有理论意义，实际上几乎没有人这么用，因为创建文件并不能保证是原子操作。另一种可行方案是使用传统数据库存储锁状态，实现方式也很简单，检测锁时只需要从数据库中查询锁状态即可。当然，可能使用传统的关系型数据库性能不太好，因此考虑使用KV-Store缓存数据库，比如Redis、Memcached等。但都存在问题：</p>
<ul>
<li><p>不支持堵塞锁。即进程获取锁时，不会自己等待锁，只能通过不断轮询的方式判断锁的状态，性能不好，并且不能保证实时性。</p>
</li>
<li><p>不支持可重入。所谓可重入锁就是指当一个进程获取了锁时，在释放锁之前能够无限次重复获取该锁。试想下，如果锁是不可重入的，一个进程获取锁后，运行过程中若再次获取锁时，就会不断循环获取锁，可实际上锁就在自己的手里，因此将永久进入死锁状态。当然也不是没法实现，你可以顺便存储下主机和进程ID，如果是相同的主机和进程获取锁时则自动通过，还需要保存锁的使用计数，当释放锁时，简单的计数-1，只有值为0时才真正释放锁。</p>
</li>
<li><p>另外，锁需要支持设置最长持有时间。想象下，如果一个进程获取了锁后突然挂了，如果没有设置最长持有时间，锁就永远得不到释放，成为了该进程的陪葬品，其他进程将永远获取不了锁而陷入永久堵塞状态，整个系统将瘫痪。使用传统关系型数据库可以保存时间戳，设置失效时间，实现相对较复杂。而使用缓存数据库，通常这类数据库都可以设置数据的有效时间，因此相对容易实现。不过需要注意不是所有的场景都适合通过锁抢占方式恢复，有些时候事务执行一半挂了，也不能随意被其他进程强制介入。</p>
</li>
</ul>
<p>支持可重入和设置锁的有效时间其实都是有方法实现，但要支持堵塞锁，则依赖于锁状态的观察机制，如果锁的状态一旦变化就能立即通知调用者并执行回调函数，则实现堵塞锁就很简单了。庆幸的是，分布式协调服务就支持该功能，Google的Chubby就是非常经典的例子，Zookeeper是Chubby的开源实现，类似的还有后起之秀Etcd等。这些协调服务有些类似于KV-Store，也提供get、set接口，但也更类似于一个分布式文件系统。以Zookeeper为例，它通过瞬时有序节点标识锁状态，请求锁时会在指定目录创建一个瞬时节点，节点是有序的，Zookeeper会把锁分配给节点最小的服务。</p>
<p>Zookeeper支持watcher机制，一旦节点变化，比如节点删除(释放锁)，Zookeeper会通知客户端去重新竞争锁，从而实现了堵塞锁。另外，Zookeeper支持临时节点的概念，在客户进程挂掉后，临时节点会自动被删除，这样可实现锁的异常释放，不需要给锁增加超时功能了。</p>
<p>提供分布式锁服务的应用我们通常称为DLM(Distributed lock manager):<br><img src="/images/dlm.png" alt="dlm"></p>
<p>注: 以上支持度仅考虑最简单实现，不涉及高级实现，比如传统数据库以及缓存数据库也是可以实现可重入的，只是需要花费更多的工作量。</p>
<h2 id="CAP概念"><a href="#CAP概念" class="headerlink" title="CAP概念"></a>CAP概念</h2><p>2000年Eric Brewer教授提出CAP猜想，2年后CAP猜想被Seth Gilbert和Nancy Lynch从理论上证明。CAP是Consitency（强一致性）、Availability（可用性）、Partition tolerance（网络分区容忍性）三个不同维度的组合体，如图所示<br><img src="/images/cap.png" alt="CAP"></p>
<p>CA ：没有网络分区，即：单点环境，这里我们不需要讨论<br>CP: 分布式环境，强制一致性<br>AP：分布式环境，最终一致性</p>
<h2 id="分布式锁的本质"><a href="#分布式锁的本质" class="headerlink" title="分布式锁的本质"></a>分布式锁的本质</h2><p>通过业务需求剖析业务背后的本质，是架构师需要具备的核心能力之一。<br>分布式锁的本质是对共享资源串行化处理。<br>我们要保证同一把分布式锁的申请在同一时刻只能有一个服务拿到此锁，因此从CAP模型底层分析，分布式锁是CP模型。<br>一切脱离场景谈架构都是耍流氓，特别是脱离业务场景。业务场景分为2类：追求数据强一致性场景、追求数据最终一致性场景。<br>数据强一致性场景比如金融、电商交易等，使用分布式锁时需要使用CP模型，不然就会出现支付去重失败等重大问题，此时公司离破产只差用户一个大请求；数据最终一致性场景比如微信发消息等，在使用分布式锁时使用AP模型较优雅，比如对用户发送消息（今晚有空吗？约个饭）的去重，极端情况下使用分布式锁去重失败，也就是消息发送到对方2次，反而会增加彼此之间的感情，本来要拒绝邀请的，由于收到2次邀请消息，结果就不好意思拒绝了。<br><img src="/images/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AF%B9%E6%AF%94.png" alt="分布式锁实现方式对比"><br>从架构设计哲学层面分析，分布式锁本质上是CP模型。一切脱离场景谈架构设计都是耍流氓，因此我们需要针对业务场景的不同，选用优雅的分布式锁实现，在追求数据强一致性的业务场景中，选用CP存储模型，在追求数据最终一致性的业务场景中，选用AP存储模型。</p>
<h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><h3 id="方法一：redis"><a href="#方法一：redis" class="headerlink" title="方法一：redis"></a>方法一：redis</h3><p>Redis 2.6.12及以上的版本:<br><code>Set 1009 100 NX PX 10000 // 设置key为1009的value为100，仅当key不存在时设置成功，并且设置key的生存时间为10000毫秒</code></p>
<p>或者：<br><code>Set 1009 100 NX EX 10 // 设置key为1009的value为100，仅当key不存在时设置成功，并且设置key的生存时间为10秒</code></p>
<p>Redis 2.6.12下的版本（redis事务）:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MULTI;</span><br><span class="line">SETNX 1009 100;</span><br><span class="line">EXPIRE 1009 10;</span><br><span class="line">EXEC;</span><br></pre></td></tr></table></figure>
<h4 id="redis-优缺点"><a href="#redis-优缺点" class="headerlink" title="redis 优缺点"></a>redis 优缺点</h4><ul>
<li>优：实现简单</li>
<li>缺：</li>
</ul>
<ul>
<li>redis 如果是单节点有 单点故障问题</li>
<li>redis 如果使用主从模式的集群部署，Sentinal哨兵机制进行主从切换时，可能会造成数据不一致</li>
<li>CAP模型： redis集群主从模式是AP模型</li>
</ul>
<h3 id="方法二：etcd"><a href="#方法二：etcd" class="headerlink" title="方法二：etcd"></a>方法二：etcd</h3><p>etcd有V2和V3两种接口：V2接口可以使用http直接访问，天然客户端物理解耦，但需要自动续租保证锁的完整性。V3接口默认grpc形式，是长链接机制，天然续租，但grpc有客户端依赖要求。可以根据场景要求，适度选择合适版本接口。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">锁参数有：</span><br><span class="line">prevExits：检查是否存在，true：新增，false：更新；</span><br><span class="line">prevIndex：检查上一个的key，既操作返回的uuid；</span><br><span class="line">prevValue：检查上一个的值；</span><br></pre></td></tr></table></figure>
<p>v2:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">取锁：curl http:&#x2F;&#x2F;ip:port&#x2F;v2&#x2F;keys&#x2F;锁名 -XPUT -d ttl&#x3D;10 -d prevExits&#x3D;false -d value&#x3D;锁值</span><br><span class="line">续租：curl http:&#x2F;&#x2F;ip:port&#x2F;v2&#x2F;keys&#x2F;锁名?prevValue&#x3D;锁值 -XPUT -d ttl&#x3D;3 -d prevExits&#x3D;true -d refresh&#x3D;true</span><br><span class="line">释放锁：curl http:&#x2F;&#x2F;ip:port&#x2F;v2&#x2F;keys&#x2F;锁名?prevValue&#x3D;锁值 -X DELETE</span><br></pre></td></tr></table></figure>
<p>v3 python 客户端:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">etcd3.client()</span><br><span class="line">etcd_lock &#x3D; etcd_client.lock(&#39;lock&#39;, ttl&#x3D;100) # lock是锁的名字,创建一个存活时间为100s的锁</span><br><span class="line">etcd_lock.acquire(None) # 这里默认是10s, none标识forever</span><br><span class="line"># do something ....</span><br><span class="line">etcd_lock.refresh()</span><br><span class="line">etcd_lock.release()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">etcd &#x3D; etcd3.client()</span><br><span class="line"># create a lock that expires after 20 seconds</span><br><span class="line">with etcd.lock(&#39;toot&#39;, ttl&#x3D;20) as lock:</span><br><span class="line"># do something that requires the lock</span><br><span class="line">print(lock.is_acquired())</span><br><span class="line"># refresh the timeout on the lease</span><br><span class="line">lock.refresh()</span><br></pre></td></tr></table></figure>

<h1 id="汇总"><a href="#汇总" class="headerlink" title="汇总"></a>汇总</h1><p>经过以上分析，可以知道，如果需要在并发中控制共享资源的申请，必须把并发变成串行化操作，锁是一个必然的选择。怎么选择需要进行一个衡量，以下是各方面的对比：</p>
<table>
<thead>
<tr>
<th>锁的实现</th>
<th>使用难度</th>
<th>能够解决的问题</th>
<th>可重入</th>
<th>超时</th>
<th>阻塞</th>
<th>具体应用</th>
</tr>
</thead>
<tbody><tr>
<td>线程锁</td>
<td>低</td>
<td>单进程多线程</td>
<td>默认不支持</td>
<td>默认不支持</td>
<td>不支持</td>
<td>threading.lock()</td>
</tr>
<tr>
<td>进程锁</td>
<td>低</td>
<td>单进程多线程，多进程</td>
<td>默认不支持</td>
<td>默认不支持</td>
<td>支持</td>
<td>fcntl.lockf()</td>
</tr>
<tr>
<td>数据库锁</td>
<td>高</td>
<td>单进程多线程，单进程多线程，分布式</td>
<td>默认不支持</td>
<td>不支持</td>
<td>不支持</td>
<td>mysql 悲观锁</td>
</tr>
<tr>
<td>分布式锁</td>
<td>中</td>
<td>单进程多线程，单进程多线程，分布式</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>etcd/redis/zookeeper</td>
</tr>
</tbody></table>
<p>在以上列表中，数据库锁是最不推荐使用的。因为数据库锁会降低吞吐量以及死锁可能带来的问题。</p>
]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>锁</tag>
        <tag>并发</tag>
        <tag>mysql 悲观锁</tag>
        <tag>mysql 乐观锁</tag>
        <tag>oslo.concurrency</tag>
        <tag>文件锁</tag>
        <tag>fcntl</tag>
        <tag>分布式锁</tag>
        <tag>cap</tag>
        <tag>redis lock</tag>
        <tag>etcd lock</tag>
      </tags>
  </entry>
  <entry>
    <title>python异步编程</title>
    <url>/2020/10/20/python%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="什么是异步编程"><a href="#什么是异步编程" class="headerlink" title="什么是异步编程"></a>什么是异步编程</h1><p>提到异步，那么就有同步。需要了解一下几个名词：同步/异步、阻塞/非阻塞。</p>
<a id="more"></a>

<p>具体解释参看 io模型与阻塞相关章节。</p>
<h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><ul>
<li>并发描述的是程序的组织结构。指程序要被设计成多个可独立执行的子任务。</li>
<li>以利用有限的计算机资源使多个任务可以被实时或近实时执行为目的。</li>
</ul>
<h2 id="并行"><a href="#并行" class="headerlink" title="并行"></a>并行</h2><ul>
<li>并行描述的是程序的执行状态。指多个任务同时被执行。</li>
<li>以利用富余计算资源（多核CPU）加速完成多个任务为目的。</li>
<li>并发提供了一种程序组织结构方式，让问题的解决方案可以并行执行，但并行执行不是必须的。</li>
</ul>
<h2 id="概念总结"><a href="#概念总结" class="headerlink" title="概念总结"></a>概念总结</h2><ul>
<li>并行是为了利用多核加速多任务完成的进度</li>
<li>并发是为了让独立的子任务都有机会被尽快执行，但不一定能加速整体进度</li>
<li>非阻塞是为了提高程序整体执行效率</li>
<li>异步是高效地组织非阻塞任务的方式</li>
</ul>
<p>要支持并发，必须拆分为多任务，不同任务相对而言才有阻塞/非阻塞、同步/异步。所以，并发、异步、非阻塞三个词总是如影随形。</p>
<h2 id="异步编程"><a href="#异步编程" class="headerlink" title="异步编程"></a>异步编程</h2><p>以进程、线程、协程、函数/方法作为执行任务程序的基本单位，结合回调、事件循环、信号量等机制，以提高程序整体执行效率和并发能力的编程方式。</p>
<p>如果在某程序的运行时，能根据已经执行的指令准确判断它接下来要进行哪个具体操作，那它是同步程序，反之则为异步程序。（无序与有序的区别）</p>
<p>同步/异步、阻塞/非阻塞并非水火不容，要看讨论的程序所处的封装级别。例如购物程序在处理多个用户的浏览请求可以是异步的，而更新库存时必须是同步的。</p>
<h2 id="异步之难-nan"><a href="#异步之难-nan" class="headerlink" title="异步之难(nán)"></a>异步之难(nán)</h2><p>控制不住“计几”写的程序，因为其执行顺序不可预料，当下正要发生什么事件不可预料。在并行情况下更为复杂和艰难。</p>
<p>所以，几乎所有的异步框架都将异步编程模型简化：一次只允许处理一个事件。故而有关异步的讨论几乎都集中在了单线程内。</p>
<p>如果某事件处理程序需要长时间执行，所有其他部分都会被阻塞。</p>
<p>所以，一旦采取异步编程，每个异步调用必须“足够小”，不能耗时太久。如何拆分异步任务成了难题。</p>
<p>程序下一步行为往往依赖上一步执行结果，如何知晓上次异步调用已完成并获取结果？</p>
<p><strong>回调（Callback）成了必然选择</strong>。那又需要面临“回调地狱”的折磨。</p>
<p>同步代码改为异步代码，必然破坏代码结构。</p>
<p>解决问题的逻辑也要转变，不再是一条路走到黑，需要精心安排异步任务。</p>
<h1 id="为什么要异步编程"><a href="#为什么要异步编程" class="headerlink" title="为什么要异步编程"></a>为什么要异步编程</h1><p>如上文所述，异步编程面临诸多难点，Python 之父亲自上阵打磨4年才使 asyncio 模块在Python 3.6中“转正”，如此苦心为什么？答案只有一个：它值得！下面我们看看为何而值得。</p>
<h2 id="CPU的时间观"><a href="#CPU的时间观" class="headerlink" title="CPU的时间观"></a>CPU的时间观</h2><p><img src="/images/cpu%E6%97%B6%E9%97%B4%E8%A7%82.png" alt="cpu时间观"></p>
<p>我们将一个 2.6GHz 的 CPU 拟人化，假设它执行一条命令的时间，他它感觉上过了一秒钟。CPU是计算机的处理核心，也是最宝贵的资源，如果有浪费CPU的运行时间，导致其利用率不足，那程序效率必然低下（因为实际上有资源可以使效率更高）。</p>
<p>如上图所示，在千兆网上传输2KB数据，CPU感觉过了14个小时，如果是在10M的公网上呢？那效率会低百倍！如果在这么长的一段时间内，CPU只是傻等结果而不能去干其他事情，是不是在浪费CPU的青春？</p>
<p>鲁迅说，浪费“CPU”的时间等于谋财害命。而凶手就是程序猿。</p>
<h2 id="面临的问题"><a href="#面临的问题" class="headerlink" title="面临的问题"></a>面临的问题</h2><ul>
<li>成本问题</li>
</ul>
<blockquote>
<p>如果一个程序不能有效利用一台计算机资源，那必然需要更多的计算机通过运行更多的程序实例来弥补需求缺口。例如我前不久主导重写的项目，使用Python异步编程，改版后由原来的7台服务器削减至3台，成本骤降57%。一台AWS m4.xlarge 型通用服务器按需付费实例一年价格约 1.2 万人民币。</p>
</blockquote>
<ul>
<li><p>效率问题</p>
<blockquote>
<p>如果不在乎钱的消耗，那也会在意效率问题。当服务器数量堆叠到一定规模后，如果不改进软件架构和实现，加机器是徒劳，而且运维成本会骤然增加。比如别人家的电商平台支持6000单/秒支付，而自家在下单量才支撑2000单/秒，在双十一这种活动的时候，钱送上门也赚不到。</p>
</blockquote>
</li>
<li><p>C10k/C10M挑战</p>
<blockquote>
<p>C10k（concurrently handling 10k connections）是一个在1999年被提出来的技术挑战，如何在一颗1GHz CPU，2G内存，1gbps网络环境下，让单台服务器同时为1万个客户端提供FTP服务。而到了2010年后，随着硬件技术的发展，这个问题被延伸为C10M，即如何利用8核心CPU，64G内存，在10gbps的网络上保持1000万并发连接，或是每秒钟处理100万的连接。（两种类型的计算机资源在各自的时代都约为1200美元）</p>
</blockquote>
</li>
</ul>
<p>成本和效率问题是从企业经营角度讲，C10k/C10M问题则是从技术角度出发挑战软硬件极限。C10k/C10M 问题得解，成本问题和效率问题迎刃而解。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>《约束理论与企业优化》中指出：“除了瓶颈之外，任何改进都是幻觉。”</p>
<p>CPU告诉我们，它自己很快，而上下文切换慢、内存读数据慢、磁盘寻址与取数据慢、网络传输慢……总之，离开CPU 后的一切，除了一级高速缓存，都很慢。我们观察计算机的组成可以知道，主要由运算器、控制器、存储器、输入设备、输出设备五部分组成。运算器和控制器主要集成在CPU中，除此之外全是I/O，包括读写内存、读写磁盘、读写网卡全都是I/O。<strong>I/O成了最大的瓶颈</strong>。</p>
<p>异步程序可以提高效率，而最大的瓶颈在I/O，业界诞生的解决方案没出意料：<strong>异步I/O吧，异步I/O吧，异步I/O吧吧！</strong></p>
<h1 id="python怎么做异步编程"><a href="#python怎么做异步编程" class="headerlink" title="python怎么做异步编程"></a>python怎么做异步编程</h1><p>如今，地球上最发达、规模最庞大的计算机程序，莫过于因特网。而从CPU的时间观中可知，网络I/O是最大的I/O瓶颈，除了宕机没有比它更慢的。所以，诸多异步框架都对准的是<strong>网络I/O</strong>。</p>
<h2 id="异步进化之路"><a href="#异步进化之路" class="headerlink" title="异步进化之路"></a>异步进化之路</h2><p>那么异步只是怎么逐步由同步进化而来呢？我们从一个爬虫例子说起，从因特网上下载10篇网页。</p>
<h3 id="同步阻塞方式"><a href="#同步阻塞方式" class="headerlink" title="同步阻塞方式"></a>同步阻塞方式</h3><p>最容易想到的解决方案就是依次下载，从建立socket连接到发送网络请求再到读取响应数据，顺序进行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">blocking_way</span>():</span></span><br><span class="line">    sock = socket.socket()</span><br><span class="line">    <span class="comment"># blocking</span></span><br><span class="line">    sock.connect((<span class="string">&#x27;example.com&#x27;</span>, <span class="number">80</span>))</span><br><span class="line">    request = <span class="string">&#x27;GET / HTTP/1.0\r\nHost: example.com\r\n\r\n&#x27;</span></span><br><span class="line">    sock.send(request.encode(<span class="string">&#x27;ascii&#x27;</span>))</span><br><span class="line">    response = <span class="string">b&#x27;&#x27;</span></span><br><span class="line">    chunk = sock.recv(<span class="number">4096</span>)</span><br><span class="line">    <span class="keyword">while</span> chunk:</span><br><span class="line">        response += chunk</span><br><span class="line">        <span class="comment"># blocking</span></span><br><span class="line">        chunk = sock.recv(<span class="number">4096</span>)</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sync_way</span>():</span></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        res.append(blocking_way())</span><br><span class="line">    <span class="keyword">return</span> len(res)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：总体耗时约为4.5秒。（因网络波动每次测试结果有所变动，本文取多次平均值）</p>
</blockquote>
<p>创建网络连接，多久能创建完成不是客户端决定的，而是由网络状况和服务端处理能力共同决定。服务端什么时候返回了响应数据并被客户端接收到可供程序读取，也是不可预测的。所以sock.connect()和sock.recv()这两个调用在默认情况下是阻塞的。</p>
<blockquote>
<p>注：sock.send()函数并不会阻塞太久，它只负责将请求数据拷贝到TCP/IP协议栈的系统缓冲区中就返回，并不等待服务端返回的应答确认。</p>
</blockquote>
<p>上面说了很多，我们力图说明一件事：<strong>同步阻塞的网络交互方式，效率低十分低下</strong>。特别是在网络交互频繁的程序中。这种方式根本不可能挑战C10K/C10M。</p>
<h3 id="改进方式：多进程"><a href="#改进方式：多进程" class="headerlink" title="改进方式：多进程"></a>改进方式：多进程</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">from</span> concurrent <span class="keyword">import</span> futures</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">blocking_way</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;与同步代码相同，此处省略&#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_way</span>():</span></span><br><span class="line">    workers = <span class="number">10</span></span><br><span class="line">    <span class="keyword">with</span> futures.ProcessPoolExecutor(worksers) <span class="keyword">as</span> executor:</span><br><span class="line">        futs = &#123;executor.submit(blocking_way) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)&#125;</span><br><span class="line">    <span class="keyword">return</span> len([fut.result() <span class="keyword">for</span> fut <span class="keyword">in</span> futs])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：总体耗时约为 0.6 秒</p>
</blockquote>
<p>改善效果立竿见影。但仍然有问题。总体耗时并没有缩减到原来的十分之一，而是九分之一左右，还有一些时间耗到哪里去了？进程切换开销。</p>
<p>进程切换开销不止像“CPU的时间观”所列的“上下文切换”那么低。CPU从一个进程切换到另一个进程，需要把旧进程运行时的寄存器状态、内存状态全部保存好，再将另一个进程之前保存的数据恢复。对CPU来讲，几个小时就干等着。当进程数量大于CPU核心数量时，进程切换是必然需要的。</p>
<p>除了切换开销，多进程还有另外的缺点。一般的服务器在能够稳定运行的前提下，可以同时处理的进程数在数十个到数百个规模。如果进程数量规模更大，系统运行将不稳定，而且可用内存资源往往也会不足。</p>
<p>多进程解决方案在面临每天需要成百上千万次下载任务的爬虫系统，或者需要同时搞定数万并发的电商系统来说，并不适合。</p>
<p>除了切换开销大，以及可支持的任务规模小之外，多进程还有其他缺点，如状态共享等</p>
<h3 id="继续改进：多线程"><a href="#继续改进：多线程" class="headerlink" title="继续改进：多线程"></a>继续改进：多线程</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">from</span> concurrent <span class="keyword">import</span> futures</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">blocking_way</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;与同步代码相同，此处省略&#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">thread_way</span>():</span></span><br><span class="line">    workers = <span class="number">10</span></span><br><span class="line">    <span class="keyword">with</span> futures.ThreadPoolExecutor(workers) <span class="keyword">as</span> executor:</span><br><span class="line">        futs = &#123;executor.submit(blocking_way) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)&#125;</span><br><span class="line">    <span class="keyword">return</span> len([fut.result() <span class="keyword">for</span> fut <span class="keyword">in</span> futs])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：总体运行时间约0.43秒。</p>
</blockquote>
<p>结果符合预期，比多进程耗时要少些。从运行时间上看，多线程似乎已经解决了切换开销大的问题。而且可支持的任务数量规模，也变成了数百个到数千个。</p>
<p>但是，多线程仍有问题，特别是Python里的多线程。首先，Python中的多线程因为GIL的存在，它们并不能利用CPU多核优势，一个Python进程中，只允许有一个线程处于运行状态。那为什么结果还是如预期，耗时缩减到了十分之一？</p>
<p>因为在做阻塞的系统调用时，例如sock.connect(),sock.recv()时，当前线程会释放GIL，让别的线程有执行机会。但是单个线程内，在阻塞调用上还是阻塞的。</p>
<p>除了GIL之外，所有的多线程还有通病。它们是被OS调度，调度策略是抢占式的，以保证同等优先级的线程都有均等的执行机会，那带来的问题是：并不知道下一时刻是哪个线程被运行，也不知道它正要执行的代码是什么。所以就可能存在<strong>竞态条件</strong>。</p>
<p>例如爬虫工作线程从任务队列拿待抓取URL的时候，如果多个爬虫线程同时来取，那这个任务到底该给谁？那就需要用到“锁”或“同步队列”来保证下载任务不会被重复执行。</p>
<p>而且线程支持的多任务规模，在数百到数千的数量规模。在大规模的高频网络交互系统中，仍然有些吃力。当然，多线程最主要的问题还是<strong>竞态条件</strong>。</p>
<h3 id="非阻塞方式"><a href="#非阻塞方式" class="headerlink" title="非阻塞方式"></a>非阻塞方式</h3><p>终于，我们来到了非阻塞解决方案。先来看看最原始的非阻塞如何工作的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import socket</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def nonblocking_way():</span><br><span class="line">    sock &#x3D; socket.socket()</span><br><span class="line">    sock.setblocking(False)</span><br><span class="line">    try:</span><br><span class="line">        sock.connect((&#39;example.com&#39;, 80))</span><br><span class="line">    except BlockingIOError:</span><br><span class="line">        # 非阻塞连接过程中也会抛出异常</span><br><span class="line">        pass</span><br><span class="line">    request &#x3D; &#39;GET &#x2F; HTTP&#x2F;1.0\r\nHost: example.com\r\n\r\n&#39;</span><br><span class="line">    data &#x3D; request.encode(&#39;ascii&#39;)</span><br><span class="line">    # 不知道socket何时就绪，所以不断尝试发送</span><br><span class="line">    while True:</span><br><span class="line">        try:</span><br><span class="line">            sock.send(data)</span><br><span class="line">            # 直到send不抛异常，则发送完成</span><br><span class="line">            break</span><br><span class="line">        except OSError:</span><br><span class="line">            pass</span><br><span class="line"></span><br><span class="line">    response &#x3D; b&#39;&#39;</span><br><span class="line">    while True:</span><br><span class="line">        try:</span><br><span class="line">            chunk &#x3D; sock.recv(4096)</span><br><span class="line">            while chunk:</span><br><span class="line">                response +&#x3D; chunk</span><br><span class="line">                chunk &#x3D; sock.recv(4096)</span><br><span class="line">            break</span><br><span class="line">        except OSError:</span><br><span class="line">            pass</span><br><span class="line"></span><br><span class="line">    return response</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sync_way():</span><br><span class="line">    res &#x3D; []</span><br><span class="line">    for i in range(10):</span><br><span class="line">        res.append(nonblocking_way())</span><br><span class="line">    return len(res)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：总体耗时约4.3秒。</p>
</blockquote>
<p>首先注意到两点，就感觉被骗了。一是耗时与同步阻塞相当，二是代码更复杂。要非阻塞何用？且慢。</p>
<p>上图代码<code>sock.setblocking(False)</code>告诉OS，让socket上阻塞调用都改为非阻塞的方式。之前我们说到，非阻塞就是在做一件事的时候，不阻碍调用它的程序做别的事情。上述代码在执行完 sock.connect() 和 sock.recv()后的确不再阻塞，可以继续往下执行请求准备的代码或者是执行下一次读取。</p>
<p>代码变得更复杂也是上述原因所致。第11行要放在try语句内，是因为socket在发送非阻塞连接请求过程中，系统底层也会抛出异常。connect()被调用之后，立即可以往下执行第15和16行的代码。</p>
<p>需要while循环不断尝试send()，是因为connect()已经非阻塞，在send()之时并不知道 socket 的连接是否就绪，只有不断尝试，尝试成功为止，即发送数据成功了。recv()调用也是同理。</p>
<p>虽然 connect() 和 recv()不再阻塞主程序，空出来的时间段CPU没有空闲着，但并没有利用好这空闲去做其他有意义的事情，而是在循环尝试读写 socket（不停判断非阻塞调用的状态是否就绪）。还得处理来自底层的可忽略的异常。也不能同时处理多个 socket 。</p>
<p>然后10次下载任务仍然按序进行。所以总体执行时间和同步阻塞相当。如果非得这样子，那还不如同步阻塞算了。</p>
<h3 id="非阻塞改进"><a href="#非阻塞改进" class="headerlink" title="非阻塞改进"></a>非阻塞改进</h3><h4 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h4><p><strong>判断非阻塞调用是否就绪如果 OS能做</strong>，是不是应用程序就可以不用自己去等待和判断了，就可以利用这个空闲去做其他事情以提高效率。</p>
<p>所以OS将I/O状态的变化都封装成了事件，如可读事件、可写事件。并且提供了专门的系统模块让应用程序可以接收事件通知。这个模块就是select。让应用程序可以通过select注册文件描述符和回调函数。当文件描述符的状态发生变化时，select就调用事先注册的回调函数。</p>
<p>select因其算法效率比较低，后来改进成了poll，再后来又有进一步改进，BSD内核改进成了kqueue模块，而Linux内核改进成了epoll模块。这四个模块的作用都相同，暴露给程序员使用的API也几乎一致，区别在于kqueue 和 epoll在处理大量文件描述符时效率更高。</p>
<p>鉴于 Linux 服务器的普遍性，以及为了追求更高效率，所以我们常常听闻被探讨的模块都是 epoll 。</p>
<p>关于io多路复用（select/poll/epoll）请参看 io 模型章节。</p>
<h4 id="回调-Callback"><a href="#回调-Callback" class="headerlink" title="回调(Callback)"></a>回调(Callback)</h4><p>把I/O事件的等待和监听任务交给了 OS，那 OS在知道I/O状态发生改变后（例如socket连接已建立成功可发送数据），它又怎么知道接下来该干嘛呢？只能回调。</p>
<p>需要我们将发送数据与读取数据封装成独立的函数，让epoll代替应用程序监听socket状态时，得告诉epoll：“如果socket状态变为可以往里写数据（连接建立成功了），请调用HTTP请求发送函数。如果socket变为可以读数据了（客户端已收到响应），请调用响应处理函数。”</p>
<p>于是我们利用epoll结合回调机制重构爬虫代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import socket</span><br><span class="line">from selectors import DefaultSelector, EVENT_WRITE, EVENT_READ</span><br><span class="line"></span><br><span class="line">selector &#x3D; DefaultSelector()</span><br><span class="line">stopped &#x3D; False</span><br><span class="line">urls_todo &#x3D; &#123;&#39;&#x2F;&#39;, &#39;&#x2F;1&#39;, &#39;&#x2F;2&#39;, &#39;&#x2F;3&#39;, &#39;&#x2F;4&#39;, &#39;&#x2F;5&#39;, &#39;&#x2F;6&#39;, &#39;&#x2F;7&#39;, &#39;&#x2F;8&#39;, &#39;&#x2F;9&#39;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Crawler:</span><br><span class="line">    def __init__(self, url):</span><br><span class="line">        self.url &#x3D; url</span><br><span class="line">        self.sock &#x3D; None</span><br><span class="line">        self.response &#x3D; b&#39;&#39;</span><br><span class="line"></span><br><span class="line">    def fetch(self):</span><br><span class="line">        self.sock &#x3D; socket.socket()</span><br><span class="line">        self.sock.setblocking(False)</span><br><span class="line">        try:</span><br><span class="line">            self.sock.connect((&#39;example.com&#39;, 80))</span><br><span class="line">        except BlockingIOError:</span><br><span class="line">            pass</span><br><span class="line">        selector.register(self.sock.fileno(), EVENT_WRITE, self.connected)</span><br><span class="line"></span><br><span class="line">    def connected(self, key, mask):</span><br><span class="line">        selector.unregister(key.fd)</span><br><span class="line">        get &#x3D; &#39;GET &#123;0&#125; HTTP&#x2F;1.0\r\nHost: example.com\r\n\r\n&#39;.format(self.url)</span><br><span class="line">        self.sock.send(get.encode(&#39;ascii&#39;))</span><br><span class="line">        selector.register(key.fd, EVENT_READ, self.read_response)</span><br><span class="line"></span><br><span class="line">    def read_response(self, key, mask):</span><br><span class="line">        global stopped</span><br><span class="line">        # 如果响应大于4KB，下一次循环会继续读</span><br><span class="line">        chunk &#x3D; self.sock.recv(4096)</span><br><span class="line">        if chunk:</span><br><span class="line">            self.response +&#x3D; chunk</span><br><span class="line">        else:</span><br><span class="line">            selector.unregister(key.fd)</span><br><span class="line">            urls_todo.remove(self.url)</span><br><span class="line">            if not urls_todo:</span><br><span class="line">                stopped &#x3D; True</span><br><span class="line">def loop():</span><br><span class="line">    while not stopped:</span><br><span class="line">        # 阻塞, 直到一个事件发生</span><br><span class="line">        events &#x3D; selector.select()</span><br><span class="line">        for event_key, event_mask in events:</span><br><span class="line">            callback &#x3D; event_key.data</span><br><span class="line">            callback(event_key, event_mask)</span><br></pre></td></tr></table></figure>
<p>此处和前面稍有不同的是，我们将下载不同的10个页面，相对URL路径存放于urls_todo集合中。现在看看改进在哪。</p>
<p>首先，不断尝试send() 和 recv() 的两个循环被消灭掉了。</p>
<p>其次，导入了selectors模块，并创建了一个DefaultSelector实例。Python标准库提供的selectors模块是对底层select/poll/epoll/kqueue的封装。DefaultSelector类会根据 OS 环境自动选择最佳的模块，那在 Linux 2.5.44 及更新的版本上都是epoll了。</p>
<p>然后，在第25行和第31行分别注册了socket可写事件(EVENT_WRITE)和可读事件(EVENT_READ)发生后应该采取的回调函数。</p>
<p>虽然代码结构清晰了，阻塞操作也交给OS去等待和通知了，但是，我们要抓取10个不同页面，就得创建10个Crawler实例，就有20个事件将要发生，那如何从selector里获取当前正发生的事件，并且得到对应的回调函数去执行呢？</p>
<h4 id="事件循环（Event-Loop）"><a href="#事件循环（Event-Loop）" class="headerlink" title="事件循环（Event Loop）"></a>事件循环（Event Loop）</h4><p>为了解决上述问题，那我们只得采用老办法，写一个循环，去访问selector模块，等待它告诉我们当前是哪个事件发生了，应该对应哪个回调。这个等待事件通知的循环，称之为事件循环。</p>
<p>上述代码中，我们用stopped全局变量控制事件循环何时停止。当urls_todo消耗完毕后，会标记stopped为True。</p>
<p>重要的是第44行代码，selector.select() 是一个阻塞调用，因为如果事件不发生，那应用程序就没事件可处理，所以就干脆阻塞在这里等待事件发生。那可以推断，如果只下载一篇网页，一定要connect()之后才能send()继而recv()，那它的效率和阻塞的方式是一样的。因为不在connect()/recv()上阻塞，也得在select()上阻塞。</p>
<p>所以，selector机制(后文以此称呼代指epoll/kqueue)是设计用来解决大量并发连接的。当系统中有大量非阻塞调用，能随时产生事件的时候，selector机制才能发挥最大的威力。</p>
<p>下面是如何启创建10个下载任务和启动事件循环的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    import time</span><br><span class="line">    start &#x3D; time.time()</span><br><span class="line">    for url in urls_todo:</span><br><span class="line">        crawler &#x3D; Crawler(url)</span><br><span class="line">        crawler.fetch()</span><br><span class="line">    loop()</span><br><span class="line">    print(time.time() - start)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：总体耗时约0.45秒。</p>
</blockquote>
<p>上述执行结果令人振奋。在单线程内用 事件循环+回调搞定了10篇网页同时下载的问题。这，已经是异步编程了。虽然有一个for 循环顺序地创建Crawler 实例并调用 fetch 方法，但是fetch内仅有connect()和注册可写事件，而且从执行时间明显可以推断，多个下载任务确实在同时进行！</p>
<p>上述代码异步执行的过程：</p>
<ol>
<li>创建Crawler 实例；</li>
<li>调用fetch方法，会创建socket连接和在selector上注册可写事件；</li>
<li>fetch内并无阻塞操作，该方法立即返回；</li>
<li>重复上述3个步骤，将10个不同的下载任务都加入事件循环；</li>
<li>启动事件循环，进入第1轮循环，阻塞在事件监听上；</li>
<li>当某个下载任务EVENT_WRITE被触发，回调其connected方法，第一轮事件循环结束；</li>
<li>进入第2轮事件循环，当某个下载任务有事件触发，执行其回调函数；此时已经不能推测是哪个事件发生，因为有可能是上次connected里的EVENT_READ先被触发，也可能是其他某个任务的EVENT_WRITE被触发；（此时，原来在一个下载任务上会阻塞的那段时间被利用起来执行另一个下载任务了）</li>
<li>循环往复，直至所有下载任务被处理完成</li>
<li>退出事件循环，结束整个下载程序</li>
</ol>
<h4 id="非阻塞总结"><a href="#非阻塞总结" class="headerlink" title="非阻塞总结"></a>非阻塞总结</h4><p>目前为止，我们已经从同步阻塞学习到了异步非阻塞。掌握了在单线程内同时并发执行多个网络I/O阻塞型任务的黑魔法。而且与多线程相比，连线程切换都没有了，执行回调函数是函数调用开销，在线程的栈内完成，因此性能也更好，单机支持的任务规模也变成了数万到数十万个。（不过我们知道：没有免费午餐，也没有银弹。）</p>
<p>部分编程语言中，对异步编程的支持就止步于此（不含语言官方之外的扩展）。需要程序猿直接使用epoll去注册事件和回调、维护一个事件循环，然后大多数时间都花在设计回调函数上。</p>
<p>通过本节的学习，我们应该认识到，不论什么编程语言，但凡要做异步编程，上述的“<strong>事件循环+回调</strong>”这种模式是逃不掉的，尽管它可能用的不是epoll，也可能不是while循环。如果你找到了一种不属于 “等会儿告诉你”模型的异步方式，请立即给我打电话（注意，打电话是Call）。</p>
<p>为什么我们在某些异步编程中并没有看到 CallBack 模式呢？这就是我们接下来要探讨的问题。本节是学习异步编程的一个终点，也是另一个起点。毕竟咱们讲 Python 异步编程，还没提到其主角协程的用武之地。</p>
<h2 id="python的异步实现"><a href="#python的异步实现" class="headerlink" title="python的异步实现"></a>python的异步实现</h2><p>我们将在本节学习到 Python生态对异步编程的支持是如何继承前文所述的“事件循环+回调”模式演变到asyncio的原生协程模式。</p>
<h3 id="回调之痛，以终为始"><a href="#回调之痛，以终为始" class="headerlink" title="回调之痛，以终为始"></a>回调之痛，以终为始</h3><p>在上节中，我们已经学会了“事件循环+回调”的基本运行原理，可以基于这种方式在单线程内实现异步编程。也确实能够大大提高程序运行效率。但是，刚才所学的只是最基本的，然而在生产项目中，要应对的复杂度会大大增加。考虑如下问题：</p>
<ol>
<li>如果回调函数执行不正常该如何？</li>
<li>如果回调里面还要嵌套回调怎么办？要嵌套很多层怎么办？</li>
<li>如果嵌套了多层，其中某个环节出错了会造成什么后果？</li>
<li>如果有个数据需要被每个回调都处理怎么办？</li>
<li>……</li>
</ol>
<p>在实际编程中，上述系列问题不可避免。在这些问题的背后隐藏着回调编程模式的一些</p>
<p>缺点：</p>
<ul>
<li>回调地狱</li>
<li>破坏代码结构<br>写同步代码时，关联的操作时自上而下运行：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">do_a()</span><br><span class="line">do_b()</span><br></pre></td></tr></table></figure>
如果 b 处理依赖于 a 处理的结果，而 a 过程是异步调用，就不知 a何时能返回值，需要将后续的处理过程以callback的方式传递给 a ，让 a执行完以后可以执行 b。代码变化为：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">do_a(do_b())</span><br></pre></td></tr></table></figure>
如果整个流程中全部改为异步处理，而流程比较长的话，代码逻辑就会成为这样：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">do_a(do_b(do_c(do_d(do_e(do_f(......))))))</span><br></pre></td></tr></table></figure>
上面实际也是回调地狱式的风格，但这不是主要矛盾。主要在于，原本从上而下的代码结构，要改成从内到外的。先f，再e，再d，…，直到最外层 a 执行完成。在同步版本中，执行完a后执行b，这是线程的指令指针控制着的流程，而在回调版本中，流程就是程序猿需要注意和安排的。</li>
<li>共享状态管理困难<br>回顾同步阻塞版的爬虫代码，sock对象从头使用到尾，而在回调的版本中，我们必须在Crawler实例化后的对象self里保存它自己的sock对象。如果不是采用OOP的编程风格，那需要把要共享的状态接力似的传递给每一个回调。多个异步调用之间，到底要共享哪些状态，事先就得考虑清楚，精心设计。</li>
<li>错误处理困难<br>一连串的回调构成一个完整的调用链。例如上述的 a 到 f。假如 d抛了异常怎么办？整个调用链断掉，接力传递的状态也会丢失，这种现象称为调用栈撕裂。 c 不知道该干嘛，继续异常，然后是 b 异常，接着 a异常。好嘛，报错日志就告诉你，a 调用出错了，但实际是 d出错。所以，为了防止栈撕裂，异常必须以数据的形式返回，而不是直接抛出异常，然后每个回调中需要检查上次调用的返回值，以防错误吞没。</li>
</ul>
<p>如果说代码风格难看是小事，但栈撕裂和状态管理困难这两个缺点会让基于回调的异步编程很艰难。所以不同编程语言的生态都在致力于解决这个问题。才诞生了后来的Promise、Co-routine等解决方案。</p>
<p>Python 生态也以终为始，秉承着“程序猿不必难程序猿”的原则，让语言和框架开发者苦逼一点，也要让应用开发者舒坦。在事件循环+回调的基础上衍生出了基于协程的解决方案，代表作有 Tornado、Twisted、asyncio 等。接下来我们随着 Python 生态异步编程的发展过程，深入理解Python异步编程。</p>
<h1 id="核心问题"><a href="#核心问题" class="headerlink" title="核心问题"></a>核心问题</h1><p>通过前面的学习，我们清楚地认识到异步编程最大的困难：异步任务何时执行完毕？接下来要对异步调用的返回结果做什么操作？</p>
<p>上述问题我们已经通过事件循环和回调解决了。但是回调会让程序变得复杂。要异步，必回调，又是否有办法规避其缺点呢？那需要弄清楚其本质，为什么回调是必须的？还有使用回调时克服的那些缺点又是为了什么？</p>
<p>答案是程序为了知道自己已经干了什么？正在干什么？将来要干什么？换言之，程序得知道当前所处的状态，而且要将这个状态在不同的回调之间延续下去。</p>
<p>多个回调之间的状态管理困难，那让每个回调都能管理自己的状态怎么样？链式调用会有栈撕裂的困难，让回调之间不再链式调用怎样？不链式调用的话，那又如何让被调用者知道已经完成了？那就让这个回调通知那个回调如何？而且一个回调，不就是一个待处理任务吗？</p>
<p>任务之间得相互通知，每个任务得有自己的状态。那不就是很古老的编程技法：协作式多任务？然而要在单线程内做调度，啊哈，协程！每个协程具有自己的栈帧，当然能知道自己处于什么状态，协程之间可以协作那自然可以通知别的协程。</p>
<h1 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h1><p>协程(Co-routine)，即是协作式的例程。</p>
<p>它是非抢占式的多任务子例程的概括，可以允许有多个入口点在例程中确定的位置来控制程序的暂停与恢复执行。</p>
<p>例程是什么？编程语言定义的可被调用的代码段，为了完成某个特定功能而封装在一起的一系列指令。一般的编程语言都用称为函数或方法的代码结构来体现。</p>
<h2 id="基于生成器的协程（yield）"><a href="#基于生成器的协程（yield）" class="headerlink" title="基于生成器的协程（yield）"></a>基于生成器的协程（yield）</h2><p>早期的 Pythoner 发现Python中有种特殊的对象——生成器（Generator），它的特点和协程很像。每一次迭代之间，会暂停执行，继续下一次迭代的时候还不会丢失先前的状态。</p>
<p>为了支持用生成器做简单的协程，Python2.5对生成器进行了增强(PEP342)，该增强提案的标题是 “Coroutines via EnhancedGenerators”。有了PEP342的加持，生成器可以通过yield暂停执行和向外返回数据，也可以通过send()向生成器内发送数据，还可以通过throw()向生成器内抛出异常以便随时终止生成器的运行。</p>
<p>yiled 具体解释参看 yield章节。</p>
<h2 id="yield-from"><a href="#yield-from" class="headerlink" title="yield from"></a>yield from</h2><p>yield from 是Python 3.3新引入的语法（PEP380）。它主要解决的就是在生成器里玩生成器不方便的问题。它有两大主要功能。</p>
<p>第一个功能是：让嵌套生成器不必通过循环迭代yield，而是直接yield  from。以下两种在生成器里玩子生成器的方式是等价的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def gen_one():</span><br><span class="line">    subgen &#x3D; range(10)    </span><br><span class="line">    yield from subgen</span><br><span class="line"></span><br><span class="line">def gen_two():</span><br><span class="line">    subgen &#x3D; range(10)    </span><br><span class="line">    for item in subgen:        </span><br><span class="line">        yield item</span><br></pre></td></tr></table></figure>
<p>第二个功能就是在子生成器和原生成器的调用者之间打开双向通道，两者可以直接通信。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def gen():</span><br><span class="line">    yield from subgen()</span><br><span class="line"></span><br><span class="line">def subgen():</span><br><span class="line">    while True:</span><br><span class="line">        x &#x3D; yield</span><br><span class="line">        yield x+1</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    g &#x3D; gen()</span><br><span class="line">    next(g)                # 驱动生成器g开始执行到第一个 yield</span><br><span class="line">    retval &#x3D; g.send(1)     # 看似向生成器 gen() 发送数据</span><br><span class="line">    print(retval)          # 返回2</span><br><span class="line">    g.throw(StopIteration) # 看似向gen()抛入异常</span><br></pre></td></tr></table></figure>
<p>通过上述代码清晰地理解了yield from的双向通道功能。关键字yield from在gen()内部为subgen()和main()开辟了通信通道。main()里可以直接将数据1发送给subgen(),subgen()也可以将计算后的数据2返回到main()里，main()里也可以直接向subgen()抛入异常以终止subgen()。</p>
<blockquote>
<p>顺带一提，yield from 除了可以 <code>yield from &lt;generator&gt;</code> 还可以<code> yield from &lt;iterable&gt;</code>。</p>
</blockquote>
<p>用yield from改进基于生成器的协程，代码抽象程度更高。使业务逻辑相关的代码更精简。由于其双向通道功能可以让协程之间随心所欲传递数据，使Python异步编程的协程解决方案大大向前迈进了一步。</p>
<p>于是Python语言开发者们充分利用yield from，使 Guido 主导的Python异步编程框架Tulip迅速脱胎换骨，并迫不及待得让它在 Python 3.4 中换了个名字asyncio以“实习生”角色出现在标准库中。</p>
<p>可以参看 <a href="https://segmentfault.com/a/1190000009781688">yield from 详细解释</a></p>
<h2 id="asyncio"><a href="#asyncio" class="headerlink" title="asyncio"></a>asyncio</h2><p>asyncio是Python 3.4 试验性引入的异步I/O框架（PEP 3156），提供了基于协程做异步I/O编写单线程并发代码的基础设施。其核心组件有事件循环（Event Loop）、协程(Coroutine）、任务(Task)、未来对象(Future)以及其他一些扩充和辅助性质的模块。</p>
<p>在引入asyncio的时候，还提供了一个装饰器@asyncio.coroutine用于装饰使用了yield from的函数，以标记其为协程。但并不强制使用这个装饰器。</p>
<p>虽然发展到 Python 3.4 时有了yield from的加持让协程更容易了，但是由于协程在Python中发展的历史包袱所致，很多人仍然弄不明白生成器和协程的联系与区别，也弄不明白yield 和 yield from 的区别。这种混乱的状态也违背Python之禅的一些准则。</p>
<p>于是Python设计者们又快马加鞭地在 3.5 中新增了async/await语法（PEP 492），对协程有了明确而显式的支持，称之为原生协程。async/await 和 yield from这两种风格的协程底层复用共同的实现，而且相互兼容。</p>
<p>在Python 3.6 中asyncio库“转正”，不再是实验性质的，成为标准库的正式一员。</p>
<p>行至此处，我们已经掌握了asyncio的核心原理，学习了它的原型，也学习了异步I/O在 CPython 官方支持的生态下是如何一步步发展至今的。</p>
<p>实际上，真正的asyncio比我们前几节中学到的要复杂得多，它还实现了零拷贝、公平调度、异常处理、任务状态管理等等使 Python 异步编程更完善的内容。理解原理和原型对我们后续学习有莫大的帮助。</p>
<h2 id="await-async"><a href="#await-async" class="headerlink" title="await/async"></a>await/async</h2><p>本节中，我们将初步体验asyncio库和新增语法async/await给我们带来的便利。由于Python2-3的过度期间，Python3.0-3.4的使用者并不是太多，也为了不让更多的人困惑，也因为aysncio在3.6才转正，所以更深入学习asyncio库的时候我们将使用async/await定义的原生协程风格，yield from风格的协程不再阐述（实际上它们可用很小的代价相互代替）。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import aiohttp</span><br><span class="line"></span><br><span class="line">host &#x3D; &#39;http:&#x2F;&#x2F;example.com&#39;</span><br><span class="line">urls_todo &#x3D; &#123;&#39;&#x2F;&#39;, &#39;&#x2F;1&#39;, &#39;&#x2F;2&#39;, &#39;&#x2F;3&#39;, &#39;&#x2F;4&#39;, &#39;&#x2F;5&#39;, &#39;&#x2F;6&#39;, &#39;&#x2F;7&#39;, &#39;&#x2F;8&#39;, &#39;&#x2F;9&#39;&#125;</span><br><span class="line"></span><br><span class="line">loop &#x3D; asyncio.get_event_loop()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">async def fetch(url):</span><br><span class="line">    async with aiohttp.ClientSession(loop&#x3D;loop) as session:</span><br><span class="line">        async with session.get(url) as response:</span><br><span class="line">            response &#x3D; await response.read()</span><br><span class="line">            return response</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    import time</span><br><span class="line">    start &#x3D; time.time()</span><br><span class="line">    tasks &#x3D; [fetch(host + url) for url in urls_todo]</span><br><span class="line">    loop.run_until_complete(asyncio.gather(*tasks))</span><br><span class="line">    print(time.time() - start)</span><br></pre></td></tr></table></figure>
<p>对比生成器版的协程，使用asyncio库后变化很大：</p>
<ul>
<li>没有了yield 或 yield from，而是async/await</li>
<li>没有了自造的loop()，取而代之的是asyncio.get_event_loop()</li>
<li>无需自己在socket上做异步操作，不用显式地注册和注销事件，aiohttp库已经代劳</li>
<li>没有了显式的 Future 和 Task，asyncio已封装</li>
<li>更少量的代码，更优雅的设计</li>
</ul>
<blockquote>
<p>说明：我们这里发送和接收HTTP请求不再自己操作socket的原因是，在实际做业务项目的过程中，要处理妥善地HTTP协议会很复杂，我们需要的是功能完善的异步HTTP客户端，业界已经有了成熟的解决方案，DRY不是吗？</p>
</blockquote>
<p>和同步阻塞版的代码对比：</p>
<ul>
<li>异步化</li>
<li>代码量相当（引入aiohttp框架后更少）</li>
<li>代码逻辑同样简单，跟同步代码一样的结构、一样的逻辑</li>
<li>接近10倍的性能提升</li>
</ul>
<p>生成器与asyncio提供的新版语法的区别请参看： <a href="https://www.jianshu.com/p/032ad0848f6b">async/await详解</a></p>
<p>到此为止，我们已经深入地学习了异步编程是什么、为什么、在Python里是怎么样发展的。我们找到了一种让代码看起来跟同步代码一样简单，而效率却提升N倍（具体提升情况取决于项目规模、网络环境、实现细节）的异步编程方法。它也没有回调的那些缺点。</p>
<h1 id="WSGI-ASGI"><a href="#WSGI-ASGI" class="headerlink" title="WSGI/ASGI"></a>WSGI/ASGI</h1><p>经过以上对异步编程的学习，接下来我们要把这些异步运用到python web中。</p>
<p>在python web编程中，有很多流行的框架，大体分为2类：wsgi、asgi.</p>
<p>这里需要特别解释一下几个名词：<br>wsgi server (比如uWSGI/gunicorn） 要和 wsgi   application（比如django/flask）交互，uwsgi需要将过来的请求转给django 处理，那么uWSGI 和 django的交互和调用就需要一个统一的规范，这个规范就是WSGI（Web Server Gateway Interface）</p>
<p>asgi与wsgi的区别之处就在于，asgi扩展了wsgi,可以支持WebSocket，具有异步功能。</p>
<ul>
<li><p>wsgi application有以下代表：</p>
<ol>
<li>Django</li>
<li>flask</li>
<li>bottle</li>
<li>webpy</li>
<li>CherryPy</li>
<li>web2py</li>
</ol>
</li>
<li><p>wsgi server有以下代表：</p>
<ol>
<li>uWSGI</li>
<li>gunicorn</li>
</ol>
</li>
<li><p>asgi application有以下代表</p>
<ol>
<li>Starlette（需要使用ASGI服务作为容器，比如Uvicorn）</li>
<li>Django Channels</li>
<li>FastAPI(集成Starlette)</li>
<li>tornado</li>
<li>Snaic</li>
<li>Quart</li>
<li>twisted</li>
<li>APIStar</li>
</ol>
</li>
<li><p>asgi server有以下代表</p>
<ol>
<li>uvicorn </li>
</ol>
</li>
</ul>
<p>那么如果已经是wsgi的同步框架能不能无缝转成异步呢？no problem —&gt; greenlet/gevent</p>
<p>我们已经知道，要异步，<strong>事件循环+回调</strong> 跑不掉。那么这个事件循环+回调在uvicorn的中只怎么体现的呢？</p>
<p><code>myapp.py</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    uvicorn.run(app&#x3D;&#39;myapp.main:app&#39;)</span><br><span class="line">...</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>uvicorn/mainpy</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Server:</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    def run(self, sockets&#x3D;None):</span><br><span class="line">        self.config.setup_event_loop()</span><br><span class="line">        loop &#x3D; asyncio.get_event_loop()</span><br><span class="line">        loop.run_until_complete(self.serve(sockets&#x3D;sockets))</span><br><span class="line">        </span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>可以看到<code>asyncio.get_event_loop()</code>获取时间循环，然后把封装了sock的serve（其实就是future对象）放入事件循环处理。</p>
<p>uvicorn 支持的loop有3种，auto/asyncio/uvloop, 默认是auto. auto会尝试首先<strong>加载uvloop</strong>,加载失败才会加载asyncio的loop.</p>
<blockquote>
<p>值得一说的是，可以使用uvicorn + gunicorn部署python asgi服务。uvicorn实现了gunicorn的worker接口，所以gunicorn启动服务的时候可以指定使用uvicorn的worker，比如：<code>gunicorn -k uvicorn.workers.UvicornWorker</code></p>
</blockquote>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMjY5NTE0MA==&mid=2247483720&idx=1&sn=f016c06ddd17765fd50b705fed64429c" title="" target="">深入理解Python异步编程</a></li>
</ul>
]]></content>
      <categories>
        <category>架构</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>异步编程</tag>
      </tags>
  </entry>
</search>
